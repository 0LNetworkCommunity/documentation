"use strict";(self.webpackChunkopen_libra_core_docs=self.webpackChunkopen_libra_core_docs||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/proposals/back-to-filo-the-future-of-open-libra","metadata":{"permalink":"/blog/proposals/back-to-filo-the-future-of-open-libra","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/back-to-filo-the-future-of-open-libra.md","source":"@site/blog/proposals/back-to-filo-the-future-of-open-libra.md","title":"Back to FILO: The Future of Open Libra","description":"Summary of Current Events","date":"2025-04-14T00:00:00.000Z","tags":[{"inline":true,"label":"filo","permalink":"/blog/tags/filo"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":5.795,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Back to FILO: The Future of Open Libra","date":"2025-04-14T00:00:00.000Z","tags":["filo","proposal"]},"unlisted":false,"nextItem":{"title":"Open Libra: The Road Less Traveled","permalink":"/blog/the-road-less-traveled"}},"content":"\x3c!-- truncate --\x3e\\n\\n## Summary of Current Events\\n\\nSince our inception in 2019 this community has been building a decentralized network grounded in unique tokenomics and thoughtful mechanism design. In 2024, a series of deceitful actions strained our community and threatened our ability to thrive. Yet our collective commitment never wavered and our consensus mechanisms worked to allow the community to respond quickly. Together, we doubled down on integrity and held to account those individuals who sought to reap unearned rewards at the expense of the whole.\\n\\nSince then, the community has been exploring additional enhancements to further secure the future\u2019s project and recently proposed 3 go forward options:\\n\\n**Option 1 - Restart:** Launch a new chain, more like a typical commercial blockchain. Everything is on the table, perhaps a pre-mine, investors, or an ICO.\\n\\n\\n**Option 2 - Lock Large Sybils:** Selectively re-lock large accounts, including probable sybil miners, validators, sprayed accounts. Keeps all balances and unlocks the same for small accounts.\\n\\n\\n**Option 3 - Commit to First-in-Last-out:**\\n\\n- Maintain all balances, but convert every account into a slow wallet with zero unlocked coins.\\n- Unlocks remain at 35,000 coins per epoch.\\n- Introduce sybil resistance mechanism through vouching for end-user accounts.\\n- Allow community wallets limited liquidity for administrative use.\\n\\nIn a recent sentiment poll (see below screenshot): **70% of active participants, 66 out of 94 votes, chose Option 3, a return to our foundational First-in-Last-out (FILO) principle.** This isn\u2019t just a preference, it\u2019s a mandate. This proposal is our answer and a bold step towards realigning with the values that define us.  We refer to each giant step forward in our collective progress as a \u201cLevel\u201d.  This document will refer to prior Levels 6 & 7 and describe our future in Level 8.\\n\\n\\n![](../../docs/assets/filo-preliminary-community-vote.png)\\n\\n## Summary of Level 7 Issues\\nLevel 7 exposed some opportunities for improvement.\\nIt began with manipulations in Level 6, where bad actors abused community wallets, our decentralized endowments, for personal gain. \\nThese bad actors, cloaked as analysts, siphoned tokens and created sham markets to dump them, profiting while the network bled. \\nThe result? [A hard fork in Level 7](https://docs.openlibra.io/blog/proposals/scorpions-claw-proposal) to exclude the worst offenders, but the damage lingered. \\nMarkets flooded with tokens, Open Libra\u2019s value crashed, and early believers were left stranded \u2013 a textbook First-in-First-out (FIFO) betrayal, the antithesis of FILO. \\nThe community fought back, proving its resilience, but the chaos revealed a truth: without stronger safeguards, trust and motivation erode.\\nThis proposal exists to fix that. You can read the [Open Libra Level 7 Post-mortem here](https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vQKWRMSIzc1yLn32TYqKMA_Ukkt8bkIjqU9F55gGpcBR1mEqU5FmNEIJ4DZ1o3caQHFutjifDgsXa5_/pub&sa=D&source=editors&ust=1747153318585623&usg=AOvVaw2fZPZvNUMX6R95AEwyaFVz).\\n\\n## The Recommendation\\nHere\u2019s the plan to restore FILO and secure our future:\\n\\n- **Founder Accounts:** All pre-Level 8 accounts become Founder Accounts.\\n- **Slow Wallets Expansion:** Proven mechanisms from Validator accounts, Slow Wallets and Vouching, will be extended to all Founder Accounts. Coins start fully locked, unlocking 35K daily at each epoch.\\n- **Vouching Requirement:** Founder Accounts need vouches from peers to unlock, a community-driven filter against sybils and bad actors.\\n- **Community Wallets Overhaul:** These wallets face the same sybil resistance. Donors must reauthorize them via vote, ensuring accountability. Up to 1% of locked funds can unlock for action, repayable within a year, or the wallet deactivates.\\n\\nThis isn\u2019t a reinvention, it\u2019s a return to what works, scaled to protect everyone committed to Open Libra\u2019s long-term mission. This isn\u2019t damage control; it\u2019s a leap forward.\\n\\n\\nBy reducing entropy and increasing coordination, the network becomes leaner and stronger. One that is poised to grow, not just survive.\\n\\n\\nRecommitting to FILO, we prevent exit-driven panics like Level 7\u2019s \u201crun on the bank,\u201d It protects those who\u2019ve been building all along with us. Reactivating dormant accounts with Slow Wallets and administrative budgets to reinvigorate the community. Reauthorizing Community Wallets ensures they serve their donors, not exploiters, fostering transparency and purpose.\\n\\n## Values, the Guardrails for the Recommendation\\n- **Reward Commitment, Not Exit Speed:** choices rest on unshakable principles; FILO uplifts the builders, not the opportunists.\\n- **Plans Measured in Centuries:** We\u2019re crafting a legacy, not chasing trends.\\n- **No Favorites, No Shortcuts:** Equal rules, no exceptions, That\u2019s how trust stays intact.\\n- **Act in the Light, or Lose the Right:** Transparency is our shield against deceit.\\n- **Strength in Restraint:** We refine what works, avoiding reckless overhauls.\\n- **Do No Harm, Protect the Honest:** Honest contributors flourish; leeches falter.\\n- **Collective Vigilance:** Every member guards our ethos, closing gaps for abuse.\\n\\nThese aren\u2019t slogans, they embody the moral compass steering us back to stability.\\n\\n## Summary of Evaluated Solutions\\nWe explored every angle before landing here:\\n\\n1. **Maintain Status Quo:** Ignoring the problem risked collapse \u2014 unacceptable.\\n2. **Chain Reset:** A hard fork to adopt crypto industry practices (inventors, foundation, pre-mint) was simple but erased years of effort.\\n3. **Selective Migration:** Hard forking bad actors is reserved for the most dramatic cases, in this case we\'re not interested in punishment or survival, but in long term viability. .\\n4. **Whale Locking:** Locking big accounts with vesting tempted us, but it was too clumsy, error prone, and had a number of subjective parameters.\\n\\nExpanding existing policies won out because it is proven, aligns with our core values, and practical.\\n\\n### Expected Objections and Rebuttals\\nCritics will emerge. We\u2019re ready:\\n\\n\u201cThis punishes long-term holders!\u201d No, it shields them, ensuring only the committed unlock funds.\\n\\n\u201cIt\u2019s too complicated!\u201d We\u2019ve streamlined it to address only the essentials while addressing the core issues. We expand existing policies.\\n\\n\u201cBad actors will still slip through!\u201d It\u2019s true perfection is a myth, but vouching for sybil resistance greatly curtails their room to maneuver.\\n\\n\u201cExchanges like Comswap suffer!\u201d We expect all users from pre-market venues to be on equal footing with the native coin holders. All third party venues were notified or invited to participate months in advance.\\n\\n## A Vision for Level 8\\nOpen Libra doesn\u2019t want to be just another crypto footnote; our community wants to pioneer the next level of the game. If Level 8 is successful it will launch the decentralized endowment model. At this stage Community Wallets find their purpose, funding century-spanning projects. Open Libra becomes patient capital, a tool for building, not speculating. Dormant wallets awake, accountable and active. The network grows more resilient, more transparent, community powered, and able to recruit the wise minds and capable hands needed to scale.\\n\\n## FAQ\\nQ: Will my coin balance change?\\\\\\nA: No, your total stays the same.\\n\\n\\nQ: What happens to regular holders?\\\\\\nA: All wallets convert to Slow Wallets, needing Web-of-Trust (WoT) Vouching to unlock.\\n\\n\\nQ: What\u2019s a Slow Wallet?\\\\\\nA: A slow account, releasing 35K unlocked coins per epoch, once vouched.\\n\\n\\nQ: How do I get vouched?\\\\\\nA: Get vouches from other founders, then it\u2019s automatic.\\n\\n\\nQ: What\u2019s Web-of-Trust (WoT) Vouching?\\\\\\nA: Peer system where founders verify each other, blocking bad actors and re-engaging the community.\\n\\n\\nQ: What about Community Wallets?\\\\\\nA: They need donor votes to stay active and can unlock 1% for operations, repayable yearly."},{"id":"/the-road-less-traveled","metadata":{"permalink":"/blog/the-road-less-traveled","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/the-road-less-traveled.md","source":"@site/blog/the-road-less-traveled.md","title":"Open Libra: The Road Less Traveled","description":"A force of the public which has the capital necessary to make meaningful interventions, at the scale of the largest organizations in society. This requires independence, durability, and sense.","date":"2025-02-12T00:00:00.000Z","tags":[{"inline":true,"label":"blog","permalink":"/blog/tags/blog"},{"inline":true,"label":"news","permalink":"/blog/tags/news"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":4.48,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Open Libra: The Road Less Traveled","date":"2025-02-12T00:00:00.000Z","tags":["blog","news","canonical"]},"unlisted":false,"prevItem":{"title":"Back to FILO: The Future of Open Libra","permalink":"/blog/proposals/back-to-filo-the-future-of-open-libra"},"nextItem":{"title":"The Open Libra NodeJS Library Has Been Published on npm \ud83d\udd25","permalink":"/blog/openlibra-nodejs-release"}},"content":"**A force of the public which has the capital necessary to make meaningful interventions, at the scale of the largest organizations in society. This requires independence, durability, and sense.**\\n\x3c!--truncate--\x3e\\n\\n### Independent, Perpetual, Sensible\\n\\n*OL looks different because it is different.* Open Libra does not have a foundation, has no labs entity, no VC funding, and no ICO. Why not? Because, unlike the First In - First Out pump and dump schemes that litter the Crypto landscape, Open Libra has a clean regulatory and moral profile to serve our focused mission \u2014 perpetual funding for impact in society, independent of corporations, governments, and traditional finance of the day.\\n\\nThe unique feature of digital assets is their opportunity to be perpetual, a highly misunderstood and underrated property. OL measures its plans in centuries, on much longer scales than you are accustomed to if you are in tech. But if instead the product is defined as independent and good capital, then a 100-year time frame is plausible. The next generations should expect there to exist an institution (more like a force of the public) which has the capital necessary to make meaningful interventions, at the scale of the largest organizations in society. Open Libra is five years in, and still pre-launch. Deliberately being principled, vigilant, and evolutionary.\\n\\n### Forget Cryptocurrency, Think *Open Titles*\\n\\nThe future lies in the thing that comes after currencies: durable capital which can accumulate entitlements, benefits, and rights over time. Digital titles that are both accessible and enforceable over generations, far beyond transient software versions and networks. Crypto makes a tacit promise: wealth while participating in what the future brings. We extend that further to create a product everyone would want to be a part of: to invite the 98% of the world who seek to participate in future themes of technology, social coordination, and build wealth through engagement with society.\\n\\nWe ask difficult questions of the industry because, to us, the design space is clear, but the offers in the market are not.\\n\\nLearn more about our vision at [https://openlibra.io](https://openlibra.io).\\n\\n## 2024: A Year of Resilience and Progress\\n\\n2024 was a pivotal year for Open Libra. Reinforcing our commitment to the long game, the project undertook several strategic measures to solidify its foothold and secure the mission.\\n\\nWe faced an exploit, a multi-step governance abuse which involved social engineering, deception, and transaction manipulation.\\n\\n**This was not a software failure, but a breach of trust.**\\n\\nThis of course, is not a surprise, and neither an unexpected disappointment. OL goes slow in order to observe and correct the course. The abuse unfolded faster precisely because the exploiters began to take notice of the core founding team that was catching up to the evidence.\\n\\nThe active community responded with an industry-leading forensic process that disabled 98% of exploited funds, demonstrating our commitment to fairness and justice in our community. The community has been clear from the beginning, that we do not invite or suffer that Open Libra is not for the 2% seeking quick wins at the expense of fellow community members. To address these challenges, a hard fork was executed and forensic tools were created, available at [GitHub](https://github.com/openlibra), facilitating interoperability and expanding the Open Libra ecosystem.\\n\\nIt took months to develop Forensic Db, a missing piece of blockchains. The comprehensive forensic database ensures project accountability and transparency. Where necessary, proper authorities in The Netherlands were also engaged to ensure regulatory compliance and proper legal standing.\\n\\n## Learnings\\n\\n### Socialized Enforcement\\n\\nUnlike traditional blockchain projects with centralized governance structures, Open Libra enforces norms through four levels of socialized enforcement. When loose social consensus fails, you should expect to see several layers of enforcement:\\n\\n1. **Smart Contracts:** Improve the binding of key policies of your community norms.\\n2. **Social Slashing:** Start a new network that reinforces the norms, move the party elsewhere.\\n3. **Civil Legal Recourse:** Utilizing judicial systems is fair game when Smart contracts are multi-party agreements.\\n4. **Criminal Enforcement:** Ultimately, criminal enforcement is reasonable against fraud and misconduct when a sovereign\'s laws overlap with ours.\\n\\n### First In Last Out is Worth Fighting For\\n\\nOne of OL\'s oldest founding beliefs is that First In First Out leads to abuse in markets (pump and dump). Many of our exemplary policies (Slow Wallets, Community Wallets) are explicitly designed with a goal of \u201cFirst In, Last Out\u201d principle. In 2024, we diverged from this norm, both intentionally by exploiters and unintentionally by distraction. Governance upgrades have been proposed and are in progress to ground us in this principle again.\\n\\n## Looking Forward to 2025 and Beyond\\n\\nAs the project sets its sights on the future, Open Libra will introduce several key initiatives in 2025 designed to reinforce its mission and expand its impact:\\n\\n- **SlowWalletV2 Proposal:** Enhancing security and longevity for long-term holders.\\n- **Project Nest Egg:** An initiative that aims to transform Libra into a force for good by funding high-quality real-world businesses by effectively deploying capital through Community Wallets. By harnessing voluntary contributions, these wallets become a strategic asset, driving sustainable growth and innovation within the ecosystem.\\n- **Validator Bidding Optimization:** Streamlining the validator selection process for greater efficiency.\\n- **Exchange Listing Initiatives:** Community-driven efforts to expand accessibility and liquidity.\\n\\n## Join Us\\n\\n*The active community invite experts across disciplines who align with our mission and are committed to sustainable, long-term impact to JOIN US: [https://openlibra.io](https://openlibra.io).*"},{"id":"/openlibra-nodejs-release","metadata":{"permalink":"/blog/openlibra-nodejs-release","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/openlibra-nodejs-release.md","source":"@site/blog/openlibra-nodejs-release.md","title":"The Open Libra NodeJS Library Has Been Published on npm \ud83d\udd25","description":"Congratulations to the Open Libra contributors!","date":"2025-02-06T00:00:00.000Z","tags":[{"inline":true,"label":"open-libra-sdk","permalink":"/blog/tags/open-libra-sdk"},{"inline":true,"label":"npm","permalink":"/blog/tags/npm"}],"readingTime":0.395,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The Open Libra NodeJS Library Has Been Published on npm \ud83d\udd25","date":"2025-02-06T00:00:00.000Z","tags":["open-libra-sdk","npm"]},"unlisted":false,"prevItem":{"title":"Open Libra: The Road Less Traveled","permalink":"/blog/the-road-less-traveled"},"nextItem":{"title":"Scorpion\'s Claw Recommendation","permalink":"/blog/proposals/scorpions-claw-proposal"}},"content":"Congratulations to the Open Libra contributors! \\n\\n### **Open Libra NodeJS library** `open-libra-sdk` has been published on the npm repository!\\n\x3c!--truncate--\x3e\\nThis SDK brings you an easy way to integrate Open Libra blockchain functionality into your NodeJS applications. Whether you\u2019re building new decentralized apps or exploring blockchain integrations, this library provides the essential tools to get started.\\n\\nFor complete installation details, usage instructions, and further information, please visit the npm repository page:\\n\\n\ud83d\udc49 [npm package page for open-libra-sdk](https://www.npmjs.com/package/open-libra-sdk).\\n\\nCarpe Diem!"},{"id":"/proposals/scorpions-claw-proposal","metadata":{"permalink":"/blog/proposals/scorpions-claw-proposal","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/scorpions-claw-proposal.md","source":"@site/blog/proposals/scorpions-claw-proposal.md","title":"Scorpion\'s Claw Recommendation","description":"Community Wallet Analytics and V7 Hard Fork Parameters [DRAFT]","date":"2024-04-09T00:00:00.000Z","tags":[{"inline":true,"label":"fork","permalink":"/blog/tags/fork"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":15.105,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Scorpion\'s Claw Recommendation","date":"2024-04-09T00:00:00.000Z","tags":["fork","proposal"]},"unlisted":false,"prevItem":{"title":"The Open Libra NodeJS Library Has Been Published on npm \ud83d\udd25","permalink":"/blog/openlibra-nodejs-release"},"nextItem":{"title":"Team Arctika Recommendation","permalink":"/blog/proposals/team-arctika-recommendation"}},"content":"\x3c!-- truncate --\x3e\\n\\n## Community Wallet Analytics and V7 Hard Fork Parameters [DRAFT]\\n\\nApril 9th 2024\\n\\n# TL;DR\\n\\nOperation Scorpion\u2019s Claw identified 4.012 billion LIBRA involved in instances of abuse of the community wallet tooling; approximately 4% of the total supply.\\n\\nA methodical approach was used to programmatically identify participating accounts. The endeavor took four weeks because\\n\\n- new tools were developed\\n- new technologies implemented\\n- platform software updated\\n\\nThe result is a list of 436 accounts. If validators decide, they can now run a version of a network aiming to exclude dishonest accounts. The dishonest accounts which currently contain 3,768,939,592 LIBRA.\\n\\nThere was a handful of abuse cases. However, the vast majority of the exploit was conducted by a long-term community member who has publicly declared ownership of the accounts originating the exploit.\\n\\n- `6DA2B828F3018637379203940C639A95`\\n- `27E9577869ADFD677DBA9C940DEECE0A`\\n- `988B8C3B7E55B6E5126884E02C8F166E`\\n\\nA hard fork is recommended, and should happen with a validator ceremony open to the public and using a clean database using the version 7.0.0 software release.\\n\\n![image](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpdWi_O_kHFqEKhvBDfr41QGlcBVH2As0u3xr5Hd0Fxb0IN9N8rBHfvFI5u76rOGSKZZFa36kWdY77XqVWhpRhSgptePszHNlvZJ-tptwfzZsp-WNkvVQLQyg4JTAe2N-uZDuTfhuO2I5XAuao1-1q84B1?key=UdkA8jBMllBve2WagZXXwA)\\n\\n# What Happened\\n\\nIn preparation for the release of the 0L Network v7 Mainnet, analytics contributors ran a comprehensive on-chain analysis of all user-generated events \u2013 code named \u201cScorpion\u2019s Claw\u201d. This meticulous examination revealed several instances of abuse, predominantly to the Donor Voice accounts (\\"community wallets\\") which are a great source of pride of the 0L community.\\n\\nBefore a report on these abuses could be completed, the rogue players discovered the operation was underway and began to drain accounts into OTC markets. Some validators responded by stopping their nodes, preferring to wait for the final report and remediation recommendations than to continue participating on a network with that behavior. Many community members were interested in a Hard Fork. This report provides the facts, and basis for which a hard fork could be conducted.\\n\\nOperation Scorpion\u2019s Claw identified 4.012 billion LIBRA involved in these instances of abuse, or approximately 4% of the total supply.\\n\\nIn this report, a list of the accounts involved in the abuse has been developed by strictly adhering to the following goals:\\n\\n- A deterministic approach for inclusion criteria.\\n- Maximum removal of misappropriated supply.\\n- Minimal adverse impact to uninvolved parties.\\n\\nThis endeavor yielded a final list of 436 accounts, holding 3,768,939,592 LIBRA.\\n\\nScorpion\'s Claw proposes that on a new network, these accounts will be excluded by being rendered inaccessible. As such, the associated supply will be permanently removed from circulation. These actions signify an exclusion rate of the total amount of dishonestly appropriated coins of 94%.\\n\\nAs with any hard fork the prior software would remain available to those who wish to continue on the prior chain. Though the recommendation of this report is that such a chain would not be popular with users for social and economic reasons, users and validators remain free to use that version of the chain if they so choose.\\n\\n## Background\\n\\n### Design Philosophy\\n\\nThe 0LNetwork community champions self-correcting systems instead of rigid white list driven systems with authoritarian control. Many 0L designers are informed by Karl Popper\'s vision of an open society and naturally self-correcting systems. This open approach to design and operations, while prone to exploitation, is essential for progress and encourages boundary testing that allows policy to evolve naturally. Exploitation and innovation are often distinguishable only in retrospect so open systems are necessarily open to what will later prove to be fraud. Eliminate any opportunity for exploitation and one also eliminates any opportunity for evolution. Exploit and evolve. We regard the tradeoff with equanimity.\\n\\nBlockchains are probabilistic, not deterministic, systems. Hard forks in this paradigm are viewed not as indicators of failure nor guarantees of success, but as strategic adjustments that are vital to the longevity and success of a robust network which is resistant to abuse and central control.\\n\\n0L\'s Approach to open policies:\\n\\n- Emphasize the absence of absolute guarantees, lean on probabilities.\\n- Reject the need for foundational authority, embrace open participation.\\n- Recognize the constructive role of exploits and boundary-pushing by participants.\\n- Accept hard forks as evolutionary steps within the policy framework, aimed for continuous improvement.\\n- Invite a dynamic interaction with policies, where challenges are opportunities for advancement.\\n- Underscore the importance of adaptability and innovation in navigating open policies.\\n\\nIn this paradigm hard forks are viewed not as indicators of failure (nor success) but as strategic adjustments that are vital to the longevity and success of a robust network.\\n\\n### 0L Network Policies\\n\\n#### Slow Wallets\\n\\nOrdinary wallets don\u2019t limit transfer amounts and have no balance restrictions. Transactions are immediate in the typical wallet a user would initialize (e.g. in Carpe).\\n\\nEarly participants in a network may receive generous subsidies, but the chain\u2019s policies should be designed in such a way as to prevent early participants from dumping on less sophisticated users. To address this need, rewards are sent to Slow Wallets (SW) rather than regular wallets. All validator node accounts, where a majority of rewards flow, are Slow Wallets. Slow Wallets have a drip mechanism that unlocks its balance in increments of 35k coins per epoch until the full balance eventually becomes unlocked.\\n\\n#### Community Wallets\\n\\n0L Network chain provides tools and patterns for communities to self-fund their activities with LIBRA. One pattern is the Donor Voice participatory payments together with Matching Donation Index, a.k.a., informally \\"Community Wallets\\".\\n\\nUnlike traditional systems, the core innovation here is that there is no whitelist or global governance structure. 0L Network had no pre-mine state, and designs such as \\"founder rewards\\" are antithetical to our design philosophy.\\n\\nA Community Wallet (CW) is instantiated not only with a number of on-chain tools (smart contracts), but also with off-chain commitments. Without going into further detail, a user could create a CW (on chain), and ask for donations (off chain). Those donations would also serve as a way to index a Matching Donations list, which validators and other contributors could opt-into (more below).\\n\\nNotably, this open system is probabilistic, it was known in advance that it was likely that this would be abused (and as you see below, it was). So there are a number of conditions a CW owner, opts-into by instantiating Donor Voice covenants on their account:\\n\\n- That account can only transfer coins to a Slow Wallet\\n- Proposed transfer takes three epochs (days) to finalize.\\n- During this period, Donors to have the opportunity to veto a transaction.\\n- Sequential vetoes to the account will freeze it from doing future transfers.\\n- Since V6.9.0, Donor Voice enabled accounts are required to be multi-sigs.\\n\\nThe astute reader will notice, the probabilistic equilibrium depends on players.\\n\\nWith an insufficient number of players observing Donor Voice accounts, or misplaced trust in observers of those accounts, abuse will take place. This is not a surprise, and was known from the start. A trade-off in playing open games.\\n\\n#### Match Index\\n\\nIn many blockchains there is programmatic removal of coins from supply. Without going into much detail, there are cases when a user should pay competitively for a resource (e.g. transaction ordering), but the cost of providing that value is not proportional to the fee. One pattern is to exclude from the new network - colloquially, \u201cburn\u201d - the difference, and remove it from circulation permanently (see for example Ethereum\'s EIP 1551).\\n\\nTypically the reason for burning instead of redirecting, is that burns prevent a kind of exploit loop where attackers can harvest the redirect. This is true, but it is also a missed opportunity and 0L Network proposed a market driven experiment.\\n\\nThere is also an opt-in alternative built into all accounts, that allows any user to redirect burns attributed to their accounts to community programs. Strictly speaking: a Donor Voice enabled account usually elects to be a part of Matching Index. This means instead of permanently removing the excess coins, validators can use them to fund any community\'s programs.\\n\\nWhen a miner or validator opted into making matching donations to a CW, certain regular programmatic removal of coins, would instead recycle coins to the Match Index. (People have compared this mechanism as akin to implementations in the crypto industry of Quadratic Finance, without the quadratic nature of votes).\\n\\n### The Equilibrium\\n\\nThe intersection of Community Wallets and Matching Donations was designed to create a healthy tension:\\n\\n- Community Wallet Creation: Any community member has the power to create a Community Wallet, allowing for community participation in a diverse set of initiatives.\\n- Influence through Donations: By donating to these wallets, individual community members can influence the allocation of matching donations. This system is designed to encourage community support.\\n\\nTo the objection that more controls were necessary, the old adage of payment processing applies: \\"I can promise you zero fraud, as long as you receive zero payments\\".\\n\\n#### Boundaries and Consequences\\n\\nWe\'ve mentioned on-chain constraints to these accounts. It\'s also worth highlighting that the economic game involving community wallet, exists offline too. The blockchain serves as a coordination layer for the game, it is not the boundary of the game. All users of community wallet tooling should have the expectation that the laws and norms of society continue to apply (code is not law).\\n\\n- Social: Community backlash or loss of trust among peers.\\n- Legal: Potential legal actions based on the severity and nature of the manipulation.\\n- Hard Fork: In extreme cases, the network might undergo a hard fork \u2014 a significant change to the protocol software and database which contain any rules the new network participants choose to enforce, for example: dropping accounts.\\n\\n# The Exploits\\n\\nThis section explains the three types of abuse by community wallet creators which led to the hard fork decision.\\n\\n### Harvesting\\n\\nThe Harvesting exploit involves skewing the matching donations algorithm by donating to a community wallet under the control of one validator with the only purpose of collecting coins from unsuspecting Match Index donors.\\n\\n- Harvesting is the act of creating a Community Wallet, then:\\n  - Creating multiple accounts (usually Validators)\\n  - Programming them to funnel their donations and locked coins to the CW they control.\\n  - By doing so, the bad actors are increasing their CW balance while also creating the perception their Community Wallet is highly valued and directing more donations from the rest of the validators and the community as a whole.\\n- The image below is an example of the harvesting exploit. The blue nodes (validators), made AUTOPAY (blue lines) to a community wallet (orange node). In the case presented below, you can see two CWs that the validators that participated in the Sybil attack donated to (one above the validators, one below):\\n\\n![image](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdDv0XeO11HLUR0NFbfKZkIMu33cTFNOtVs8jrwbHF45XecHE4tZO7MGQBUeeOIHGUAXh6G2cB5oqCxKdHVsRQh41wjG5r0OIEthoJwlz2-HYC78Ic5EDcNfp8a7sYfq9X6VXbVogCm3nyWrqYs9NljeDqT?key=UdkA8jBMllBve2WagZXXwA)\\n\\n### Spraying\\n\\nSpraying exploits circumvent the standard Slow Wallet time-locking algorithm by dividing payments into several Slow Wallets.\\n\\n- By design, a Community Wallet only makes payments to a Slow Wallet.\\n  - Coins that are sent from CW to a SW first enter a \u201cbucket\u201d of \u201clocked\u201d coins.\\n  - They vest and then eventually transition to an unlocked state at a rate of 35,000 coins per epoch.\\n- Spraying is the act of creating multiple Slow Wallets and then sending CW_PAYMENT to them in parallel. Doing so linearly increases the number of unlocked coins. Instead of the allowed 35k unlocked coins per epoch, this exploit multiplies the effect by the number of slow wallets involved in the exploit.\\n- In the image below, the purple nodes represent slow wallets, and the green lines represent CW_PAYMENTs. In this case 2773 payment events were made to 433 slow wallets.\\n  - That means that every epoch, the owner of that network accumulated 15.1 million unlocked coins.\\n\\n![image](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdedjYc4qNdnT7RzmvLX2vZNgrF0SiobpUAFrQT-X3k69OxssdhXIE0FXbblYocdKintniwjcMx9tde51PD587GAJaABy6J8rFkwQgnClMVj_KH1tHTvC5YBFvCJJMB2ssQGrBiW3jPRR9lq8EXwBjyinQ?key=UdkA8jBMllBve2WagZXXwA)\\n\\n### Transfer Bug\\n\\nA regression to the codebase was introduced during the v6.9.0 upgrade.\\n\\n- The codebase regression manifested in the ability of a CW to make ordinary transfers. This meant bypassing all Donor Voice governance including donor observability, and restricting to Slow Wallets.\\n- The bug exploit can be seen in the image below with the red lines (transfers) from the CW (orange) to the nodes around it. In this particular case, you can see it exhibits also the first (multiple validators donate to it) and second exploits (making many payments to a multitude of Slow Wallets).\\n\\n![image](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdg4tqkagkrHnHtGSOaOQgul_UDCLG2v1RFp3R1eKigc8Y3Psx6XsAeClqxwkF2nnvSFciXTP2hslnlOvMZiw2EaatK0dacqEncm2JRL3-W9c6xQOTbNTcbYoRgA1Aj-1Pl6VPW3i0I3WFkt-kDtO8B9ION?key=UdkA8jBMllBve2WagZXXwA)\\n\\n# CASE 1 Principal Exploit\\n\\nWe will not cover each exploit in detail. However CASE 1 is exceptional because of the exploit size, there were approximately 3,614,811,756 (3.6 Billion) unlocked coins in possession of an individual (the largest unlocked coin stake by perhaps 30x). This is approximately 3.6% of the network supply.\\n\\n### Principal Accounts involved\\n\\nThere are many hundreds of accounts created by a single exploiter. This is verifiable by observing the path of account creation from a seed set of a few accounts.\\n\\n![image](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfiR_6nWttmM-i-0e5digE-8N3Z3HfFC1cQZtQR0Jy3imt67q44yYlFVMgKsp7vJN1iP6af1pfNBxbGQdy3kF7wBJrmEstINS4NaTCorV3tks6jtYr8kemVaK_f_u3W_9aGiB06Q6xLnVFIQLj_tiO9KWyy?key=UdkA8jBMllBve2WagZXXwA)\\n\\nIf the relationships of these few nodes are expanded, the flow of funds goes through these nodes:\\n\\n![image](https://lh7-rt.googleusercontent.com/docsz/AD_4nXd2GfTBgsrE6jEFLkeSFOyQJjaRaNyQb5FuBgV1ExEoMjf489bfdS9WKX4o8B7khcS_ibHawRgYAvZLInFWt76e6heG-Y24kA5XrT-W_oWzZ5Nuz1jj1Je42ou5bEACLroPMZgszHp3EDoNQccJCcv2bCE?key=UdkA8jBMllBve2WagZXXwA)\\n\\n#### Sham Community Programs\\n\\nThe community wallets involved in this case are:\\n\\n- `7B61439A88060096213AC4F5853B598E`\\n- `5E68026887147DE0EA9CA90962C25A41`\\n- `97DCBC6BFAA7EDF00F9002DAAED49C46`\\n\\nThere is no information publicly available about these \\"community\\" programs. Different from other credible and well regarded programs in the community. Their principal source of funding was from \\"validators\\" nodes which the individual publicly associated themselves with. Due to the nature of Match Index (described above), many other validators became unwitting contributors to these accounts (the \\"harvesting\\" exploit).\\n\\n#### Sybil Validator Accounts\\n\\nCommunity wallets could not reasonably accumulate much capital unless they solicited donations from many people. But if an individual had acquired access to many \\"validators\\" with high reward potential, they could do so. (Note, acquiring multiple validators was also outside the stated norms of the community. Several validators were notified publicly that you should not try to run multiple validators even though you might be able to get around some of the constraints).\\n\\nIn this case, the exploiter had ownership of the following validator addresses:\\n\\n- `6DA2B828F3018637379203940C639A95`\\n- `15B291FFCA97895D726E8AA9A5BE6A2A`\\n- `5DC8C3878E99E9FD12EBDEFA1803D332`\\n- `C5162C65FDE8C9D9CA9B564E41A54003`\\n- `988B8C3B7E55B6E5126884E02C8F166E`\\n- `7D299BF3D624E937C23302D8B5E3A1B2`\\n- `99E4EE712E2A57F694344D288A0FC27A`\\n- `9F1D8C66883768F167A097FF4C58DE88`\\n- `C0FFEE1A3393516D27B72B28464EAA5F`\\n\\n# The Hard Fork Goals\\n\\nOnce validators realized the magnitude of the exploit, they and core contributors responded by stopping their nodes preferring to await a full analysis and recommendation.\\n\\nThe recommendation here is to perform a hard fork of the 0L Network, which maintains all properties of the canonical chain except that it does not migrate the accounts involved in the abuse of the system\u2019s hardcoded rules and prevents the abuse of those hardcoded rules from taking place again.\\n\\nPunishment is not an end-goal. The recommendation is to simply remove abusive accounts, while perhaps setting a non-binding social precedent signaling that a decentralized group of validators are capable of taking, and willing to take, coordinated action to prevent abuse and will not run software that allows abuse.\\n\\n# The Process\\n\\nThe first part of the process involved defining the exploit types. The effort had three key objectives: ensure accuracy, capture as much questionable activity as possible, and avoid penalizing innocent parties all while still being deterministic.\\n\\nThe Goals were to:\\n\\n1. Find all the community wallets that participated in the defined exploits.\\n2. For each of them, via pattern matching, identify and collect a list of the nodes that participated in the scheme.\\n3. Identify edge cases where the common patterns did not apply or the scheme operator attempted to obfuscate their actions or balance by spreading nodes via common \u201csuperspreaders\u201d like the Discord onboarders.\\n4. Ensure no common, widely known accounts were present on the list such as Discord onboarders.\\n5. Leave every harvesting case with a single validator node (both as a show of grace and to reward their legitimate contribution to the network).\\n6. Applying a 200K LIBRA balance threshold to reduce the impact to innocent parties who might be caught up accidentally in the exploit. This approach led to 45.58% of the accounts being excluded from further examination, ensuring the focus of remediation on more chief offenders (see table A in appendix).\\n7. A single database command should generate a list of accounts without human intervention.\\n\\nThis whole process was written in several Cypher language (graph DB) queries and packaged into a Python tool that can be run by anyone to produce an identical checksum of the final list. This tool and the queries have been made public in the following directory on GitHub: [https://github.com/0LNetworkCommunity/scorpions-claws](https://github.com/0LNetworkCommunity/scorpions-claws).\\n\\n# The Result\\n\\n- 436 accounts excluded from new network\\n- Total LIBRA excluded from new network (\u201cburned\u201d): 3,768,939,592\\n- Circulating LIBRA burned: 1,419,359,988\\n- Locked LIBRA burned: 640,266,766\\n- Community Wallet LIBRA burned: 1,709,312,837\\n- Community Wallet excluded from new network: 6\\n- Historical validator accounts excluded from new network: 11\\n\\n# Actions Needed by The Coin Holders\\n\\nNo action is required by community members who were not involved in the exploits. The transition to the hard fork and all subsequent version upgrades will occur seamlessly and automatically.\\n\\n# Other Mitigations in Place\\n\\nWhat does the future look like and what more needs to be done?\\n\\n- The Bug exploit was fixed in January 2024 in an on-chain upgrade.\\n- A new off-chain monitoring infrastructure will be built post v7.\\n  - This will improve network visualization and investigative capabilities. The tools that have been developed and utilized during this exploit analysis, will be available soon for public use.\\n- A dedicated Community Wallets page in explorer will provide valuable insights and live CW activity.\\n  - The community and contributors will continue to report any discovered exploits, rather than taking advantage of them to the detriment of the rest of the community.\\n- There is no more easy money left.\\n  - A majority of the exploits occurred during a time in the evolution of the network where exploits like harvesting could be rewarded. That time has passed.\\n\\n# Acknowledgments\\n\\nSpecial thanks to the Scorpion\'s Claw task force and all the contributors who worked tirelessly over weeks to resolve these issues on behalf of the extended community. Your commitment to the network is greatly appreciated, and the community is very thankful for your efforts.\\n\\nA very sincere and heartfelt thank you also to the wider community for your patience and support throughout this process.\\n\\n# Appendix\\n\\nScorpion\u2019s Claw Farm Report: [https://docs.google.com/document/d/e/2PACX-1vQXu7IISWJIAYQ1OG--ETtdaqE7tYG5Gs0kxDkwfRWZAD0W7SFVdb_EgoN8IqHyTj3DXIhF1okYLFT2/pub](https://docs.google.com/document/d/e/2PACX-1vQXu7IISWJIAYQ1OG--ETtdaqE7tYG5Gs0kxDkwfRWZAD0W7SFVdb_EgoN8IqHyTj3DXIhF1okYLFT2/pub)"},{"id":"/proposals/team-arctika-recommendation","metadata":{"permalink":"/blog/proposals/team-arctika-recommendation","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/team-arctika-recommendation.md","source":"@site/blog/proposals/team-arctika-recommendation.md","title":"Team Arctika Recommendation","description":"To survive, the 0L Network needs to solve two problems. We need:","date":"2023-05-23T00:00:00.000Z","tags":[{"inline":true,"label":"econ","permalink":"/blog/tags/econ"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":9.695,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Team Arctika Recommendation","date":"2023-05-23T00:00:00.000Z","tags":["econ","proposal"]},"unlisted":false,"prevItem":{"title":"Scorpion\'s Claw Recommendation","permalink":"/blog/proposals/scorpions-claw-proposal"},"nextItem":{"title":"2022 Governance Recap","permalink":"/blog/proposals/october-2022-governance-recap"}},"content":"\x3c!-- truncate --\x3e\\n\\n**To survive, the 0L Network needs to solve two problems. We need**:\\n1. Abundant capital for security, and\\n2. Abundant capital for recruiting talent.\\n\\n\\nAnd if possible, we should solve these problems in a fashion that does not worsen the inequality between members of the community.\\n## Much More Capital Is Needed\\n\\n\\nThe crypto headwinds are significant: Regulatory pressure, fraud, scammers and a macro economic environment that favors the bears. If the network wants to survive the next decade, without any inflation, it needs to reserve a large portion of the network capital for future purposes. We will need to provision a greater amount than our peers who have inflation. We are of the opinion that the proportion should be as close to 80% / 20% as possible (the math resembles that of venture fund economics). While we strived for that goal, we weren\'t able to reach that number without massive disruption to multiple user groups. We finally arrived at a 70/30 ratio (70% for growth and ecosystem; 30% held by community members today), which gets us functionally close to the original goal, without system wide disruption of stakeholders.\\n## How much is necessary for the Infrastructure Escrow Fund (IEF)?\\n\\n\\nWe can estimate that, in order to attract validators, the network will have to pay each validator US$4-5k per month (this is consistent with what validators are paid in mature networks with smoothly operating software). In our interviews with professional validators, we arrived at $4,200 as our baseline. See the data in the table, below:\\n\\n\\n![](../../docs/assets/validator-opportunity-cost.png)\\nThe Team agrees that we need to provision for another 7 years of network operations. We\u2019re roughly three years into the network\u2019s life cycle at this point in time (1 year in testnet, followed by almost 2 years since Genesis). Altogether, we should make it through at least the first 10 years of the network.\\n\\n\\nOf course, translating a token with no market value into monthly USD amounts requires some assumptions about value. We must take a conservative approach on market cap, for \\"all weather conditions\\". Despite what we\u2019ve seen with some of our peer networks, we can\'t reasonably say that the base case for networks is a valuation of $1B\\\\+ over the next 7 years. Likewise a network worth less than $50M for many years likely leads to extinction. So, the calculations we made assumed a $100M market cap, from which a token value could be extrapolated; this seemed like a reasonable base-case (which could be substantiated further).\\nAt that intersection: 100 validators earning $4,200 per month over 7 years, with a network on average worth $100m, the result is approx 35% of network capital needs to be pre-diluted for sufficient safety.\\n\\n![](../../docs/assets/infrastructure-escrow-pledge-sensitivity.png)\\n### Over-allocation\\n\\n\\nThe formula above, and our approach to erring on the side of more rewards, may lead to over-allocation of OPEX instead of CAPEX type activities; so there must be a provision for over allocation (i.e. if the network is persistently worth more than $100M).\\n#### Policy for Over Allocation\\n\\n\\nThe IEF is designed to continue with the V5 policy, that overspending can be burnt: i.e. reclaimed capital. The burn can optionally be \\"recycled\\" by validators by sending to an algorithmic matching contract, which distributes to Donor Directed wallets (aka community wallets) which have received the most donations (biased for most recent donations). We recommend this policy continue, such that over-allocation to OPEX and infrastructure, doesn\'t penalize growth capital (CAPEX). This is compatible with the Proof-of-Fee design where, for example, every epoch there can be a consistent drawdown from infra-escrow, and only the net is paid to validators, and the overallocation is burnt per the policy above.\\n## Who can contribute?\\n\\n\\nSome category of participants need to pay for these proposed changes. This requires a pragmatic, and not an emotional solution: ***What does the repeated game need for success?***\\nWe elected to eliminate some options outright:\xa0\\n* **Carpe miners**: There is not enough capital to meaningfully tax those users. Any tax would be symbolic.\\n* **Worker slow wallets** (e.g., beneficiaries of FTW, Hustle Karma, and other community bounties): Again there is not enough to tax, that would meaningfully contribute.\\n* **Community Wallets**: That\u2019s a bigger topic so, see below\\n\\n\\n### Why Exclude Community Wallets?\\n\\n\\nThere\'s a lot of misunderstanding about Community Wallets \u2013 and the concept is very important to the project for several reasons, not the least of which is regulatory compliance.\xa0\\n0L has no centralized treasury, by design, and for regulatory compliance it has been recommended that we never implement one. Community wallets are an emergent property of the network. The wallets have typically\xa0 been created to fund programs for the benefit of the community. Part of their role is to safeguard capital for future uses. The vast majority of them have some language related to: a) safeguarding capital for future use in the network, b) deploying that capital. According to the disclosures of these accounts the capital is not used for personal or company enrichment.\\nGiven their stated role, taxing the community wallets is taxing our growth capital. If you reduce the size of community wallets in favor of infrastructure escrow (IEF), you are reducing the amount of discretionary investment capital.\xa0\\nIn the extreme case: If you tax community wallets 100% into the IEF, while we will solve problem one (security capital), we would fail on the second problem (there will be no funds to credibly attract future talent and entrepreneurship).1\\nWe are left with charging the Validators.\\n## How much do we ask validators to contribute?\\n\\n\\nIf we keep with the numbers above, Validators should contribute 80% of past rewards towards the future IEF. We think this is acceptable for two reasons: First, there is very little choice if we are to survive, and second, the historical payout was not reflective of market conditions and therefore equity favors adjustment.2\\n### Disproportionate rewards\\n\\n\\nOur conclusions about the need to address equity were based on data. We conducted a survey to find out how much volunteers have contributed over time, and what is the approximate value of that work. We asked the same of validators, as well as engineers.\\nThe results of our (limited3) research showed that, at the extremes, workers had a cost per coin that was up to 45X higher\xa0 than the costs incurred by the Validators. Another way to look at it, the cost per coin (from lost wages and infrastructure payments) that pure Validators paid was 1/45 that of the top contributors (all rewards considered). That\'s about a 98% discount4, according to our research numbers. Paying more did not confer the workers any advantage in volume (they were not able to accumulate more share of the network).\\nAfter the dilution, Validators are still getting an extremely attractive proposition. Excluding outliers (0D for example) the typical validator accounts still have paid 87% less than the top 10 worker accounts.5 It would be inappropriate, however, to conclude that the workers have been given a superior deal. The vast majority of workers have the majority of their coins from validator work. And those accounts will also be contributing 80%. This can only be corrected by using the community wallets judiciously.\\nDespite the workers not being explicitly and mechanically taxed, they have already been (e.g., inflation). Even after this intervention, and considering possible uses of community wallets to \\"make-whole\\" these workers, in the best case the largest passive validators will have a 76% discount on cost per coin versus the lead engineers. While we can make it better, we can\u2019t fix everything.\\nLastly, the most committed Validators will partially reclaim their contributions to IEF if they commit to validating over the long term. By continuing to operate a Validator, a portion of those coins will come back to them. (Note this is the only group of community members that benefits from this mechanism.)\\n## Budgeting for past workers\\n\\n\\nA related issue is also being addressed in conjunction with the tokenomics adjustment. Prior to the re-basing and the dilution and adjustments outlined above, the Tip Jar and Iqlusion FTW wallets will be distributed to workers. Note that these uses are consistent with the stated aims of the wallets and, at least in the case of the FTW wallet, the amounts should have already been paid out. Failure to pay those out prior to the re-basing would disadvantage those workers. Put another way, the Tip Jar (which 0D has already offered to community purposes), as well as the FTW wallet (which has not made monthly payouts as it was intended to) should \\"make-whole\\" the past workers.\xa0\\nWe think the proposal increases equity but frankly the main purpose of the proposal is for survival. The increase in equity is a bonus. The only scenario in which everyone is equal is the collapse scenario which none of us want.\\n## Budgeting for future workers\\n\\n\\nThe remaining community programs should focus on the future. There is no formal mechanism, but they can be encouraged to do so by their donors (which are historically validators) through the governance changes to Donor Directed Wallets.\\n## Conclusion: This is what Good Capital looks like\\n\\n\\nWe looked at many models of dilutions and fees. Asking validators to invest 80% of prior rewards into Infra Escrow, very cleanly (even serendipitously) allowed the network to have these properties:\\n* 70/30 in favor of future network participants.\\n* Have future capital for Opex (Infra Escrow) and Capex (Community Wallets) split evenly (out of the 70%) in the base case.\\n* Reduce the gap between worker and validators to 1\\\\.3X from 16X.\\n\\n\\n![](../../docs/assets/summary-dilution-impacts.png)\\n\\nWe think this allocation, with abundant amounts for future capital, which honors prior workers such that we can continue recruiting for future talent, and sets up all current participants for future success is **unique and exemplary in the industry, and fulfills our mission of creating \\"good capital\\" and gives us the best shot at surviving and thriving.**\\n\\n\xa0\\n### **\u2013 Team Arctika** (AlexT, Daniyal, Lex, 0D, ricoflan, Wade \\\\| TPT, Zmanian)\\n\\n\\n\xa0\\n\\n*\\\\*\\\\*Note the Arctika Report was originally published to the 0L Network Discord on 23 May, 2023\\\\.\xa0See, https://discord.com/channels/833074824447655976/910315033672704090/1110679498288005130*\\n\\n\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=end notes\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\\\=\\n\\n1\xa0That all said, there is an important recommendation we must make for community wallets. Keeping with the October poll, where the network expanded the governance of the Donor Directed wallets, to allow the donors to freeze accounts, this was underspecified. What happens with the frozen account? We think the natural conclusion is that the frozen account should get liquidated into a pro-rata share of the remaining qualifying donor directed wallets. We don\'t anticipate this will ever be done, but it\'s important for the game theory of multiparty negotiation of the uses of the community wallets.\\n2\xa0A key incident contributed to the second issue, the disparity in the history payouts to Validators. There is an acknowledgement that the Reward Auction in 0L was no longer viable after a partial upgrade in April 2022 (the baseline parameters were not updated after some other policies were updated).\\n3\xa0This was done via a Google Form that a number of members voluntarily completed, so it is based on self-reported data.\\n4\xa0We do recognize this is a generalization and may not apply to everyone across the distribution, but the data we gathered did support these numbers as a general matter.\\n5\xa0Note that our calculations showed that you could achieve equity between the groups, but only at the expense of diluting Validators by 98% \u2013 a non-starter.\\n6\xa0Note this \u201cBEFORE\u201d data is from the Cap Table research done by ricoflan in March 2023, so it is not current at the time of publication of this paper (23 May 2023\\\\)."},{"id":"/proposals/october-2022-governance-recap","metadata":{"permalink":"/blog/proposals/october-2022-governance-recap","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/october-2022-governance-recap.md","source":"@site/blog/proposals/october-2022-governance-recap.md","title":"2022 Governance Recap","description":"The 0L Community recently concluded its first round of collaborative, decentralized strategic planning. Starting first with rounds of guided discussion on the RadicalxChange Voice platform, the process culminated with a set of eight proposals for community vote. In this blog post, we\u2019re going to take a brief look at the contents of those proposals and reflect on the outcomes of the vote.","date":"2022-11-08T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":8.2,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"2022 Governance Recap","date":"2022-11-08T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Team Arctika Recommendation","permalink":"/blog/proposals/team-arctika-recommendation"},"nextItem":{"title":"Proof of Fee - Part 2","permalink":"/blog/proof-of-fee-part-2"}},"content":"\x3c!-- truncate --\x3e\\n\\n# October 2022 Governance Recap\\n\\nThe 0L Community recently concluded its first round of collaborative, decentralized strategic planning. Starting first with rounds of guided discussion on the [RadicalxChange Voice](https://voice.radicalxchange.org/) platform, the process culminated with a set of eight proposals for community vote. In this blog post, we\u2019re going to take a brief look at the contents of those proposals and reflect on the outcomes of the vote.\xa0\\n\\n\\n\\n\\n## The Voting Process\\n\\n\\n\\n\\nSeven of the eight proposals gave voters a yes\\\\-or\\\\-no binary option for voting. The eighth proposal was comprised of four parts that needed to be voted on independently. The voting platform was RadicalxChange Voice, which gives all voters an equal amount of \u201ccredits\u201d, which can be used to vote more than once for any proposal they feel strongly about, allowing them to express how committed they are to that result (note this factor is expressed below as \u201cvoting power\u201d which expresses the total commitment of both positive and negative votes). Voters were not able to see the votes of the group as they cast their votes, and the voters could change their votes right up to the deadline.\xa0\\n\\n\\n\\n\\n## The Proposals\\n\\n\\n\\n\\n### [Proposal 2210\\\\-01 Final Supply](http://openlibra.blog/2022/10/11/proposal-2210-1-final-supply/)\\n\\n\\n\\n\\n**Synopsis**: Proposal 1022\\\\-01 is focused on stopping inflation within 0L, while creating a mechanism for funding ongoing validator incentives in the absence of issuance. There are three parts to the proposal: (1\\\\) stop issuance; (2\\\\) rebase the token; and (3\\\\) create and fund an Infrastructure Escrow community wallet to provide validator rewards. The proposal asks for a single vote on all three parts; the three parts are interconnected and dependent.\\n\\n\\n\\n\\n**Voting Result:** This proposal passed by the largest margin (\\\\+134\\\\) and also showed the largest commitment of voting power (1,036 credits). Looking at the raw numbers in the voting, this proposal received the largest total number of positive votes and the highest number of voters.\\n\\n\\n\\n\\n**Comments**: Clearly, this was the topic of greatest concern to the community. The large positive vote was a bit of a surprise given the complexity of this proposal (3 parts) and the significant impact it would have on the system\u2019s tokenomics.\xa0\\n\\n\\n\\n\\n### [Proposal 2210\\\\-02 Proof of Fee](http://openlibra.blog/2022/10/11/proposal-2210-2-proof-of-fee/)\\n\\n\\n\\n\\n**Synopsis**: Proof of Fee could be used to partially replace 0L\'s current security model by adding new economic guarantees.\\n\\n\\n\\n\\n**Voting Result**: Passed by a reasonable margin (\\\\+63\\\\) and received the second largest amount of voting power (579\\\\). A look at the raw data shows this proposal had the third\\\\-largest number of voters and received the largest number of negative votes.\\n\\n\\n\\n\\n**Comments**: This was a highly technical question that is primarily of interest to validators (existing or potential). The high levels of commitment, combined with the median result in the voting margin, shows that there were strong opposing opinions about this. The large number of negative votes also shows this to be one of the most divisive proposed changes to the network\u2019s technical architecture.\\n\\n\\n\\n\\n### [Proposal 2210\\\\-03 Musical Chairs](http://openlibra.blog/2022/10/11/proposal-2210-3-musical-chairs/)\\n\\n\\n\\n\\n**Synopsis**: Change the way the validator selection set is chosen so that performance and cost can be optimized in a competitive way..\\n\\n\\n\\n\\n**Voting Result**: Passed with the smallest margin of any of the full proposals (\\\\+61\\\\) and showed a moderate amount of commitment in terms of voting power (191\\\\). A look at the raw data shows this proposal had the second\\\\-highest number of negative votes.\\n\\n\\n\\n\\n**Comments**: Like proposal 1022\\\\-02, this proposal presents a highly technical question that is primarily of interest to validators (existing or potential). This passed, but by the smallest margin of the entire set of proposal, and with a significant number of negative votes, indicating that this proposal is likely the most controversial of the entire set.\\n\\n\\n\\n\\n### [Proposal 2210\\\\-04 Repurpose Carpe](http://openlibra.blog/2022/10/11/proposal-2210-4-repurpose-carpe/)\\n\\n\\n\\n\\n**Synopsis**: Move the Carpe app away from building towers and use it for something else, maybe as an oracle for the network.\\n\\n\\n\\n\\n**Voting Result**: Passed by with a reasonable margin (\\\\+74\\\\), but showed the second lowest amount of commitment in terms of voting power of any of the proposals (306\\\\). A look at the raw data shows this proposal had the second highest number of voters.\\n\\n\\n\\n\\n**Comments**: A large number of voters with a low expenditure of voting power would indicate that while people had opinions on this proposal, they were not strongly held.\xa0\\n\\n\\n\\n\\n### [Proposal 2210\\\\-05 Revenue Binding Primitives](http://openlibra.blog/2022/10/11/proposal-2210-5-revenue-binding-primitives/)\\n\\n\\n\\n\\n**Synopsis**: Tells the engineering team to make 0L protocol primitives that support a variety of payment functions that will be needed for future app development their top priority.\xa0\\n\\n\\n\\n\\n**Voting Result**: Passed by the second\\\\-largest margin (\\\\+85\\\\), but showed a relatively low amount of commitment in terms of voting power (335\\\\). A look at the raw data shows that there were no votes against this proposal, one of only two to pass without opposition.\\n\\n\\n\\n\\n**Comments**: A non\\\\-controversial proposal that advocates for building tooling, this proposal passed easily.\\n\\n\\n\\n\\n### [Proposal 2210\\\\-06 Faucets for Workers](http://openlibra.blog/2022/10/11/proposal-2210-6-faucets-for-workers/)\\n\\n\\n\\n\\n**Synopsis**: Create faucet tooling for Community Wallets and others to create automated rewards.\\n\\n\\n\\n\\n**Voting Result**: Passed with the smallest margin of any of the full proposals (\\\\+36\\\\) and showed the lowest commitment of voting power of any of the proposals (191\\\\). A look at the raw data shows this proposal had no negative votes, one of only two to pass without opposition.\\n\\n\\n\\n\\n**Comments**: This proposal was non\\\\-controversial, but generated low engagement, suggesting that it is generally supported but not necessarily a top priority for the community.\\n\\n\\n\\n\\n### [Proposal 2210\\\\-07 Donor\\\\-Directed Community Wallets](http://openlibra.blog/2022/10/11/proposal-2210-7-donor-directed-community-wallets/)\\n\\n\\n\\n\\n**Synopsis**: Create better oversight of community wallets such that they are actually donor\\\\-directed, and have purpose\\\\-built multisignature features.\\n\\n\\n\\n\\n**Voting Result**: Passed with the third highest margin of any of the full proposals (\\\\+76\\\\) and showed a moderate amount of commitment in terms of voting power (354\\\\). A look at the raw data shows this proposal had only one negative vote.\\n\\n\\n\\n\\n**Comments**: The result here aligns with what we\u2019ve been hearing in community conversations, namely, that community wallets, as designed, are underperforming and need to better support more complex governance.\\n\\n\\n\\n\\n### [Proposal 2210\\\\-08 Infrastructure Escrow Fund](http://openlibra.blog/2022/10/11/proposal-2210-8-infrastructure-escrow-funding/)\\n\\n\\n\\n\\n**Synopsis**: This proposal asked voters to indicate how they wished the cost of the Infrastructure Escrow Fund to be allocated among the existing wallet holders. Voters could vote for, or against, charging each of four categories: Validators, Community Wallets, Carpe Miners, or Basic Wallet Holders.\xa0\\n\\n\\n\\n\\n**Voting Result**:\xa0\\n\\n\\n\\n\\n2. Validators: \\\\+67 (487 commitments)\\n\\n6. Community Wallets: \\\\+58 (446 commitments)\\n\\n10. Carpe Miners: \\\\+1 (147 commitments)\\n\\n14. Basic Wallet Holders: 0 (156 commitments)\\n\\n\\n\\n\\n**Comments**: There is a clear and strong preference for diluting the Validators and Community Wallets. The results of this vote will be used to create the formula used for diluting all the wallet holders, a process needed to implement the Infrastructure Escrow Fund (as per Proposal 1022\\\\-1 Final Supply).\\n\\n\\n\\n\\n## Where do we go from here?\\n\\n\\n\\n\\nIt is important to note that all the proposals presented in this process were signaling proposals, that is, they were created to help define consensus and formulate direction and strategy for the network. None of the proposals resulted in immediate changes to the network, either online or offline. Rather, these proposals form the basis for taking further action to accomplish the strategic goals defined by this vote. Given that, it is hard to categorize any of these proposals as winners or losers; rather, they all served as indicators of future direction and required significant additional effort from the community.\\n\\n\\n\\n\\nStepping back a moment and looking at the sum of the proposals on the slate:\\n\\n\\n\\n\\n* Despite some controversy displayed in the discussions around the Final Supply proposal (Proposal 2210\\\\-01\\\\), the vote revealed a clear mandate to move forward. The proposal was sweeping in its proposed changes and included (1\\\\) stopping issuance, (2\\\\) rebasing the token, and (3\\\\) creating the Infrastructure Escrow Fund. Implementing these changes would represent a significant change in direction for the tokenomics of the project. This is our strongest indication of direction from the community and therefore deserves to be prioritized.\\n\\n* Given the results of the votes on the four parts of the Infrastructure Escrow Fund (Proposal 1022\\\\-08\\\\), the re\\\\-basing should result almost exclusively in the dilution of Validators and Community Wallets, with only a token contribution coming from the Carpe Miners. Basic Wallet holders (i.e., workers, other token holders) would not be impacted.\\n\\n* Two of the proposals aimed squarely at our validator operations, Proof of Fee (1022\\\\-02\\\\) and Musical Chairs (1022\\\\-03\\\\), gave us more ambiguous results and better reflected the divided discussions that occurred in the run\\\\-up to the vote. Though both of these changes passed, it seems clear that there should be further discussion and perhaps refinement of these proposals to achieve better consensus.\\n\\n* The question of what to do with the Carpe app in light of the changes proposed above also remains open. While the proposal to repurpose Carpe (1022\\\\-04\\\\) passed, it showed a lack of commitment, which may reflect the fact that while the community recognizes that Carpe has value and that we should do something with it, no one is exactly sure what the best course of action is for the future of the app.\\n\\n* The remaining three proposals (Revenue Binding Primitives, Faucets for Workers, and Donor Directed Community Wallets), were all non\\\\-controversial, and the results were consistent with that. The low levels of commitment on proposals 1022\\\\-05 and 1022\\\\-06 would indicate that these matters, while non\\\\-controversial, are also not priorities. In contrast, the higher levels of engagement on 1022\\\\-07 (Donor\\\\-Directed Community Wallets), would indicate that this proposal should be moved forward more quickly.\\n\\n\\n\\n\\nAt the end of all this, the answer to the question \u201cwhere do we go from here?\u201d depends on whether the individual members of our community can move forward with collaborative action. The successful completion of this community strategy development process, while meaningful, is all for naught if the community does not step up and commit the resources needed to operationalize the strategy."},{"id":"/proof-of-fee-part-2","metadata":{"permalink":"/blog/proof-of-fee-part-2","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proof-of-fee-part-2.md","source":"@site/blog/proof-of-fee-part-2.md","title":"Proof of Fee - Part 2","description":"From empirical evidence over the last five years, we have seen few malicious attacks by validators; clearly something is working. We don\'t want to break something that is working. What we want to evaluate is whether we can make it sustainably work at a lower cost.","date":"2022-10-20T00:00:00.000Z","tags":[{"inline":true,"label":"PoF","permalink":"/blog/tags/po-f"},{"inline":true,"label":"Proof of Fee","permalink":"/blog/tags/proof-of-fee"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":34.405,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proof of Fee - Part 2","date":"2022-10-20T00:00:00.000Z","tags":["PoF","Proof of Fee","canonical"]},"unlisted":false,"prevItem":{"title":"2022 Governance Recap","permalink":"/blog/proposals/october-2022-governance-recap"},"nextItem":{"title":"Proof of Fee - Part 1","permalink":"/blog/proof-of-fee-part-1"}},"content":"\x3c!-- truncate --\x3e\\n\\n```\\nIn [Part 1 of this paper](http://openlibra.blog/2022/10/15/proof-of-fee-part-1/) we laid the foundations for Proof of Fee. Some of the ideas expressed there may be different from what you have seen elsewhere, and we do urge you to read that before you begin here. In Part 2 of this paper, below, we get into the mechanics and implementation details of Proof-of-Fee (PoF).\\n```\\n\\n\\n\\nFrom empirical evidence over the last five years, we have seen few malicious attacks by validators; clearly something is working. We don\'t want to break something that is working. What we want to evaluate is whether we can make it sustainably work at a lower cost.\\n\\n\\n\\n\\n## Gaming it out\\n\\n\\n\\n\\nIn part 1, we concluded that estimating the security of the network in monetary terms is not directly correlated to the financial costs of stakes. PBFT as a consensus algorithm has compelling built-in security properties. Plus, launching a PBFT network necessarily starts from a root of trust, and this can be reinforced by validator admission policies that reduce likelihood of Sybil attacks.\\n\\n\\n\\n\\nThe central question is this: How is a large bond staked by a diverse group of agents contributing to security? Is it really necessary?\\n\\n\\n\\n\\nBefore we can evaluate how the high bonding works on PBFT, we should define which actors can be Byzantine. Are we trying to be safe from the everyman who goes rogue, or a madman? The deterrence strategies you would apply in those two situations are not the same.\\n\\n\\n\\n\\nIf you goal is educating the initially honest validators on what is expected, then we would argue that swift and sure penalties are much more important than highly severe but rare penalties. When it comes to madmen, however, economic guarantees are marginal at best.\\n\\n\\n\\n\\n### Deterrence is in the mind\\n\\n\\n\\n\\nSwift and sure penalties train actors in cause and effect and teach what is expected. A quick time-out is a much better training method for wayward children than a rare but severe strapping.\xa0 In theory, high stakes penalties for unlikely events are a way of achieving compliant behavior without having to wait for the parties to learn (by way of experiencing the penalties) but they work mostly through perceptions and may easily backfire. The rare strapping, for example, may teach the child that punishment is random and parents are not to be trusted.\xa0\\n\\n\\n\\n\\nSimilarly, capital punishment is a pyschological game, not a device meant to train someone across a series of events. Moreover, for something as extreme as capital punishment to work well, it needs to be placed within a context of other swift and sure penalties. That is, the credibility of maximal punishment also depends on consistency. Catch people for spray painting graffiti and others may be deterred from more serious crimes, but let graffiti take over and all punishment will come to be doubted no matter the crime.\\n\\n\\n\\n\\nPunishments for unlikely events work within a context of swift and sure penalties for smaller events mostly by preventing good agents from \\"breaking bad\\". Normal people learn what is expected and don\u2019t doubt that big deviations will be punished.\\n\\n\\n\\n\\nSevere penalties don\u2019t necessarily deter people that don\'t evaluate the punishment in the same way (e.g., the mentally ill, the North Korean nuclear program), or engage in a repeated game with the state where the punishment is not dispensed (e.g., serial killers, organized crime, Iranian nuclear program). Policy designers may assume incorrectly that the only way to handle these situations is to ratchet rare punishments yet higher. Applying maximal punishment out of the context of learning may seem rational to deter a madman, but to the everyman it is terror and leads to distrust and learned helplessness.\xa0\\n\\n\\n\\n\\nWhat does this mean for blockchain?\xa0\\n\\n\\n\\n\\nAn attack by a sophisticated and resourced or irrational malicious actor is not going to be deterred by high bonding. In practice, slashing is never complete because of the fear this creates in normal, and normally good, actors. As implemented in Tendermint, for example, a defector does not lose their entire stake in a single \\"slashing\\" event commensurate with the damage done because that would drive out good actors. Moreover, a well-resourced attacker knows this, and isn\'t particularly deterred (and in fact could subsidize a one-time attack with winnings along the way). The solution, however, isn\u2019t to slash more.\\n\\n\\n\\n\\nThere are always madmen that want to see the world burn; economic guarantees are not effective against them. The only thing that deters the madman, at any price, is the validator admission policy, as we describe below. Modest, swift, and sure penalties will achieve what can be achieved and at lower cost than \u201ccapital punishment\u201d style slashing. We should leverage this in our favor to secure PBFT blockchains, at the appropriate cost.\\n\\n\\n\\n\\n### A town of robbers is no town at all\\n\\n\\n\\n\\nThere\'s another argument often advanced for high bonds: Humans are not inherently honest ergo, we should assume people on the internet are out to rob the chain. This may be a perfectly reasonable philosophy but, in the specific case of PBFT, it\'s unlikely to be destabilizing.\\n\\n\\n\\n\\nSilvio Micali has a thought experiment; it goes like this: Why would anyone move into a neighborhood or town where the vast majority of people were thieves? Certainly no good actor. In fact, not even the robbers would want to live there! These are places that, by definition, cannot exist. This is called the \\"honesty assumption\\" of PBFT and PBFT algorithm provides a guarantee. If you want to reorganize the already committed blocks, you\'ll need \u2154rds of the validator set to go along with it. Certainly it\'s possible that \u2154rds of the validator set could act against the will of one party or the entirety of the accounts on chain, but it begs two questions: (1\\\\) How does a network even arrive to the point of having \u2154 malicious actions? and (2\\\\) Are we sure an honest community can\'t recover from this?\\n\\n\\n\\n\\nSince PBFT networks start from a root of trust and continue to reinforce the norms of behavior, it seems that the deterrent to this problem is not economic, but rather in the validator credentialing process. The ways this is implemented are diverse. We\u2019ve seen multiple approaches, from a foundation or a company signing contracts (with testnet winners), or a decentralized vouching from the existing validators, or coin voting for validator admission.\\n\\n\\n\\n\\nMoreover, there is also a way for account holders to recover: They can fork the validators out. Forking is another deterrent to a cabal of malicious agents. If you reorg the blocks against the will of the account holders by creating a fork, it may be trivial for the account holders to continue from where the fork branched off, with a new validator set. This is considered \\"weak subjectivity\\", and informal in the eyes of certain blockchain designers, but it doesn\'t prevent it from being a real deterrent, since it only needs to exist in the mind of the malicious actor. All that effort by the madman will be for naught. (To be clear this property doesn\'t neatly generalize to all blockchain consensus algorithms).\\n\\n\\n\\n\\n### Cartels are unstable\\n\\n\\n\\n\\nLastly, advocates of high bonding rates might say it\'s trivial to turn good actors bad \u2013 you can just bribe people to join a cartel. However, that argument fails to consider that bad agents also face challenges. Coordination in adversarial space is a hard problem and this also applies to malicious agents attempting to form a cartel.\xa0\\n\\n\\n\\n\\nCartels are not monopolists, though they try to achieve the maximum profit as if they were one. The trouble with cartels is that the dominant strategy of the cartel member is to cheat, not only once, but repeatedly. One defector from the cartel can reap the rewards of the monopoly price at a cost to other cartel members (not the consumer). And cheating in the repeated game quickly destabilizes the cartel. Plus, if your cartel operates outside the law or norms, is there any reason to expect a cartel member to respect the cartel\'s agreement? We know this from the behavior of other malicious cartels (think: drugs, mafia), which are rarely stable. The stable cartels that come to mind are those rare exceptions supported by governments (think: OPEC, American Medical Association).\\n\\n\\n\\n\\nSo, if you are planning a long range attack on a blockchain, you\'d better be sure that you are the monopolist and that you control all the nodes, otherwise you will be left holding the bag. This is a very expensive proposition, and likely loss-making. The cartel argument is a distraction; though one-time colluding attacks in PBFT can happen at a cost and uncertainty to the participants, sustaining collusion is another matter.\\n\\n\\n\\n\\n## Proof of Fee: Auctioning Consensus Seats\\n\\n\\n\\n\\nGiven what we\'ve seen above, a lot of the deterrence is already baked into the nature of the PBFT game and that deterrence is largely independent of the price. The madman attack is taken care of by admission controls, not economics. The cartel scenario is a red-herring. The economic guarantees seem to only be needed to keep honest people\u2026 honest.\xa0\\n\\n\\n\\n\\nSo our provocation is this: What\'s the optimal price for the *social surplus*, so that everyone wins?\\n\\n\\n\\n\\nProof of fee (PoF) is based on a premise: Let\u2019s create equivalents of the bonding, staking, and slashing process by simply charging the equivalent cost of capital through an admission fee.\\n\\n\\n\\n\\n### Problem Definition\\n\\n\\n\\n\\nThe PoF protocol assumes that all revenues to the chain belong to all the token holders. As such, transaction fees are not a property right of the operators (validators). We assume that blockchains intend to be self-sufficient (or better), where sufficient revenues exist to pay for the consensus costs. As discussed in Part 1, because future blockspace is likely to become abundant (due to engineering advances), the blockchain must either develop other revenue streams besides blockspace, or become more cost efficient. For the cost-conscious token holders, the key question is: For a given level of security, how much do token holders have to pay to validators?\\n\\n\\n\\n\\n### First Approach: A Reverse Auction\\n\\n\\n\\n\\nOn all blockchains, nodes are competing in an auction of compute power. What if we turned the usual blockchain auction upside down?\\n\\n\\n\\n\\nOur first attempt at a delegation-less and stake-free economic system is a [reverse auction](https://en.wikipedia.org/wiki/Reverse_auction). Reverse auctions are also called procurement auctions, such that an enterprise has their orders for materials delivered at the lowest cost. In our case, the enterprise is the blockchain and the provider is the validator node.\\n\\n\\n\\n\\nOne could set up an auction as follows: At the start of an upcoming epoch (period of blocks) a node which is selling compute power (to the blockchain for consensus) states the minimum reward they are willing to receive for the services at the end of the epoch. The X number nodes with lowest bids get admitted to the validator set.\\n\\n\\n\\n\\nThe reverse auction model is attractive, namely for its simplicity. Alas, however, it is too simple. Simply agreeing to take a low fee, and subsequently being allowed to enter the validator set is not sufficient in permissionless and adversarial environments. We would really be pushing the limits on the guarantees of PBFT, since we really have the nothing-at-stake problem in this design.\\n\\n\\n\\n\\nThe limitation of the above design is that there is no actual cost to enter the agreement with the blockchain. In such a simple reverse auction, the validator can bid a low fee but never deliver on services. In a group of carefully vetted operators, this would be fine. But in an adversarial scenario, or a scenario where the abilities of the validators are indeterminate (amateurs), there should be a real cost to non-performance.\xa0 We can imagine ways in which a madman might wreak havoc in a number of ways (a \\"split brain\\" attack for instance). But as we said above, preventing this belongs in the domain of the validator credentialing. The real threat is operator incompetence. Suppose a validator bids the maximal amount, and simply forgets to start the machine at the right time. This hurts the network in a meaningful way, it will slow down and ultimately halt, and at no cost to the validator. The risks are asymmetric, and leads to a type of prisoner\'s dilemma game. Empirically this has been the greatest threat to PBFT networks: Amateurism.\xa0\\n\\n\\n\\n\\n### Pricing Carelessness With A Forward Auction\\n\\n\\n\\n\\nIn almost all markets there are entry fees, some are explicit, and some are implicit. In Bitcoin, there is a hardware capital cost. In DPoS, there is a bond. How else can we charge an entry fee?\\n\\n\\n\\n\\nAs a reverse auction is not ideal, we\'ll need to go back to an ordinary (forward) auction, where the blockchain is selling consensus seats. In this case, the validators need to know what they are bidding on, and know what the cost of non-performance is.\xa0\\n\\n\\n\\n\\nThe design is equally simple: The blockchain must determine the baseline reward it is willing to offer validators for the epoch, and validators pay to gain admission.\\n\\n\\n\\n\\nAs an example, suppose the blockchain offers 10 coins per validator every epoch and suppose that the validator is profitable at 4 coins to validate (with 4 being the real dollar cost evaluated in coins at current dollar-coin exchange rates). Validators, functioning as bidders, would then bid on the seats in consensus, e.g. pay in advance up to 6 coins, for the benefit of winning 10, and thus netting 4 coins. This is functionally equivalent to the reverse auction where the validator would bid 4 coins. The difference is that the node is bonded within the epoch. The payment to get a validator seat is final. So if the validator does not perform, their admission fee is lost and they lose 6 coins. Thus, this auction format is the equivalent in DPoS of \\"slashing\\" a part of the bond.\\n\\n\\n\\n\\nThe bond may seem low, but remember our thesis: We are only trying to keep honest actors from turning bad, and also not encourage careless operators with asymmetric risks.\xa0\\n\\n\\n\\n\\nThe disadvantage of this model is that the blockchain must set the baseline reward wisely (10 coins in the above example). If the baseline is set very wrong, it can create an uncompetitive auction. We discuss this issue further below.\\n\\n\\n\\n\\n### Thermostatic Baseline Price\\n\\n\\n\\n\\nHow can the baseline price stay within a range in which the bidders are motivated to participate, given the external market conditions? If one sets the baseline too high and not enough biders show up, the network may dilute or exhaust their reward subsidies. If the baseline becomes too low, then no bidders show up.\\n\\n\\n\\n\\nSuppose the baseline reward to validators is set too low, given extrinsic market conditions. Such a situation does not create a large implicit bond, and thus does not create an effective deterrent. For example, suppose that instead of setting the baseline reward at 10 in the above example, the reward was set to 5\\\\. Now validators will bid up to 1 for the right to earn 5 but this means that a validator that fails to validate loses only 1\\\\. Worse yet if the baseline reward falls to less than 4 then eventually no validators show up. To solve for this, a \u201cthermostatic\u201d solution could be applied: as in home heating devices, the heat increases or decreases by a certain amount to target a given temperature.\xa0\\n\\n\\n\\n\\nLet\u2019s look at an example. Let the baseline reward be BR and the cost of validation C then validators will bid up to BR-C to enter the validation set. To simplify notation we can assume that C contains an opportunity cost of capital so that if bidders are paid C they are earning a normal profit. In this case, in a competitive market, bids will rise until Bid\\\\=BR-C. (Recall from the previous example that BR was 10, C was 4 and bids rose to 6\\\\). The bid is also the equivalent bond since it is the bid which may be lost by failing to validate. Now from this perspective, there is an easy solution to setting the baseline reward: Set it absurdly high, say 1000\\\\. In this case bids will rise to 996 and validators will be extremely careful never to fail to validate since the bond is 996\\\\. The problem with this simple solution is that the higher the bond the greater the rewards to collusion and the more risk is imposed on validators. The competitive price in this scenario is 996 but even minimal collusion that brought the price down to say 900 would create very large profits and thus this model is asking for collusion. Even without collusion there may arise a situation where, for accidental or unusual reasons, there are only a handful of bidders who bid say 900 or less and thus they win the rights to earn 1000 for a pittance. In addition, a very high bid/bond means that an error on the part of the validators (\u201ctrembling hands\u201d) subjects them to large losses. Risk aversion may then dissuade bidders from bidding which in turn could make collusion easier. High fees could thus potentially put the network at risk. Low fees, however, result in too few bidders as we noted above.\\n\\n\\n\\n\\nThus, the protocol must target a bid (BR-C) which is large enough to promote good and careful behavior on the part of the validators but also small enough to not induce collusion and to withstand \u201ctrembling hands,\u201d i.e. small errors in competitive behavior or execution. Fortunately, there is a very large range under which these conditions are satisfied. Thus, the targeting need not be precise.\\n\\n\\n\\n\\nEssentially we want the bid to be large enough so that poor performance hurts but not so large as to deter bidders for fear of losing the bond nor so large as to encourage collusion. It\u2019s likely that a bond greater than 2C would be enough which would mean BR-C\\\\>2C or BR\\\\>3C and BR\\\\>5C would be plenty so we would target a baseline reward (BR) at 3 to 5 times validator costs. Costs (including opportunity costs) don\u2019t vary much over time so this could be set slowly.\xa0\\n\\n\\n\\n\\nThere are a few ways this could be implemented. Some blockchains may find it acceptable to set this manually through governance (one or two times a year), though this just creates another issue to quarrel about. It\'s possible an oracle could be used to target an extrinsic price signal, i.e. the dollar price of the reward. Though we would prefer on-chain algorithms.\\n\\n\\n\\n\\nA simple algorithm could be implemented that when the bids are persistently near 100% or 0% of the reward then the baseline may increase or decrease by N coins in the following epoch. Alternatively, something more straightforward may be possible: Target BR so that the number of bidders relative to the validator set is always large and well above the validator set. That is, BR would rise as the number of bidders fell and fall as the number of bidders rose. Again, the precision does not matter, so long as BR doesn\'t fall out of range for a prolonged period of time.\\n\\n\\n\\n\\nNote again, that because the bidders will bid more when the BR rises there is little to no danger in a large BR so long as there are many bidders and we avoid situations where BR is so high that the network cannot afford accidental large payments.\\n\\n\\n\\n\\nThe numbers, above, are illustrations. The actual numbers would need to be experimentally tested and paired with thermostatic adjustments to properly tune the design space.\\n\\n\\n\\n\\n## Implementation Details\\n\\n\\n\\n\\n### Limited Validator Set Rotation\\n\\n\\n\\n\\nThe auction should not be used to replace the entirety of the seats in the validator set. For example, if there are 21 seats available, and there are 100 candidates for the seats, it wouldn\'t be prudent to allow all the 21 seats to be replaced by highest bidders from the 100 candidates.\xa0\\n\\n\\n\\n\\nTheoretically, the problem here is that a sufficiently well funded adversary, with no experience (or perhaps even the hardware) could completely halt the network simply by creating accounts and funding them. While we think madmen scenarios are unlikely, this would just be an invitation to them.\xa0\\n\\n\\n\\n\\nAs we discussed above, operator error is the most common threat, (ou may have \u2153 of the nodes that simply were not ready, or were hit by a data center outage, or failed to upgrade, or were asleep, etc.). This problem also exists in PoS blockchains, and the most common solution to this as observed in the field is to limit the validator rotation\xa0\\n\\n\\n\\n\\nIn practice this means limiting the amount of turnover between one epoch and the next for exactly this reason. In PoF, we would have to accommodate for this as well. For example, no more than \u2153 of the new incoming validators can be of unknown \\"readiness\\". (Practically, it should be a lower number than one third to accommodate for 2f\\\\+1 errors where you might be putting your network really at the borderline of forming consensus. So perhaps \xbc is better.)\\n\\n\\n\\n\\nFortunately the solution is straightforward for PoF: Rank the maximum bidders of outgoing and prospective sets, and drop the bottom \u2153 validators from outgoing set to open up for the prospects.\xa0\\n\\n\\n\\n\\nAssuming epoch E1 and E2, and a prospective validator universe P, which is a set of all bidding validator candidates, and the respective epoch validators V1 and V2\\\\. We first fill the two-thirds of cardinality of V2, i.e,\xa0 \u2154 \\\\* V2, with *the* highest bids of V1, called continuing, denoted by C. Then we fill the set of (V2-C) with the ranked bids of P excluding C the continuing validators.\xa0\\n\\n\\n\\n\\nThis way the union is always maximizing for the highest bidders, and not endangering the network for halts by operator unpreparedness.\\n\\n\\n\\n\\nReaders might ask, why not take the most reliable validators by some metric, and then auction off the remaining \u2153 of the seats? This leads to a couple problems:\\n\\n\\n\\n\\n1. You\'re introducing a vector for gaming. A validator that is consistently the best performing will rationally bid zero. And as such this opens a Sybil issue and malicious behavior can be rewarded. Moreover, the auction is not maximizing revenue.\\n2. More importantly, we don\'t have reliable metrics to use on-chain for this. We only really know who signed and who proposed the previous block at any time. If we create a target threshold from either of these points, we introduce other undesirable properties of a network that should be plausibly neutral. In PBFT there\'s one artifact of networking which would cause the validators that are in the nearest datacenters (by network ping) to propagate their proposals and votes faster. Thus, to rely solely on the ratio of signatures or proposals creates a race to centralization.\\n\\n\\n\\n\\n### The Seats Should Be Uniform\\n\\n\\n\\n\\nThe product of the auction matters: Is it auctioning consensus power, or consensus seats of the same power?\\n\\n\\n\\n\\nThe mechanism described above is notionally for multiple units of the same product: Seats in consensus. However, BFT consensus has another feature which is voting weights, or consensus power. Every block requires a quorum to be committed where quorum is two-thirds of total voting weight. A validator selection process needs to also address the weight of each vote in reaching consensus. In DPoS systems, stakers have their\xa0 \\"consensus weight\\" determined by the amount staked. The implication of a higher consensus weight is that the nodes are able to cast more \\"votes\\" on a block, and thus have an outsized role in consensus. Layered on top of that may be an economic reward for proposers (for example, the proposer bonus in Cosmos Hub).\\n\\n\\n\\n\\nIn having different weights, especially when there is huge deviation, consensus would be reached faster by reaching a quorum with lesser participants. For instance, some PoS networks have 100\\\\+ validators but only the top 5 make the quorum.\xa0\\n\\n\\n\\n\\nOur current opinion is that all seats should be treated equally. Most BFT academic work, and deployment pre-blockchain, assume equal weights. Recent derivations, such as HotStuff, Narwhal, and BlockSTM, talk in terms of equal weight in their published academic work. It was with Tendermint and DPoS that the concept of weighting gained prominence (possibly because of an assumption that it would optimize the auction for seats by stake, which may not bear out).\\n\\n\\n\\n\\nWe think that variable votes in consensus removes one of the important sybil resistance properties of the \\"madman\\" attack described above. That said there may be a reason a blockchain wishes to give greater weight to different nodes.\xa0\\n\\n\\n\\n\\nThrough entry fees, a node could be assigned relative weights depending on the price that they bid. That is, the nodes which forgo the most payment will have higher chances of qualifying for liveness. Conversely, the nodes whose hardware and operation constantly perform the highest, will likely be able to charge higher fees, since they are not at risk of being below threshold. Auctioning a \u201cliveness bonus\u201d, so to speak, is a price signal, and there may be legitimate reasons why validators are needing to get a bonus (their nodes are harder to reach).\xa0\\n\\n\\n\\n\\nFuture research should decide if there is a meaningful optimization in having variable votes per seat, without compromising the security. Note variable votes per seat has important consequences for the auction mechanism (more detail below).\\n\\n\\n\\n\\n### Auction Formats\\n\\n\\n\\n\\nThere are multiple auction formats that should be discussed. There\'s a risk in getting side-tracked in a discussion on auction mechanisms, but fundamentally, the big picture is simple: There\'s no auction mechanism that can correct for the absence of bidders. Ensuring an ample supply of bidders that always exceeds the number of validator slots is of first order importance.\xa0\\n\\n\\n\\n\\nThe auctioneer maximizes revenue mainly by having better products. And if the product can\u2019t be improved, the auction increases revenue by adding another\xa0 marginal bidder. This needs to be highlighted: **Everyone\u2019s effort is best spent on making a better product**. The only job of the auction designer is to eliminate the worst auctions, and then pick the auction that is easiest to understand by the bidder, and appears fair. This will increase the amount of bidders, and thus revenue.\\n\\n\\n\\n\\nIn terms of picking the auction, the designer needs to\xa0 prioritize certain features, as these decisions will impact your choice of auction format and configuration. Key issues impacting that choice are:\xa0\\n\\n\\n\\n\\n* Whether to optimize for revenue of the chain?\\n* Should validators bid their true expected utility?\\n* Are seats uniform?\\n* What level of privacy is desired?\\n* Do we expect collusion from bidders?\\n\\n\\n\\n\\nThe principal decision to be made is whether the product is \\"votes\\" in consensus or seats which are all equal. Above, we recommend seats with the same consensus weight, but we will give some notes below for the auction for votes scenario.\\n\\n\\n\\n\\n#### *If All Seats Are Equal*\\n\\n\\n\\n\\nThe most important optimization as we say above is that the auction has to invite the most bidders, that is: It needs to be low friction, not require much analysis, and generally feel fair.\\n\\n\\n\\n\\n##### Vickrey-Clarke-Groves\\n\\n\\n\\n\\nThe main constraint on the auction design is whether private bidding is possible. A sealed bid, (implemented with commit-reveal) may be possible, but is likely impractical for the workflows of operators. Assuming this was an acceptable position, we could make use of incentive-compatible Vickrey-Clarke-Groves auctions. There\'s a lot to be said about VCG auctions and their ability to surface bidder preferences in a truthful manner. In blockchain applications, however, this has been impractical, so we need to consider open auction formats.\\n\\n\\n\\n\\n##### Open Nth-Price Auctions\\n\\n\\n\\n\\nThe simplest and most common auction type is a *first price auction*. Despite known tradeoffs Blockchains implement first prices often, and they seem reliable in adversarial environments. First price auctions can be conducted in the open. Bitcoin uses first price for transaction ordering. A [Generalized First Price Auction](https://en.wikipedia.org/wiki/Generalized_first-price_auction) has been historically used in online environments (ads), also for positional ordering, but it is difficult for bidders to discover optimal strategies and for these reasons is susceptible to manipulation (reducing revenue to auctioneer) based on its non-truthful properties.\\n\\n\\n\\n\\nA [Generalized Second Price Auction](https://en.wikipedia.org/wiki/Generalized_second-price_auction) (also a variation of a Vickrey Auction), seems similar to a Vickrey auction but is misnamed since the truthful properties of bidding are not always preserved in GSP. (VCG is the true generalized second price auction.) For similar reasons, the bidder has to work on figuring out where they are placed with other validators. In practice, it works reasonably well, however, and revenues are typically as high as in VCG.\\n\\n\\n\\n\\n##### Uniform price auctions\\n\\n\\n\\n\\nWe recommend a single price auction for the case of uniform seats. ([Also called treasury auctions,](https://en.wikipedia.org/wiki/Single-price_auction) since this format is used in U.S. Treasury market operations.) The last ranked qualifying bid sets the price for all validators.\\n\\n\\n\\n\\nThis may be counter intuitive, but even though everyone pays the *lowest* accepted bid the revenue to the auctioneer has been demonstrated to be similar to other auction formats such as the first price format in which everyone pays their own bid. In essence, under first price people shade their bids down but in a uniform auction bids are higher and it works out that on average revenues are the same. The major advantage of uniform-price auctions is that it\'s easier for the bidders to know what to do: They can bid their true preferences since they will never overpay. Gaming may not be worth the effort. It\'s an elegant solution, and very easily applied to blockchain contexts, though it would require that all seats have the same properties.\\n\\n\\n\\n\\nUniform price auctions are usually done as a sealed-bid, however it appears that open auctions with repeat bidding, with bids that cannot be retracted (lowered), will approximate the revenue of sealed bids. A reserve price also helps prevent non-truthful bidding.\\n\\n\\n\\n\\n#### *If Selling Votes in Consensus*\\n\\n\\n\\n\\nIn the case of auctioning variable votes in consensus we have multiple units of the product, and the bidder can buy multiple ones. Typically a [sealed multiunit auction](https://en.wikipedia.org/wiki/Multiunit_auction) would be recommended. Though we have the same privacy issues described above for VCG. The multi-unit auction and single price auctions have a winner take all problem, where one bidder can take all the votes available in consensus in a single bid: if you know the highest price you can outbid and take all\xa0 votes available.\\n\\n\\n\\n\\nGiven these issues we should consider nth-price auctions. A generalized first price auction (described above) would be the alternative to experiment with. This format gives the bidder the value that they were willing to pay. It is also practical for blockchain environments and can be played openly, but not perfectly susceptible to collusion with a limited amount of bidders.\xa0 If they were to pay a lower price than what they bid (as in a second price auction), the incentive is to vote only above the remaining votes, possibly shading the bid.\xa0\\n\\n\\n\\n\\n### Negative Fees\\n\\n\\n\\n\\nNegative fees are possible, and might be allowed in PoF since they are a relevant price signal. As described above, if bidders are consistently on average bidding 100% of the reward, this means that the reward is low, and we might be losing validators because we are not paying the opportunity cost. If 100% was the limit, it would be hard to discover how much we are underpaying. That is, it might take longer for a thermostatic mechanism to adjust. Said differently: Thermostatic baseline pricing allows for negative fee price signaling.\\n\\n\\n\\n\\nNegative fees should be avoided if there is no thermostatic adjustment, due to the risk of making validators compete on MEV frontrunning. Validators may engage in frontrunning, and as such should pay for it \u2013 PoF allows for this. It becomes something of a detractor for those who try to gain an edge with MEV.\xa0\\n\\n\\n\\n\\nIn another situation, it\u2019s conceivable that MEV might become widespread, and negative fees would force validators who are not engaging in front running to do so in order to remain competitive. PoF is not a solution to MEV; this will eventually be resolved through engineering advances in transaction inclusion design (e.g. proposer and validator separation). Until this gets solved, the blockchain can monetize some of the MEV.\\n\\n\\n\\n\\nIf negative fees are permitted, there must be lower bounds, even though negative fees means more revenue for coin holders until the thermostatic adjustment kicks in. Without limits, it would be trivial for a sufficiently funded Byzantine adversary to take all the seats (or consensus power depending on auction) in a given epoch.\\n\\n\\n\\n\\n## Discussion\\n\\n\\n\\n\\n### Ergonomics\\n\\n\\n\\n\\nThe greatest benefit of PoF is that it is simple. Every actor has a very simple instruction on what to do:\\n\\n\\n\\n\\n* Holders: Just hold. You are losing nothing by being passive.\\n* Validators: Bid what it\'s worth to you.\\n* Apps: Developers can develop scenarios where the coin is used in the app, or held, without risking its loss of value from dilution.\\n\\n\\n\\n\\nThere are no secret handshakes, it doesn\'t require being able to become connected to capital to fund your stake. Historical DPoS networks have started by using a company or foundation sponsoring the initial stakes of validators (and this is often hidden information). PoF removes this out-of-band game. It not only provides an open opportunity to prospective validators, it\'s optimal for the network: The validators must compete on price, and not pre-existing business relationships.\\n\\n\\n\\n\\n### Bonding\\n\\n\\n\\n\\nThe greatest question about PoF is if it is safe. Put differently, is the inter-epoch bond (the entry fee) a sufficient deterrent.\xa0\\n\\n\\n\\n\\nIn DPOS systems, very large bonds are placed to disincentivize, via the cost of capital of the parked coins combined with the threat of slashing. These costs appear to work. But to what extent is the cost too high? The bond and expense of a validator in DPOS is measured in the collateral and the expense of the cost of capital during the epoch. This cost can be orders of magnitude greater than the profit of the validator during the epoch.\\n\\n\\n\\n\\nThe trap is that, in DPOS, the answer to the question of how much of a bond is needed is usually \\"more\\". Modeling this is an exercise fraught with assumptions. Above we argue that the baseline \\"\'honesty assumptions\\" of BFT and the empirical evidence show that slashing large stakes is not needed. Notably, Avalanche blockchain is a Proof-of-Stake network without slashing.\\n\\n\\n\\n\\nPoF has no slashing except for losing the bid, which is effectively a bond. The question PoF asks is whether that bond needs to be 1,000X the profit, or if by slashing smaller stakes (i.e. the bid) repeatedly, if need be, we will have the same deterrence on less-than-competent validators.\\n\\n\\n\\n\\n### Delegation\\n\\n\\n\\n\\nA notable feature of Proof of Fee is that there is no delegation. Delegation in POS proposes to solve two issues: (1\\\\) how to distribute rewards broadly, and (2\\\\) how to have economic agents participate in validator selection.\\n\\n\\n\\n\\n#### *Less investor rent-seeking*\\n\\n\\n\\n\\nWe assume with DPOS that all rewards are distributed to the \\"stakers\\" of the validator, and that a marginal fee (usually around 3-5%) is paid to the validator\'s operator. Historically, this means the initial stakes are set up by investors from conventional venture capital or, until about 2019, \\"retail\\" market ICOs. As we stated earlier, there are social effects to having this investor class receiving rents from future depositors.\\n\\n\\n\\n\\nIn PoF, the principal property is that all coin holders are effectively stakers of the entire validator set. This is because PoF removes delegation and the investor class. While there are opportunities for capitalists in PoF, such as financing entry fees, this operates much more like a type of receivables financing rather than a preferred shares early investor financing. There could be no broader distribution of excess rewards. So, while PoF welcomes capitalist financing, it does not depend on it to get off the ground, and doesn\'t promise rents into perpetuity above and beyond what other coin holders receive.\xa0\\n\\n\\n\\n\\n#### *Participation in Validator Selection*\\n\\n\\n\\n\\nValidator selection is an issue on PBFT chains. PoF and DPOS have similar issues when there is no mechanism for selecting validators beyond economics, i.e. the party with the most economic budget can join the validator set.\\n\\n\\n\\n\\nA PBFT network is born from a group of validators, and the social norms of those validators propagate to subsequent participants. In contrast, PoF leaves the question of validator selection open, allowing for variations of delegation to exist, for example:\\n\\n\\n\\n\\n* On-chain or off-chain vouching mechanisms for validators will be desired by most communities.\\n* Delegation, whereby validators may receive loans from different agents to pay for entry fees.\\n* A community may even be willing to risk adversarial nodes (e.g. MEV) in consensus for a while. We would expect that such behavior would quickly cease to be attractive as participants are outbid by honest agents.\\n\\n\\n\\n\\nThe DPOS hypothesis is that the holders of coins are good estimators of validator \\"quality\\" for the network. This is actually a public goods provision problem: A free rider problem. Estimating the abilities and usefulness of a validator is valuable to the network, but someone must pay for it, and neither end-user nor validator has the incentive to pay to create that information.\xa0\\n\\n\\n\\n\\nThe DPOS hypothesis is that staking is a good heuristic. The trouble is that the game forces operators to have a distributed group of economic agents wager on which validator they should be a party to. Empirically, this leads to a race from operators to offer \\"rebates\\" and negative commissions to users. Additionally, in practice, many stakers are in fact passive and allow their virtual asset service provider (i.e. Coinbase, Binance, etc.) to choose the destination of the delegation (usually their own nodes). On the part of the account holder, this is a perfectly rational decision in response to asymmetric information about the blockchain\'s condition. It\'s not entirely obvious that there is a high signal from the stakers on validator selection. Do we really know if we are picking the best, most performant and honest validator set? There are commentators in the field that say that the opposite often happens.\\n\\n\\n\\n\\n#### *Delegation increases Costs*\\n\\n\\n\\n\\nOur hypothesis is that the cost of consensus is not only higher on non-staked depositors in DPOS, but also it is higher globally. That is, for the transaction fees of the chain to adequately cover the security budget of consensus, the fees need to be sufficient to cover the opportunity costs of not only the operator, but also of the stakers.\xa0\\n\\n\\n\\n\\nThis means that higher transaction fees are needed than in the absence of delegation, and this picture is further complicated when issuance is needed to supplant that deficit in transaction fees. Non-staked coin holders are disadvantaged by this design.\\n\\n\\n\\n\\n### Law\\n\\n\\n\\n\\nA final point to mention here is regulatory profile. This topic is of increasing relevance to actors in this sector and DPoS needs to be considered in light of what is known. There\'s a long discussion to be had on whether regulatory issues are outside of protocol or not, that is, should regulators be considered agents in your game and is regulation an attack vector. Regardless of your views on that, DPoS clearly has a heightened regulatory profile due to the presence of various approaches to pooling, lending, and equity that variations of DPoS apply. Proof of Fee and its cost to enter the service market is more distinct, in that it does not rely on overt capital pooling mechanisms.\\n\\n\\n\\n\\n## Conclusion\\n\\n\\n\\n\\nThe PoF design is upside-down from mainstream blockchains: Usually the protocol determines the price that is right for each validator, and the validator can choose to enter the validator set. As such it needs to make assumptions about private information of the validator, and so the validator is left with a binary choice: Take it or leave it. Over the very long term this may approximate opportunity cost, but with the practice of most blockchains heavily weighting rewards to early participants, the blockchain usually errs on the side of overpaying for security. In PoF, the onus is on the validator to reveal the correct price of consensus.\\n\\n\\n\\n\\nThe above proposal starts with the assumption that PBFT networks are theoretically resilient before economic guarantees are applied: They a) have a high bar for transaction reordering which is easily caught with cryptography, and b) walk a trusted graph of nodes from the genesis. As such those chains have a higher safety profile than Nakamoto consensus for many theoretical threats. As for economic guarantees, DPOS on PBFT is cheaper than PoW with Nakamoto consensus.\\n\\n\\n\\n\\nWith PoF we may be able to make PBFT even more cost effective for the chain, by safely removing delegation, which adds costs and taxes the less-informed and the accounts that are otherwise restricted from staking. If anything, our conclusion is that DPoS may be a local maximum, and there is still further experimentation to be made on economic guarantees for PBFT consensus.\\n\\n\\n\\n\\nProof of Fee, with its emphasis on reducing the cost of security to a market-driven minimum, provides a new mechanism for blockchains concerned with building sustainable business models and for those concerned with maintaining greater equity among the participants in their ecosystem. We think this is a first step to creating networks that the mainstream population actually want to belong to."},{"id":"/proof-of-fee-part-1","metadata":{"permalink":"/blog/proof-of-fee-part-1","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proof-of-fee-part-1.md","source":"@site/blog/proof-of-fee-part-1.md","title":"Proof of Fee - Part 1","description":"The Cost of Consensus","date":"2022-10-15T00:00:00.000Z","tags":[{"inline":true,"label":"PoF","permalink":"/blog/tags/po-f"},{"inline":true,"label":"Proof of Fee","permalink":"/blog/tags/proof-of-fee"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":17.71,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proof of Fee - Part 1","date":"2022-10-15T00:00:00.000Z","tags":["PoF","Proof of Fee","canonical"]},"unlisted":false,"prevItem":{"title":"Proof of Fee - Part 2","permalink":"/blog/proof-of-fee-part-2"},"nextItem":{"title":"Proposal 2210-2 - Proof of Fee","permalink":"/blog/proposals/proposal-2210-2-proof-of-fee"}},"content":"\x3c!-- truncate --\x3e\\n\\n## The Cost of Consensus\\n\\n\\n\\n### TL;DR\\n\\n\\n\\n\\nAs an alternative to the (near-universally deployed) Delegated Proof of Stake (DPoS), we propose Proof of Fee (PoF), a sybil resistance technique designed natively and with consideration of the benefits and tradeoffs of PBFT consensus from empirical experience.\\n\\n\\n\\n\\n* Profits to blockchains are slim to non-existent. Low consensus costs are foundational for any chain that wishes to provide consumer surplus and profit to coin-holders; where excess winnings of the chain can be distributed to *all* account holders without preference to an investor class of \\"stakers\\".\\n* In PoF the cost of consensus is lowered maximally to the *operator opportunity cost*; with such an approach, the social cost of dilution through issuance is minimized.\\n* Validator seats are auctioned at each epoch, such that the validators private valuation of rewards, MEV, breakage, and governance is revealed.\\n* PoF coins have superior ergonomics. Every actor has a very simple instruction; no staking, no delegation, no yield games, no slashing.\\n\\n\\n\\n\\n\\n```\\nBefore we dive into the mechanics of Proof-of-Fee, in Part 1 of this paper we lay some foundations which may be different from what you have seen elsewhere. [Part 2 of the paper](http://openlibra.blog/2022/10/20/proof-of-fee-part-2-a-proposal/) gets into the mechanics and implementation details of Proof-of-Fee (PoF), an affordable sybil resistance technique native to PBFT consensus.\\n```\\n\\n\\n\\n## Why Not Delegated Proof of Stake?\\n\\n\\n\\n\\nWhile the purpose of the document is not to dissect DPoS, what follows\xa0 is the briefest context\xa0 on reasons why DPoS may not work for a blockchain\'s community.\xa0\\n\\n\\n\\n\\nA meaningful issue is the \\"ergonomics\\" of the token, that is, how do humans interact with it. End users may be unsophisticated and not know how to stake. They may have coins on an exchange which does not offer staking services. The coins may be in escrow in an application\'s smart contract, or across a bridge. Some of these issues are surmountable if there were sufficient education and infrastructure, but in the meantime the result is a disparity between the percentage of tokens staked and the percentage of account holders. A large percentage of the token supply may be staked (by whales and the savvy coin holders), but it represents only a small number of the total wallets.\\n\\n\\n\\n\\nModern DPoS blockchains are also universally deployed with \\"inflation\\" or issuance of new coins to subsidize the validator operators and their stakers. This may be necessary because transaction fees from producing blocks are far lower than the validators deem acceptable to provide their services.\\n\\n\\n\\n\\nThe result is that the accounts which are not staking are effectively paying a fee to the stakers. This means usually the retail investors are paying a fee to keep an account on the chain (a wealth tax) often to the founding members of the chain (venture capitalists and developers). This is not a widely advertised property of such chains.\xa0\\n\\n\\n\\n\\nPromoters of the chains may say that this is transitory, that transaction fees will one day catch up, but this should be viewed with some skepticism. Looking forward to the next ten years, the cost of each state transition on a blockchain will drop radically due to secular engineering advances (e.g., parallelization, mempool optimization, sharding, layer 2, etc.); given a trend towards commoditization, prices tend to drop to marginal levels. Given the likelihood of a paucity of revenue from transaction fees, DPoS blockchains may be structurally and permanently in the business of taxing the depositors.\\n\\n\\n\\n\\nThere is also some debate around the \\"delegation\\" component of DPOS and whether it is serving its purpose. Delegation is expensive as it adds to the cost of consensus (because now there are more people, and more opportunity costs, that need to be compensated). The cost must achieve the goals of plausible neutrality (decentralization) and select for ideal validators. Instead, the empirical evidence of what delegation does is select for the parties that can accumulate capital (e.g. large centralized exchanges). That behavior does not necessarily align with achieving the goals.\\n\\n\\n\\n\\nLastly, the staking requirements may be excessive, inefficient uses of capital. One should ask the question: Does the bond really need to be 1,000 to 1,000,000 times the reward of an epoch? Given that L1s have not empirically seen slashing of large stakes from malicious attacks, the level of bonding is disproportionate to the need (more below on nothing-at-stake issues).\\n\\n\\n\\n\\nWe start from the assumption that more exploration needs to be done on economic guarantees for modern blockchains, which are mostly all based on PBFT and derivations thereof. Proof of Fee is proposed as an experiment.\\n\\n\\n\\n\\n## Validator Economics\\n\\n\\n\\n\\nSince validators are the largest cost of a network, we need to clearly understand their costs and their expected utility from participating in a network.\xa0\\n\\n\\n\\n\\nValidators have a private valuation (*expected utility*) of a seat in consensus. The same validator has a private opportunity cost for the work it provides. If the expected utility is greater than the total costs, including opportunity cost, then a rational validator should participate in consensus.\\n\\n\\n\\n\\n### Validator Costs\\n\\n\\n\\n\\nOne of the roles of protocol engineers is to lower the hard costs associated with being a validator; make the tools work reliably, make the node software use less hardware resources, and provide greater automation and monitoring.\\n\\n\\n\\n\\nTechnical matters, however, cannot address all of the costs of the validator; there are also opportunity costs. The time it takes for the staff to operate the nodes, research, participate in governance, and do business administration could be used for other purposes (on other chains). Additionally, if there is a financial cost such as staking, then that value could always be used elsewhere, staked elsewhere.\\n\\n\\n\\n\\nOpportunity cost is out of the control of protocol engineers and designers, it is a feature of the global markets (labor, tokens, compute, energy, etc.).\\n\\n\\n\\n\\n### Validator Utility\\n\\n\\n\\n\\nGiven that the opportunity cost is extrinsic, profitability for the validator (and the blockchain) is created by the business environment of the blockchain. Some of the factors that contribute to the private assessment of the utility of the validator seat are tangible and easily measurable (transaction fees), others are intangible and highly subjective (governance roles).\\n\\n\\n\\n\\n#### *Transaction Fees*\\n\\n\\n\\n\\nMost blockchains describe transaction fees as a title (property right) of node operators. (Note in Proof of Fee we take the view that transaction fees are a title of the coin holders, more on that later). The transaction fees flow by default to network operators. Most often those fees are far lower than what those same validators are earning from network subsidies.\\n\\n\\n\\n\\n#### *Subsidies*\\n\\n\\n\\n\\nMost blockchains provide subsidies in addition to transaction fees. This is supposed to supplement the validator\'s earnings while bootstrapping the network and the transactions are insufficient. Even in 2022 the most established blockchain, Bitcoin, generated only a fraction of earnings from transaction fees: Roughly 1% (i.e., roughly 99% comes from subsidies - see the chart, below).\\n\\n\\n\\n\\n![](https://lh4.googleusercontent.com/IDSFhHIiMq_FQMvE7JKvK9tlUD9pKIRvXl-XJ_aDk5U2bur44IjQAQLx41gfWYUn6xOKHTKMkrR1Y2x--7UguUH0L-WlUJhpiW92PRzTEda8Ix8_uo_4HWSU3vsP1zMUl-IsbKcAR4LpyuihYRg6mN5pkX-gkBzwWr3OiJmDqXBcAlm5kYsc5kTu)\\n\\n\\n\\n\\nSource: [TheBlock.co](https://www.theblock.co/)\\n\\n\\n\\n\\nAs a matter of practice, subsidies are almost exclusively newly issued network equity, and as such are dilutive. Meaning, subsidies are a cost to depositors on a blockchain due to the reduction in their percent equity. Assuming a network with a constant market-cap valuation (which we must do from a unit-economics analysis), new issuance to the miner which produced security, is a reduction in value to anyone who didn\'t receive a new coin. Additionally, this new equity is financing the current security needs by time shifting future earnings from transaction fees (presumably, unless new revenue models are discovered).\\n\\n\\n\\n\\nAll known blockchains are loss-making in this regard. While Ethereum makes some claims about becoming profitable, it remains to be seen whether this can be sustained over more than a brief period (, and there are at least a few pundits out there who are questioning that claim).\xa0\\n\\n\\n\\n\\n#### *No-Show Rewards*\\n\\n\\n\\n\\nAnother aspect of validator utility to consider is no-shows from other validators, that is, drop-outs from competitors. When a validator is successful in the validator set, and one or more of its peers fails in consensus, there is a surplus of transaction fees (or subsidies) that are available to it. Meaning, the pool of rewards within an epoch is greater than what was nominally attributable to the validator at the start of the epoch. We separate this from the topic above because chance is involved and part of the utility is a wager on the success of the peers.\\n\\n\\n\\n\\nThis is relevant because even if validation is nominally not profitable from transaction fees or expected subsidies, the validator may see value in \\"staying in the game\\" in case another node falls out.\\n\\n\\n\\n\\n#### *MEV*\\n\\n\\n\\n\\nMEV is a category of earnings that a validator can create by engaging in different types of frontrunning as it prepares transactions into blocks. As of 2022, this has become an important source of revenue for many operators.\xa0\\n\\n\\n\\n\\nThough MEV seems to be becoming acceptable in some circles, when viewed through another lens, it can be argued that engaging in MEV violates the spirit of the agreement between validators and users. Validators are employing their access to insider information to game the system. From that perspective, MEV is an attack on the integrity of the system. (You can view a compilation of MEV attacks documented at [https://www.mev.wiki/attack-examples](https://www.mev.wiki/attack-examples).)\\n\\n\\n\\n\\nFrom 2021 to 2022, the tools for engaging in MEV attacks have become commoditized on Ethereum, and the cumulative costs approach $700M taken from users.\\n\\n\\n\\n\\n![](https://lh6.googleusercontent.com/J6P-cUzicXGsCa6TyeCe8YmYykkYsOKnZpB5EQ1G6IvbG-rWc-b1JE98Blvhfz1yHsdA02I19Y34R8xSib4v1JKFNcqnPI42hgi5tqXFLY-9n2fFe7N6ZafPT4f-6-DUUByYx4D3tGR0UYn_SYhoX61inTYU8zl02joNeunR5oDsBq5N-3oZIKPJ)\\n\\n\\n\\n\\nSource: https://explore.flashbots.net/\\n\\n\\n\\n\\nMEV can be significant. In the early days of the Ethereum Post-Merge, as the cost of consensus went down, the share of MEV became higher. In September 2022, post merge, the MEV would average $100K, per day, while earnings from subsidies was $2M and transaction fees roughly $700k. Though on certain days, there are worrisome outliers, on September 27th 2022, the total subsidies paid to operators was $2\\\\.14M, while Tx Fees was $0\\\\.67M and the MEV was $1\\\\.5 M, that is 50% extra earnings over expected in-protocol earnings. (see, [https://www.theblock.co/data/on-chain-metrics/ethereum](https://www.theblock.co/data/on-chain-metrics/ethereum)).\xa0\\n\\n\\n\\n\\nIn the long term there may be technical solutions to MEV attacks, such as the block producer and proposer separation seen in Ethereum (Flashbots MEV-Boost Relay). There may also be solutions on the application layer for \\"tricking the bots\\" (see: [https://www.mev.wiki/attempts-to-trick-the-bots](https://www.mev.wiki/attempts-to-trick-the-bots)), and for fun see some applications\' mousetraps: ([https://www.coindesk.com/tech/2021/03/22/bad-sandwich-defi-trader-poisons-front-running-miners-for-250k-profit/](https://www.coindesk.com/tech/2021/03/22/bad-sandwich-defi-trader-poisons-front-running-miners-for-250k-profit/))\\n\\n\\n\\n\\n#### *Governance*\\n\\n\\n\\n\\nValidator utility also includes the exercise of governance rights. Validators have outsized roles in governance (parameter changes, state machine upgrades). In fact, it may be said that validators hold the only \\"hard power\\" governance. Validators can always coordinate to apply a write to the database and that control over the protocol gives them de facto power to set policy. Most chains try to apply lower friction ways of other stakeholders changing policy, however ultimately the validator has the last say (or veto) on policies. Even if there are other governance mechanisms on-chain, validators may in collusion reject such transactions which trigger an upgrade (more below on types of malicious behavior). Resolving this balance of power is not the topic of this paper; suffice to say that the validator can reasonably have a private valuation for this governance role.\\n\\n\\n\\n\\n## Cost of Consensus\\n\\n\\n\\n\\nConsensus is a shorthand for getting a database transaction approved, though there is some confusion in equating a consensus algorithm, and a sybil resistance mechanism. Usually when we refer to cost of consensus we mean both inputs. Proof of stake was an evolution in reducing the cost of preventing sybil attacks, in both reducing the hardware costs in preventing attacks from malicious actors.\\n\\n\\n\\n\\n### PoW Sybil resistance\\n\\n\\n\\n\\nNakomoto consensus (invented for Bitcoin) relies on the longest chain principle, but it depends on Proof of Work (PoW) for sybil resistance. The longest chain principle helps in sequencing blocks of transactions, but not just anyone is allowed to do that. PoW as an identity mechanism says the block is proposed by the largest pool of CPU power. The more the CPU power of a pool, the more likely they get to propose the next block and hence, better rewards. As long as most CPU power rests with honest nodes, they outpace Byzantine actors by proposing more blocks.\xa0\\n\\n\\n\\n\\nOver time, the demands for computing power kept rising from CPUs to GPUs to ASICs. As a result, the capital for infrastructure and the recurring cost of electricity resources kept growing, leading to increased costs for consensus (besides energy we have cost of capital).\xa0\\n\\n\\n\\n\\n### What PoS solves and the Nothing-at-stake problem\\n\\n\\n\\n\\nProof of Stake (PoS) addresses Sybil attacks using native tokens as a stake in the system in place of the capital requirements of the hardware. This approach significantly lowers the cost of sybil attack behavior compared to Nakomoto consensus plus PoW due to a drop in the cost of computation (since no proof of work puzzles need to be solved).\xa0\\n\\n\\n\\n\\nHowever, this reduced cost could lead to nothing at stake problem wherein validators could behave arbitrarily (see, [Vitalik\'s original](https://blog.ethereum.org/2014/07/05/stake) description of the nothing at stake problem). In short: It\'s cheap for validators to create forks of the network, for example in a long range attack creating many plausible forks that in the future may be presented at the canonical fork. And for this reason, the earliest DPoS chains implemented high deposits and \\"slashing\\" when double-signing was occurring. As we will see later, there has been debate as to whether the threat of the penalty has any effect, or if the value of the bond is actually the cost-of-capital of the parked coins, thus negating that there is really a nothing-at-stake issue.\\n\\n\\n\\n\\nDPoS can be applied to numerous consensus algorithms (including Nakamoto, though not plausibly). The most well known is Tendermint PBFT implementations (or derivatives of Cosmos Hub), but there are many others in the wild.\\n\\n\\n\\n\\nOur concern is narrower: How economic guarantees interacts specifically with PBFT and its derivatives.\\n\\n\\n\\n\\n### Profitability\\n\\n\\n\\n\\nIf a network is profitable it will return value to coin holders. For this to happen, the revenue of the blockchain\'s products must be greater than the costs. That is, there can be no issuance of coins to fill the gap between what end-users paid for services, and the different costs of goods sold (the validators). As of 2022, there has never been a reliably profitable blockchain.\\n\\n\\n\\n\\nCurrently the infrastructure costs of most blockchains are equal to the cost of consensus (i.e, only nodes and miners are paid).\xa0 The true cost of consensus, as noted above, is not really technical or resource bound on post PoW chains; it\u2019s the sum of the opportunity cost of validators. Validators have other means of using their time and compute resources to make money. Assuming a security guarantee of *S*, the validators have a cumulative opportunity cost of *C* (we don\'t assume these to be equal, or even necessarily correlated).\\n\\n\\n\\n\\nDuring bootstrapping of a network the relation between opportunity cost and issuance is indeterminate, since the network is discovering its value. In **steady state** however, the costs to the network should be the lowest possible (approaching the opportunity cost of node operators), such that the costs can be more readily covered with revenue. If the revenue cannot cover the cost of security, historically, chains have covered the shortfall by charging fees to account holders; those fees come in the form of dilution through issuance. Put another way, they pass through the costs to the account holders.\\n\\n\\n\\n\\nChains can only provide security if the opportunity cost of a sufficiently non-colluding validator set is being met. Chains can only cover those costs if they are solvent (they have revenue). The chains can finance the deficit with issuance, but this is also a tangle since it can only have value if it is long-term solvent (by eventually having revenues greater or equal to security costs). Another way to think about it: Issuance is financing; it is only shifting the future revenues to the present validators.\\n\\n\\n\\n\\n### PBFT Further Lowers the Cost of Consensus\\n\\n\\n\\n\\nProof of Stake is the dominant method of sybil resistance for PBFT chains. Proof of stake designs, however, predate implementation of PBFT consensus. The specifics of PBFT chains allow for different economic guarantees but, for historical reasons, those have not been fully explored. Moreover, there are some misunderstandings about the total security guarantee of PBFT chains in relation to economic costs.\\n\\n\\n\\n\\n### Background on PBFT\\n\\n\\n\\n\\nThe Byzantine Generals problem was posed four decades ago in 1982\\\\. The problem it addressed was how to reach a consensus among participants who might not necessarily trust each other and could have Byzantine failures. Reaching consensus facilitates state machine replication among distributed systems, where Byzantine failure is any arbitrary behavior, including intentional and unintentional behavior such as crash failures, collusion among participants, and software bugs. A solution to this problem is Byzantine fault-tolerant (BFT) consensus algorithms, a family of consensus protocols for distributed systems that provide both safety (\u201cbad things don\u2019t happen\u201d) and liveness (\u201cgood things do happen\u201d) guarantees.\xa0\\n\\n\\n\\n\\nThe early BFT protocols assumed synchrony (i.e., synchronized clocks); that expectation can be challenging to obtain practically on the internet. PBFT is the first prominent practical solution to the Byzantine Generals problem. PBFT found its application in safety-critical systems, such as aircraft and submarines, where hardware is complex and may become unreliable in unpredictable ways, sometimes in hostile environments. Over the past two decades, we observed numerous advances to PBFT protocols with advances in networking and cryptography. These advances have significantly improved performance, measured throughput (tx/sec), and latencies.\xa0\\n\\n\\n\\n\\nBlockchains, where trust and security are critical, can leverage the underlying correctness guarantees of PBFT protocols. One downside, however, is that PBFT protocols assume a committee of participants and therefore can face Sybil attacks where a single participant has created multiple identities. To address this challenge, mechanism designs for establishing identity and economic incentives with guarantees from game theory are often necessary. One such mechanism widely used in blockchains is Proof of Stake, wherein anyone with native tokens in the system stakes their assets to become participants in the network. We\'ve pointed out some of the issues with this sybil resistance approach, above.\\n\\n\\n\\n\\nHistory won\'t end with PBFT, there may be other consensus innovations in the future. For our purposes we assume that the technical cost of consensus (CPU, networking, disk) is a domain of computer science and that the lowest hanging fruit has already been plucked, absent a major breakthrough in the Byzantine Generals Problem.\xa0\\n\\n\\n\\n\\n### Walking the graph: The Disconnect Between Security and Cost\\n\\n\\n\\n\\nLet us consider the common threat scenarios, relative to PBFT:\\n\\n\\n\\n\\n1. Malicious transactions : Impossible unless signed by the user. One cannot append malicious transactions even if they have a majority. State machine replication would not let this happen and is guaranteed by cryptography.\\n2. Reverse/delete blocks after finality: Leads to another fork, means abandoning the current chain. For that fork to continue it requires a\xa0 2/3rd majority on each block of the new fork.\\n3. Malicious writes: Requires 2/3rd of nodes to approve a forced malicious write. This also requires coordinated action among the malicious validators and cannot happen with state machine replication.\\n\\n\\n\\n\\nEmpirically from approximately four years of PBFT permissionless networks in the wild, there is scant evidence of malicious writes to a database. One possible explanation for this may be the fact that chains are built by \\"walking\\" from a trusted root. All known blockchains using PBFT require starting up from a \\"genesis set\\". And usually this involves participating in a community (usually a company) and developing offline reputation. In few such networks are the validators anonymous.\\n\\n\\n\\n\\nMoreover, in PBFT there are games outside of consensus that increase the cost to authenticate (create reputation), such that amplification of attacks from performant malicious nodes becomes more costly. Systems can add other costs which then work in concert to create unsustainable costs for the attacker. There are a broad range of experiments in this area related to reputation, validator set accession, and disincentives for malicious behavior.\\n\\n\\n\\n\\nMitigating attacks is not obviously mapped to economic costs. And economic costs will not exclusively deal with those attacks. Any analysis of cost paid for security versus the estimated dollar value of a safe transaction to send, are hampered by the noise of the effects of the reputation layer, which is very varied in the field.\\n\\n\\n\\n\\nReputation and validator admission are high hurdles in PBFT chains, which is very different from Nakamoto consensus (which assumes no trusted root). But given that many of the security guarantees are arguable coming from \\"walking the graph\\", it seems that there may be optimizations in reducing the overpayment.\xa0\xa0\\n\\n\\n\\n\\nThe validators must receive a payment for their services. The challenge for all token holders is determining what is the correct fee to pay operators given that a) validator opportunity cost is extrinsic to chain b) the validators preferences (utility) is private.\\n\\n\\n\\n\\nIf blockchains underpay, trust from the users goes down as fewer nodes participate. As a result, the security guarantees for halts and writes go down, and the subjective political neutrality of the chain is lowered. While perhaps a reasonable but imperfect assumption, that more payment always increases security, the designers of blockchain economics usually err on the side of overpaying for consensus.\\n\\n\\n\\n\\n\\n```\\nThis is the end of Part 1. [In Part 2](http://openlibra.blog/2022/10/20/proof-of-fee-part-2-a-proposal/), we will explore the mechanics and implementations of an alternative approach, Proof of Fee.\\n```"},{"id":"/proposals/proposal-2210-2-proof-of-fee","metadata":{"permalink":"/blog/proposals/proposal-2210-2-proof-of-fee","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-2-proof-of-fee.md","source":"@site/blog/proposals/proposal-2210-2-proof-of-fee.md","title":"Proposal 2210-2 - Proof of Fee","description":"Proposal Type: Signalling","date":"2022-10-13T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":5.02,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-2 - Proof of Fee","date":"2022-10-13T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proof of Fee - Part 1","permalink":"/blog/proof-of-fee-part-1"},"nextItem":{"title":"Proposal 2210-7 - Donor Directed Community Wallets","permalink":"/blog/proposals/proposal-2210-7-donor-directed-community-wallets"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: 0o-de-lally\\n\\n\\n\\n\\n###### Date: 13 October 2022\\n\\n\\n\\n\\n###### State: Draft / Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nAs an alternative to the (near-universally deployed) Delegated Proof of Stake we propose a sybil resistance technique designed natively for the benefits and tradeoffs of PBFT consensus, we call that system Proof-of-Fee (PoF). This proposal seeks to replace the Delay Towers mechanism currently in place with Proof-of-Fee.\xa0\\n\\n\\n\\n\\nProfits to blockchains are slim to non-existent. Low consensus costs are foundational for any chain that wishes to provide consumer surplus and profit to coin-holders; where excess winnings of the chain can be distributed to *all* account holders, that is, without preference to an investor class of \\"stakers\\". In PoF, the cost of consensus is lowered maximally to the *operator opportunity cost*, and such that the social cost (of dilution through issuance) is minimized.\\n\\n\\n\\n\\nValidator seats are auctioned at each epoch, such that the validators private valuation of rewards, MEV, breakage, and governance is revealed. PoF coins have superior ergonomics. Every actor has a very simple instruction; no staking, no yield games, no slashing. Holding the coin is the dominant strategy.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nProof of Fee partially replaces the current security model of 0L, by introducing novel economic guarantees layered with the validator admission through Vouches and Jail reputation.\\n\\n\\n\\n\\nThe proposal has two parts:\\n\\n\\n\\n\\n1. Define a new validator incentives mechanism, and\\n2. Replace Delay Towers with Proof of Fee.\\n\\n\\n\\n\\nHere\u2019s how each part works:\\n\\n\\n\\n\\n**Part 1: Define a New Validator Incentives Structure (i.e., determining how much is paid)**\\n\\n\\n\\n\\n* 0L will shift from the algorithmic calculation of validator incentives that we presently employ, to a fee that is a percentage of the total supply. The percentage is stable across epochs.\\n* Each successful validator will receive an equal amount as other validators in incentives each epoch.\\n* The amount of the fee is a parameter subject to governance action (and hence is adjustable on vote by the community).\\n* The amount should be minimal (e.g., single digit percentages of the total supply per year) yet designed to provide adequate incentives for validators to secure and maintain a reliable network.\\n* Incentives will be paid from the Infrastructure Escrow community wallet (see, Proposal 2210-1\\\\)\\n\\n\\n\\n\\n**Part 2: Implement Proof of Fee\xa0 (i.e., determining who gets to be paid)**\\n\\n\\n\\n\\nProof of Fee creates a competitive auction mechanism to pick who gets to participate in the validator set each epoch. Here\u2019s an overview of how it works, a thorough paper is forthcoming:\\n\\n\\n\\n\\n* At the beginning of each epoch, all validators who wish to participate in the epoch will place a bid (an Entry Fee).\\n* There is a limit to the number of validators in an epoch, the ones with the highest bids will enter the epoch.\\n* Validator consensus power is determined by the entry fee.\\n* Each validator bids their highest entry fee, with the expectation of receiving a flat fee at the end of a successful epoch.\\n* The initial proposed auction type is a Generalized Second Price Auction (a variation of the Nth Price Auction), which means the validator doesn\'t pay their maximum bid, but the bid of the next person immediately below them. (note: Future variations on this auction are possible and should be explored)\\n* Bids in excess of the pre-defined validator incentive for that epoch (i.e., a negative bid) will be permitted, within limits (e.g. 110% of the reward). The limit is a parameter subject to governance action (and hence is adjustable on vote by the community)\\n* At completion of the epoch, the pre-defined incentive amount will be paid to all validators that successfully completed the epoch. (The entry fee was already be paid thus, the net reward to a validator will be: Gross Incentive - Entry Fee \\\\= Net Amount Received by Each Validator)\\n\\n\\n\\n\\nAll actions will be included in the Version 6 upgrade to the Protocol.\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\nA vote of YES on this proposal will signal to the Engineering Team and the Validator set the community\u2019s desire to enact the following changes in the Version 6 Protocol Upgrade:\\n\\n\\n\\n\\n1. Create new epoch reward amount, with parameter for governance,\\n2. If Final Supply proposal passes, then the validator reward will be extracted from the Infrastructure Escrow community wallet (no new coins will be minted).\\n3. Disable Delay Towers for Validator Sybil Resistance Purposes.\\n4. Implement Proof of Fee with all necessary dependencies\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\nA vote of NO on this proposal will reject all parts of this proposal and retain the Delay Towers mechanism that is currently in place.\\n\\n\\n\\n\\n* The author(s) believe that revision of our current approach to consensus is essential for the community, so in the event that you choose to vote against this proposal, we welcome you to engage with the community to collaborate on the creation of a policy that is acceptable to the community at large.\\n\\n\\n\\n\\n### **Special Notes:**\\n\\n\\n\\n\\n* Note that this is a signalling proposal and therefore does not directly impact the chain; subsequent action is required to implement these changes.\\n* The outcomes of this proposal can be modified by the community via a subsequent proposal and vote\\n\\n\\n\\n\\n### **Reference Materials:**\\n\\n\\n\\n\\n* See also, Proposal 2210-1, Final Supply, for an explanation of the Infrastructure Escrow Community Wallet\\n\\n\\n\\n\\n#### **Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. **The closing date for revisions is 15 October.**\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-7-donor-directed-community-wallets","metadata":{"permalink":"/blog/proposals/proposal-2210-7-donor-directed-community-wallets","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-7-donor-directed-community-wallets.md","source":"@site/blog/proposals/proposal-2210-7-donor-directed-community-wallets.md","title":"Proposal 2210-7 - Donor Directed Community Wallets","description":"Proposal Type: Signalling","date":"2022-10-12T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":4.16,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-7 - Donor Directed Community Wallets","date":"2022-10-12T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-2 - Proof of Fee","permalink":"/blog/proposals/proposal-2210-2-proof-of-fee"},"nextItem":{"title":"Proposal 2210-8 - Infrastructure Escrow Funding","permalink":"/blog/proposals/proposal-2210-8-infrastructure-escrow-funding"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: TBD\\n\\n\\n\\n\\n###### Date: 12 October 2022\\n\\n\\n\\n\\n###### State: Draft / Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nThis proposal is focused on improving alignment of community wallets through governance levers.\\n\\n\\n\\n\\nAs a reminder, all community wallets are owned by a real world entity, not by the chain. As such those real world entities have real world liabilities if they misuse the funds donated to them. This off chain governance layer is expensive and slow to catch problems. Smart contract capabilities can help create proper governance.\\n\\n\\n\\n\\nCurrent Challenges:\\n\\n\\n\\n\\n* Community wallets hold a great amount of coins, but most are inactive.\\n* There is a perception that community wallets are for enrichment of participants (not donor directed funds for growth).\\n* Stopping Community wallets from misbehaving is hard.\\n\\n\\n\\n\\nThere\'s nothing the protocol can do to take money away from community wallets, or to censure certain wallets. Forking and removing certain coins can be done by the validator set, though this is politically impossible. What can be done is to correct some of the governance issues in the wallets; this proposal seeks to do that.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nThere are five parts to this proposal to enhance Community Wallets.\xa0\\n\\n\\n\\n\\n**1\\\\.****Implement Donor Direction**\\n\\n\\n\\n\\nTypically within our community, the Community Wallets have been idealized and spoken about as being \\"donor directed\\". However we had no proper tracking on-chain of the donations to actually realize this vision. As an intermediary step, we said the validators would be the authorities over veto and freezing of these wallets. This was fine when there was a large overlap of donors and active validators, but today this has already diverged significantly.\\n\\n\\n\\n\\nWe already have the donation tracking (the Receipts module) and with the v6 fork we can do two things to improve Community Wallet governance.\\n\\n\\n\\n\\n* Confirm that the values are correct per donor account (and sum to the value of donations), and\\n* Update the voting mechanism to use the Receipts module, thereby enabling the donors to have oversight over the expenditures rather than depending on action by the validator set.\\n\\n\\n\\n\\n**2\\\\.****Inclusion in the Burn Index**\\n\\n\\n\\n\\nAdditionally, with the v6 fork we can also add Community Wallets to the Burn Index, which will give every account in 0L the option to have their costs (burns) be recycled to an index of community wallets.\xa0\\n\\n\\n\\n\\n**3\\\\.****Optimization of Voting Thresholds**\\n\\n\\n\\n\\nSince participation is low in community wallets and the monitoring tools are lacking, the voting thresholds for rejecting and ultimately freezing wallets should be lowered.\\n\\n\\n\\n\\n* A community wallet transaction should be rejected if 1/6th of the donors disapprove with a veto. Three consecutive Vetos would mean freezing of the account, no changes there.\\n* There was no way to directly freeze a wallet. A wallet can also be frozen if 1/6th of the donors choose to do so. And can be unfrozen if 2/6th of the donors choose to do so.\\n\\n\\n\\n\\n**4\\\\.** **Define A Community Wallet as a Donor Directed Wallet with a Multisig**\\n\\n\\n\\n\\n* The new Policy would be: For a community wallet to be included in the Burn Index, and for unrestricted transactions from Transfer and Autopay functionality, the wallet will have to have a minimum of 3 of 4 multisig. The multisig will be implemented in the Donor Directed contract (as opposed to by off-chain signing wallets).\\n* Multisig signers for Community Wallets must have a threshold number of addresses that are unrelated (from different Ancestry in the permission trees).\\n\\n\\n\\n\\n**5**. **Create tools for monitoring and reacting to community wallets**\\n\\n\\n\\n\\n* Build monitoring and reporting into 0LExplorer.io\\n* Create interactive reports on Carpe\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\n1. Community Wallet policies will be changed to correct their behavior such that they are actually donor directed, and that they use multisigs for transaction approval.\\n2. Developers would be funded to create the code in line with the 5 changes outlined, above.\\n3. Carpe and 0L Explorer developers should be funded to create monitoring tools.\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\n1. Community Wallets will continue to have low oversight by the people and entities that funded them.\\n2. It will be difficult to catch one bad actor who abuses the Burn Match Index mechanism, since it doesn\'t require a diverse multisig, and there are no monitoring tools.\\n\\n\\n\\n\\n#### **Reference Materials:**\\n\\n\\n\\n\\n* n/a\\n\\n\\n\\n\\n**Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. **The closing date for revisions is 15 October.**\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-8-infrastructure-escrow-funding","metadata":{"permalink":"/blog/proposals/proposal-2210-8-infrastructure-escrow-funding","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-8-infrastructure-escrow-funding.md","source":"@site/blog/proposals/proposal-2210-8-infrastructure-escrow-funding.md","title":"Proposal 2210-8 - Infrastructure Escrow Funding","description":"Proposal Type: Signalling","date":"2022-10-12T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":2.9,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-8 - Infrastructure Escrow Funding","date":"2022-10-12T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-7 - Donor Directed Community Wallets","permalink":"/blog/proposals/proposal-2210-7-donor-directed-community-wallets"},"nextItem":{"title":"Proposal 2210-1 - Final Supply","permalink":"/blog/proposals/proposal-2210-1-final-supply"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: 0o-de-lally\\n\\n\\n\\n\\n###### Date: 12 October 2022\\n\\n\\n\\n\\n###### State: Draft / Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nIf the Final Supply proposal (2210-1\\\\) passes, an Infrastructure Escrow Community Wallet will be created to provide future validator rewards; this is a replacement for the daily minting of coins. The need for validator incentives will remain after minting of new coins stops, and this fund is designed to fill that gap into the medium term future (5-10 years).\xa0\\n\\n\\n\\n\\nNote that the re-basing contemplated by the Final Supply proposal means that the total supply will increase by a multiple. That multiple can be applied equally to all wallet types or distributed among the wallet holders in a variety of unequal fashions. The funds for the Infrastructure Escrow Community Wallet have to come from somewhere. So, as the supply is increased by the re-basing, a portion of tokens need to be carved off and put into a Community Wallet to pay for future incentives. It is inevitable that someone has to be diluted. This proposal asks voters to signal how they want that burden to be distributed.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nThe escrow fund should cover between 5 and 10 years of network infrastructure subsidies. To achieve that, wallets will have to be diluted. This proposal asks you how you prefer that dilution to occur; it asks you who do you want to see diluted. The options are:\\\\\\\\\\n\\n\\n\\n\\n1. Carpe Miners\\n2. Workers\\n3. Validators\\n4. Community Wallets\\n\\n\\n\\n\\nBased on the expression of preference by the voters, a formula will be created.\xa0\\n\\n\\n\\n\\nRemember, this is a quadratic voting process so you can express strong preferences here if you so desire. Quadratic Voting shows conviction voting on each of these variants, and based on that we can estimate how much each party should pay and put that forward in a subsequent governance action.\xa0\\n\\n\\n\\n\\n(By way of example: If the community votes equally strongly to dilute all, then all accounts should be diluted. In contrast, if two of the categories of wallets stand out equally then those wallets would have the same dilution (while the other two none). And variations on this.)\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\n1. Voting Yes on any of the variants increases the share that the group in question will contribute to the infrastructure escrow. Voting with greater conviction will increase the share.\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\nVoting No on any variant, reduces the proportion that the group will contribute to the escrow fund. Voting NO with greater conviction reduces the share.\\n\\n\\n\\n\\n### **Impact of Abstaining on this Proposal**\\n\\n\\n\\n\\n* If you do not have conviction on these items, (you use your Quadratic Voting credits elsewhere) the proportions will be set by other voters.\\n\\n\\n\\n\\n#### **Reference Materials**\\n\\n\\n\\n\\n* See also, [Proposal 2210-1, Final Supply](http://openlibra.blog/2022/10/11/proposal-2210-1-final-supply/)\\n\\n\\n\\n\\n**Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. **The closing date for revisions is 15 October.**\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-1-final-supply","metadata":{"permalink":"/blog/proposals/proposal-2210-1-final-supply","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-1-final-supply.md","source":"@site/blog/proposals/proposal-2210-1-final-supply.md","title":"Proposal 2210-1 - Final Supply","description":"Proposal Type: Signalling","date":"2022-10-11T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":4.045,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-1 - Final Supply","date":"2022-10-11T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-8 - Infrastructure Escrow Funding","permalink":"/blog/proposals/proposal-2210-8-infrastructure-escrow-funding"},"nextItem":{"title":"Proposal 2210-4 - Repurpose Carpe","permalink":"/blog/proposals/proposal-2210-4-repurpose-carpe"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: **Signalling**\\n\\n\\n\\n\\n###### Champion: **ricoflan**\\n\\n\\n\\n\\n###### Date: **11 October 2022**\\n\\n\\n\\n\\n###### State: **Draft / Work In Progress**\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nThis proposal relates to the biggest opportunity 0L has. With this proposal, the community is in a unique position to create a balanced, equitable approach to sustainability in which all participants are of a single class: All participants are workers.\xa0\\n\\n\\n\\n\\nThe current 0L token issuance schema is dramatically diluting workers while enriching the validators via issuance of new tokens each epoch (i.e., inflation). Anyone who has earned bounties, or engineering funds, have had their value reduced significantly by inflation across the last 6 months. This needs to change.\\n\\n\\n\\n\\nThe challenge to stopping inflation is how to preserve incentives for validators without ongoing issuance. This proposal seeks to stop inflation by ending issuance while providing a means to fund validator incentives for the medium to long term.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nThis proposal seeks to scaffold a permanently deflationary coin. There are three parts to the proposal: (1\\\\) stop issuance; (2\\\\) rebase the token; (3\\\\) create and fund an Infrastructure Escrow community wallet to provide validator rewards. The proposal asks for a single vote on all three parts; the three parts are interconnected and dependent.\\n\\n\\n\\n\\n1. Stop Issuance: The first part of this proposal is the simplest: Stop issuance of new tokens.\\n2. Rebase the Token: In order to fund the Infrastructure Escrow wallet (see, \\\\#3 below), there must be some form of dilution. The simplest, and most regulatory compliant way is to rebase the existing token by splitting each coin by approximately 5 (final calculations TBD) such that the total final supply is 10B coins. This in effect expands significantly the supply in a one time action; all account holders will have a higher account balance after the rebasing. (Note that this proposal only establishes a mandate to rebase; the exact methodology will be the subject of a separate, subsequent governance action if this passes.)\\n3. Create and Fund the Infrastructure Escrow community wallet: A new community wallet will be created to serve as an escrow for future validator rewards. This wallet will be funded from the tokens created by the rebasing of the token (see \\\\#2, above).\xa0 (Note that this proposal only establishes a mandate to create and fund; the exact methodology will be the subject of a separate, subsequent governance action if this passes.)\\n\\n\\n\\n\\nAll three actions will be included in the Version 6 upgrade to the Protocol.\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\nA vote of YES on this proposal will signal to the Engineering Team and the Validator set the community\u2019s desire to enact the following changes in the Version 6 Protocol Upgrade:\\n\\n\\n\\n\\n1. Stop issuance of tokens\\n2. Rebase the token using a formula to be determined in subsequent governance action\\n3. Create a new community wallet named Infrastructure Escrow\\n4. Transfer into that wallet a number of tokens to be determined by subsequent governance action\\n5. Note the impact of the passage of this proposal on token holders in multi-fold:\\n\\t1. There will be more tokens in the system.\\n\\t2. All wallets will show higher balances.\\n\\t3. A formula will be devised to allocate a portion of those tokens from all wallets to the new Infrastructure Escrow. That formula will need to be determined in subsequent governance actions.\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\nA vote of NO on this proposal will reject all parts of this proposal and issuance-driven inflation will remain in effect as it is currently.\\n\\n\\n\\n\\n* The author(s) believe that a clear path to a mission-aligned revision of our tokenomics is essential for the community, so in the event that you choose to vote against this proposal, we welcome you to engage with the community to collaborate on the creation of a policy that is acceptable to the community at large.\\n\\n\\n\\n\\n#### **Special Notes:**\\n\\n\\n\\n\\n* Note that this is a signalling proposal and therefore does not directly impact the chain; subsequent action is required to implement these changes.\\n* The outcomes of this proposal can be modified by the community via a subsequent proposal and vote\\n\\n\\n\\n\\n#### **Reference Materials:**\\n\\n\\n\\n\\n* See also, Proposal 2210-8, Infrastructure Escrow Funding\\n\\n\\n\\n\\n\\nNotes on Process\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. **The closing date for revisions is 15 October**.\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-4-repurpose-carpe","metadata":{"permalink":"/blog/proposals/proposal-2210-4-repurpose-carpe","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-4-repurpose-carpe.md","source":"@site/blog/proposals/proposal-2210-4-repurpose-carpe.md","title":"Proposal 2210-4 - Repurpose Carpe","description":"Proposal Type: Signalling","date":"2022-10-11T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":2.835,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-4 - Repurpose Carpe","date":"2022-10-11T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-1 - Final Supply","permalink":"/blog/proposals/proposal-2210-1-final-supply"},"nextItem":{"title":"Proposal 2210-5 - Revenue Binding Primitives","permalink":"/blog/proposals/proposal-2210-5-revenue-binding-primitives"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: TBD\\n\\n\\n\\n\\n###### Date: 11 October 2022\\n\\n\\n\\n\\n###### State: Draft / Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nIf Proposal 2210-2 Proof of Fee passes, the need for Towers will be eliminated and Carpe users will have nothing to do. This proposal advocates for one approach (an oracle service) to creating utility for Carpe. Additionally, 0L is seeking to have more revenue opportunities for the chain and expanded functionality. Oracles are ways of getting off-chain data onto the chain, e.g. getting the price of a coin from a website. The design does not foreclose other future uses for Carpe.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nThis proposal advocates that we take advantage of the Carpe installed base and repurpose Carpe into an Oracle Protocol, which in the future would be another source of revenue. Common oracle use cases are for the scraping of pricing data and exposing it on chain for apps to consume the data. Other similar uses are also possible. As such, oracles are a foundational piece of blockchain architecture that enables other services to function onchain in 0L.\\n\\n\\n\\n\\n* While the nature and pricing of the service will require subsequent governance action, a simple revenue model could work like this: The Oracle service will charge fee for its data stream that revenue should be designed to cover the Carpe costs.\\n* When revenue surpasses Carpe costs, then the remainder should be burned (i.e. redistributed to all accounts).\\n* Initially, as revenues ramp up, a subsidy will be needed to keep Carpe users mining until the Oracle product is complete.\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\n1. Tower mining, and the Identity Subsidy, by Carpe will NOT stop when towers are discontinued with Proof of Fee. It will continue until an Oracle subsidy or Oracle product can be introduced.\\n2. The Engineering team will design and build an oracle function for Carpe Miners\\n3. The oracle upgrade will be distributed for on-chain policy upgrades (AKA Stdlib), and upgrades to Carpe.\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\n\xa0If this proposal is defeated, Carpe mining will have no reward, and Carpe will continue only as a wallet.\\n\\n\\n\\n\\n* If Delay Towers are abandoned (as per Proposal 2210-2 Proof of Fee, or other governance action), then Carpe will cease to function.\\n* Note that if this proposal is defeated, there will remain a need to explore future expansion of Carpe functionality, or the sunsetting of the Carpe app. The author encourages those who vote No on this proposal to work with the community to find a means to address these challenges.\\n\\n\\n\\n\\n### **Reference Materials**\\n\\n\\n\\n\\n* See Proposal 2210-2, Proof of Fee, for an explanation of Proof of Fee and how that would replace Delay Towers.\\n\\n\\n\\n\\n#### **Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. The closing date for revisions is 15 October.\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-5-revenue-binding-primitives","metadata":{"permalink":"/blog/proposals/proposal-2210-5-revenue-binding-primitives","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-5-revenue-binding-primitives.md","source":"@site/blog/proposals/proposal-2210-5-revenue-binding-primitives.md","title":"Proposal 2210-5 - Revenue Binding Primitives","description":"Proposal Type: Signalling","date":"2022-10-11T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":1.675,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-5 - Revenue Binding Primitives","date":"2022-10-11T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-4 - Repurpose Carpe","permalink":"/blog/proposals/proposal-2210-4-repurpose-carpe"},"nextItem":{"title":"Proposal 2210-6 - Faucets for Workers","permalink":"/blog/proposals/proposal-2210-6-faucets-for-workers"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: TBD\\n\\n\\n\\n\\n###### Date: 11 October 2022\\n\\n\\n\\n\\n###### State: Draft/Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nThe community has signaled the importance of profitable unit economics. Experimentation is needed in order to create revenue streams from a) new protocol products, b) third party applications and c) off-chain businesses. Currently in the 0L tech stack, there are few functions, or bindings for that experimentation take place. This proposal advocates for the network to create this foundational tooling.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nDevelop new protocol services. Third party apps, and offline protocols need an easy way to charge fees in 0L coins. Priorities:\\n\\n\\n\\n\\n* Helpers in DiemAccount.move to facilitate future products\\n\\t+ Bridge\\n\\t+ Name service\\n\\t+ Indexing Service\\n\\t+ Exchange\\n* Applications and Off-chain Scaffolds for Revenue\\n\\t+ Create App revenue bindings\\n\\t+ Simple transaction capabilities, tracking, and bindings should be provided.\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\n1. The 0L standard library will be extended so that developers can easily charge fees in 0L coins, which will help generate revenue to the chain.\\n2. Engineers will be funded to work on developing a spec and delivering the code.\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\n1. This will not be worked on at the moment, and third party developers need to issue their own coins for apps.\\n\\n\\n\\n\\n#### **Reference Materials**\\n\\n\\n\\n\\n* n/a\\n\\n\\n\\n\\n**Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. The closing date for revisions is 15 October.\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-6-faucets-for-workers","metadata":{"permalink":"/blog/proposals/proposal-2210-6-faucets-for-workers","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-6-faucets-for-workers.md","source":"@site/blog/proposals/proposal-2210-6-faucets-for-workers.md","title":"Proposal 2210-6 - Faucets for Workers","description":"Proposal Type: Signalling","date":"2022-10-11T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":2.125,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-6 - Faucets for Workers","date":"2022-10-11T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-5 - Revenue Binding Primitives","permalink":"/blog/proposals/proposal-2210-5-revenue-binding-primitives"},"nextItem":{"title":"Proposal 2210-3 - Musical Chairs","permalink":"/blog/proposals/proposal-2210-3-musical-chairs"}},"content":"\x3c!-- truncate --\x3e\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: TBD\\n\\n\\n\\n\\n###### Date: 11 October 2022\\n\\n\\n\\n\\n###### State: Draft/Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\nThe proposals Proof of Fee (2210-2\\\\) and Final Supply (2210-1\\\\) are targeted at adjusting rewards from validators, with the goal of incentivizing the best performing validators. In line with the vision of creating an entrepreneurial cooperative, the 0L Network should also have a low-friction way for workers to organize themselves and receive streams of payments, in the absence of algorithmic rewards. This proposal takes a first step in that direction.\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nThis proposal advocates for the Engineering team to prioritize the development of functionality that will enable a simple mechanism for routing payments to working via the creation of a Move 0L framework (AKA stdlib) tools for entities to create and fund faucets. Features would include:\\n\\n\\n\\n\\n1. Anyone can start a Faucet\\n2. Faucets can have one or more administrators\\n3. The faucet can receive donations (from Community Wallets or users).\\n4. A user can claim a self-service payment from a faucet\\n\\n\\n\\n\\nThe self-service aspects of the faucets will be gated, as follows:\\n\\n\\n\\n\\n* The more users claiming the longer it takes for payment to process.\\n* The payment happens automatically unless an administrator intervenes.\\n* Certain faucets may require credentials (an NFT) before one can join.\\n\\n\\n\\n\\nA leading use case for this would be the Hustle Karma DAO, which can reduce overhead and speed payments by allowing users to self-paying for their work.\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\n1. Faucets would become an 0L stdlib feature which Community Wallets and others could use.\\n2. An engineering group would be funded to develop the Faucets tooling. The code would be merged to Move Stdlib on completion.\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\n* No Engineering effort in this area would be undertaken absent additional governance action.\\n\\n\\n\\n\\n#### **Reference Materials**\\n\\n\\n\\n\\n* n/a\\n\\n\\n\\n\\n**Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. The closing date for revisions is 15 October.\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/proposals/proposal-2210-3-musical-chairs","metadata":{"permalink":"/blog/proposals/proposal-2210-3-musical-chairs","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/proposal-2210-3-musical-chairs.md","source":"@site/blog/proposals/proposal-2210-3-musical-chairs.md","title":"Proposal 2210-3 - Musical Chairs","description":"Proposal Type: Signalling","date":"2022-10-10T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"},{"inline":true,"label":"proposal","permalink":"/blog/tags/proposal"}],"readingTime":4.965,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proposal 2210-3 - Musical Chairs","date":"2022-10-10T00:00:00.000Z","tags":["governance","proposal"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-6 - Faucets for Workers","permalink":"/blog/proposals/proposal-2210-6-faucets-for-workers"},"nextItem":{"title":"New Milestones for Carpe","permalink":"/blog/new-milestones-for-carpe"}},"content":"\x3c!-- truncate --\x3e\\n\\n###### Proposal Type: Signalling\\n\\n\\n\\n\\n###### Champion: TBD\\n\\n\\n\\n\\n###### Date: 10 October 2022\\n\\n\\n\\n\\n###### Status: Draft / Work in Progress\\n\\n\\n\\n\\n### **Context**\\n\\n\\n\\n\\n0L hasn\'t attempted to use Proof of Stake to filter malicious actors. Historically, we have had multiple layers of sybil resistance to prevent a malicious actor from amplifying attacks by multiplying the nodes they have access to. Vouches, social dynamics, and Delay Towers all work collectively to provide some resistance to bad actors. The mechanisms implemented to date have been sufficient for bootstrapping but are likely to prove inadequate at steady state.\\n\\n\\n\\n\\nThe current design of 0L makes it such that validators compete less among themselves as the count of nodes expands. For example, at 60 seats, the next epoch will have 10 slots open (the network always makes \u2159 the number of seats available). This means the competition is lower as the network progressively increases, which may be counter to the needs of the network. Meaning: when the validator set is large, the performance in TPS goes down, and better higher-quality validators are needed (not more seats with validators of unknown quality). Also when the set is large, it may also intersect with be that demand for the network services being are high. In those cases we want more, or at least the same, amount of competition.\\n\\n\\n\\n\\nThe validator set needs to be optimized for both performance and reliablility. The current selection process utilized by 0L optimizes for neither of those attributes, being based instead, on purely numerical conditions. A revised approach could advance both performance and reliability.\\n\\n\\n\\n\\nIt is expected that implementing the process described in this proposal will result in:\\n\\n\\n\\n\\n1. Greater competition\\n2. Higher performance in vulnerable conditions\\n3. Lower costs to the network\\n4. Competition at any size\\n\\n\\n\\n\\nWe expect validator selection to be more competitive than the current design. By reducing the \u2159 expansion criteria to a fixed 1 seat, only when perfect performance is achieved by the collective, then we expect that there will be greater competition for the validator set.\\n\\n\\n\\n\\nPerformant validators are not guaranteed a position, except when the network is vulnerable. In the case of subsequent reductions in the validator set because of extrinsic factors, the validator set progressively reduces to the most performant nodes, before becoming competitive again.\\n\\n\\n\\n\\nWhat Musical Chairs modifies, is that in a shrinking event, the validators which performed are guaranteed a seat. But as soon as a new seat opens up, then all validators must again compete on price (Delay Towers or Proof of Fee proposal)\\n\\n\\n\\n\\n### **Synopsis**\\n\\n\\n\\n\\nWith musical chairs, the validator set has no maximum limit. Whatever it\'s size (M) it is currently at its limit. Validators compete for seats through normal mechanism (Tower height) or a different cost (Proof of Fee), when the validator set is performant.\\n\\n\\n\\n\\nWhenever the validator set has perfect performance by all nodes, the set can increase by 1 seat (M \\\\+ 1\\\\). No validators are guaranteed a seat when the seat count is stable or growing. They compete on the lowest cost of service provided (cost of consensus). In the event of a validator set where one node did not perform (M - 1\\\\), then the next epoch will include all the performant validators LESS the one non-performing (the new size is M - 1\\\\).\\n\\n\\n\\n\\nThere key attributes of Musical Chairs are:\\n\\n\\n\\n\\n1. The validator set has no fixed upper bound of validator seats (i.e., no longer fixed at 100\\\\).\\n2. The validator set only expands if every member of the validator set performed above threshold - and then it only increases by 1 seat.\\n3. If any validator(s) did not perform, the validator set is reduced by the size of the non-performing validator(s) - and the expansion begins again.\\n4. In a shrunk validator set, all of the performant validators are allowed to remain, though if the validator set resumes increasing, they must compete on cost.\\n\\n\\n\\n\\nAll actions will be included in the Version 6 upgrade to the Protocol.\\n\\n\\n\\n\\nA vote of YES on this proposal will signal to the Engineering Team and the Validator set the community\u2019s desire to enact the following changes in the Version 6 Protocol Upgrade:\\n\\n\\n\\n\\n### **Impact of Voting YES on this Proposal**\\n\\n\\n\\n\\n1. Create the Musical Chairs functionality and all necessary dependencies\\n2. Disable the present validator selection set methodology\\n3. Implement Musical Chairs\\n\\n\\n\\n\\n### **Impact of Voting NO on this Proposal**\\n\\n\\n\\n\\nA vote of NO on this proposal will reject all parts of this proposal and retain the validator set sizing mechanism that is currently in place.\\n\\n\\n\\n\\n* The author(s) believe that revision of our current approach to validator set sizing is essential for the community, so in the event that you choose to vote against this proposal, we welcome you to engage with the community to collaborate on the creation of a policy that is acceptable to the community at large.\\n\\n\\n\\n\\n### **Special Notes:**\\n\\n\\n\\n\\n* Note that this is a signalling proposal and therefore does not directly impact the chain; subsequent action is required to implement these changes.\\n* The outcomes of this proposal can be modified by the community via a subsequent proposal and vote\\n\\n\\n\\n\\n### **Reference Materials:**\\n\\n\\n\\n\\n* See also, Proposal 2210-2, Final Supply, for an explanation of Proof of Fee, which is closely related to this proposal\\n\\n\\n\\n\\n#### **Notes on Process**\\n\\n\\n\\n\\n* This document is a Draft / Work in Progress. It will change until marked as FINAL. The closing date for revisions is 15 October.\\n* Publication here is an invitation for community collaboration and co-creation.\\n* To engage on this content, visit the **\\\\#governance-proposals** channel on the 0L Discord (link at bottom right)\\n* Once this Proposal is finalized, it will be the subject of Voting on the Radical X Change platform. If you do not yet have credentials, visit the **\\\\#rxc-voice-discussion** channel on the 0L Discord and make a request to join.\\n* **Voting opens 17 Oct and closes 22 Oct**"},{"id":"/new-milestones-for-carpe","metadata":{"permalink":"/blog/new-milestones-for-carpe","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/new-milestones-for-carpe.md","source":"@site/blog/new-milestones-for-carpe.md","title":"New Milestones for Carpe","description":"The 0L Network today reached a new record in terms of activity on the network: The daily number of active Carpe miners topped 2,000 for the first time today, with 2,080 installations running and earning tokens today. The number of active Carpe miners has been increasing steadily across the last 30 days, as new users have joined the community and discovered how easy it is to run Carpe and earn rewards.","date":"2022-08-11T00:00:00.000Z","tags":[{"inline":true,"label":"carpe","permalink":"/blog/tags/carpe"},{"inline":true,"label":"wallet","permalink":"/blog/tags/wallet"},{"inline":true,"label":"software","permalink":"/blog/tags/software"}],"readingTime":1.575,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"New Milestones for Carpe","date":"2022-08-11T00:00:00.000Z","tags":["carpe","wallet","software"]},"unlisted":false,"prevItem":{"title":"Proposal 2210-3 - Musical Chairs","permalink":"/blog/proposals/proposal-2210-3-musical-chairs"},"nextItem":{"title":"0L Network Constitution","permalink":"/blog/proposals/the-0l-network-constitution"}},"content":"\x3c!-- truncate --\x3e\\n\\nThe 0L Network today reached a new record in terms of activity on the network: The daily number of active Carpe miners topped 2,000 for the first time today, with 2,080 installations running and earning tokens today. The number of active Carpe miners has been increasing steadily across the last 30 days, as new users have joined the community and discovered how easy it is to run Carpe and earn rewards.\\n\\nAlso on this date we have released a newly updated version of Carpe \\\\- version 0\\\\.5\\\\.0\\\\. Here\'s what\'s new:\\n\\n* Wallet\\\\-to\\\\-wallet coin transfers\\n* Better reliability connecting to the chain\\n* Dynamic VDF proofs (improving network and miner performance!)\\n* Over\\\\-the\\\\-air upgrades\\n* Support for localization in multiple new languages\\n\\nFor the next few days, you will need to manually download and install Carpe. The automatic updater will be enabled after we\u2019ve given our more experienced users a chance to install the new version manually and report back on their experience.\\n\\nHere are the links for the packages you need for a manual update:\\n\\n* Windows users: [https://github.com/0LNetworkCommunity/carpe/releases/download/v0\\\\.5\\\\.0/carpe\\\\_0\\\\.5\\\\.0\\\\_x64\\\\.msi](https://github.com/0LNetworkCommunity/carpe/releases/download/v0.5.0/carpe_0.5.0_x64.msi)\\n* MacOS users (11\\\\+ only): [https://github.com/0LNetworkCommunity/carpe/releases/download/v0\\\\.5\\\\.0/carpe\\\\-macos\\\\-11\\\\.dmg](https://github.com/0LNetworkCommunity/carpe/releases/download/v0.5.0/carpe-macos-11.dmg)\\n* Debian users: [https://github.com/0LNetworkCommunity/carpe/releases/download/v0\\\\.5\\\\.0/carpe\\\\_0\\\\.5\\\\.0\\\\_amd64\\\\.deb](https://github.com/0LNetworkCommunity/carpe/releases/download/v0.5.0/carpe_0.5.0_amd64.deb)\\n\\nFor those of you unfamiliar with Carpe, it is a wallet and light miner application that can run on most consumer computers. The app only requires 1 thread of your CPU, meaning not only can most machines run it, but you can run it in the background while you do other things with your machine. Download Carpe, learn about 0L and start receiving rewards \\\\- it\u2019s very easy to get started.\\n\\nKudos to all of the Carpe contributors and the top\\\\-tier 0L community for pressing on during this crypto winter. It\u2019s time for builders to build! We welcome all builders into the community and encourage you to explore this site to learn more and [drop by our Discord and say hi](https://discord.gg/Nw7MpczV4X).\\n\\nCarpe diem!"},{"id":"/proposals/the-0l-network-constitution","metadata":{"permalink":"/blog/proposals/the-0l-network-constitution","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/proposals/the-0l-network-constitution.md","source":"@site/blog/proposals/the-0l-network-constitution.md","title":"0L Network Constitution","description":"Adopted by Community Polling on 3 May 2022","date":"2022-05-03T00:00:00.000Z","tags":[{"inline":true,"label":"governance","permalink":"/blog/tags/governance"}],"readingTime":1.84,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"0L Network Constitution","date":"2022-05-03T00:00:00.000Z","tags":["governance"]},"unlisted":false,"prevItem":{"title":"New Milestones for Carpe","permalink":"/blog/new-milestones-for-carpe"},"nextItem":{"title":"Spring Forward","permalink":"/blog/spring-forward\xa0"}},"content":"\x3c!-- truncate --\x3e\\n\\nAdopted by Community Polling on 3 May 2022\\n\\n\\n\\n\\n## **Purpose of this Document**\\n\\n\\n\\n\\nThis document is intended as an exposition of shared values at the heart of the 0L Network Community. The principles espoused herein are provided as a framework for decisions at a macro level and have been drafted to inform the decision process and provide a foundation to facilitate consistent and rational decision-making. This Constitution should be treated as a living document that is extensible \u2013 within the framework of our core values \u2013 as the community grows.\\n\\n\\n\\n\\n## **Our Core Values**\\n\\n\\n\\n\\nFrom our genesis, we have avoided the creation of an insider class (like a foundation, a protocol team, or venture capital investors) that might lead us down the path toward plutocracy. By creating an egalitarian community we hope to give the power of this blockchain to those that might do good for both our community and the wider world. We, as a community, seek to empower visionary entrepreneurs who hope to harness our chain to address problems at the intersection of information, economics and social coordination. To that end, we have adopted the following core values, which will serve as the underpinnings for critical decisions and our long term roadmap:\xa0\\n\\n\\n\\n\\n**1\\\\. Merit**: We are a community of do-ers who believe that those who serve our community and its vision should be rewarded \\\\& given a voice in shaping our community\u2019s future.\xa0\\n\\n\\n\\n\\n**2\\\\. Equity:** We are a democratic community that values fairness. We welcome all and actively seek to avoid descending into plutocracy.\\n\\n\\n\\n\\n**3\\\\. Diversity**: We strive to build an inclusive and diverse set of stakeholders, as we recognize that a diverse community is a resilient community.\\n\\n\\n\\n\\n**4\\\\. Network Integrity**: We take the state and security of the network seriously and will not lightly take actions that impair or threaten them.\\n\\n\\n\\n\\n**5\\\\. Decentralization**: The project should always strive towards decentralization.\\n\\n\\n\\n\\n**6\\\\. Permissionless:** We will strive to keep the network and the community open to all.\\n\\n\\n\\n\\n**7\\\\. Do Good**: We believe that generating positive social impact is everyone\u2019s responsibility and we pledge a portion of this community\u2019s output to furthering social good and humanitarian relief.\\n\\n\\n\\n\\n\\n\\n\\n**Related Documents**\\n\\n\\n\\n\\n* [Libra Liberated](http://openlibra.blog/2021/11/15/libra-liberated/), (15 Nov 2021\\\\)"},{"id":"/spring-forward\xa0","metadata":{"permalink":"/blog/spring-forward\xa0","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/spring-forward\xa0.md","source":"@site/blog/spring-forward\xa0.md","title":"Spring Forward","description":"Growth requires challenge","date":"2022-04-29T00:00:00.000Z","tags":[{"inline":true,"label":"news","permalink":"/blog/tags/news"}],"readingTime":8.005,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Spring Forward","date":"2022-04-29T00:00:00.000Z","tags":["news"]},"unlisted":false,"prevItem":{"title":"0L Network Constitution","permalink":"/blog/proposals/the-0l-network-constitution"},"nextItem":{"title":"Carpe Goes Multilingual","permalink":"/blog/carpe-goes-multilingual"}},"content":"\x3c!-- truncate --\x3e\\n\\nGrowth requires challenge\\n\\nThere was plenty of such fuel over the last several weeks, challenging our community to run a functional and fair network that is more poised for growth. This announcement will detail what has happened, how we addressed it and how, along the way, we solved a number of different problems and improved prospects going forward.\\n\\nOn 9 April 2022, the 0L Network halted. Multiple factors combined to create the incident; factors that started small and cascaded until the entire network ceased to produce blocks. While the detailed causes and the technical forensics have been discussed at length in our community meetings, the important point to raise here is that the halt was avoidable \u2013 or rather would have been avoidable \u2013 had a sufficient number within our validator community been more attentive to their machines and taken steps in a timely fashion. Better coordination is a key learning derived from this event.\\n\\nWith the network stopped, the community decided to take the time to make some major changes and bring back a network that was better and stronger and more aligned to the broader community\u2019s interests. **As you read this, the network is back, with a new set of features and a richer set of options for developers, Carpe miners, and the community as a whole.**\\n\\nAmong the enhancements we\u2019ve launched with this new version of the 0L Network:\\n\\n### **Carpe Enhancements**\\n\\nTogether with this network upgrade, we will shortly be releasing a new version of the Carpe wallet and desktop miner. With this release, Carpe will attain full wallet functionality, with the ability for users to send and receive coins using a standard wallet interface. The new release is in testing now and will be announced soon. The Internet of Value needs money in motion.\\n\\n### **Make Whole**\\n\\nWith this upgrade, we have set up a methodology for Carpe miners to claim coins that were under-paid to them in several past epochs due to a network bug. The Make Whole proposal has already been approved by the community, and we have set up a process that can be executed easily from inside Carpe to do so (you can learn more about this, and the new version of Carpe, once the release date is formalized).\\n\\n### **Slow Wallets**\\n\\nSlow wallet holders, particularly the members of our Hustle Karma workforce, will be pleased to learn that we have also used this upgrade to ease limitations on slow wallets. As of today, you can use your Carpe slow wallets to move coins! Daily transaction limits remain in place for slow wallets, at the level of 1,000 Libra per day. (Note that the daily transaction limit parameter is subject to adjustment by the community at a future date.) The goal is to balance active labor participation and value accrual with fair vesting and spending.\\n\\n### **Recovery Tools**\\n\\nA new set of recovery tools and workflows to make the network better able to recover from shocks in the future. There were a number of refactors to the writeset-tool, which enables a halted network to apply transactions at rest to upgrade the state machine code, update validator set, trigger new epochs, and enter recovery mode. Future halts could have very minimal downtime if the root cause is found quickly.\\n\\n## **Addressing the Larger Problem**\\n\\nThe tools and actions listed above are important and worth celebrating. However, we have a larger social issue that needs resolution \u2013 that is, the negative impact of passive validators.\xa0\\n\\nThe recent outage shows the need to take action to better align validator incentives with the best interests of the broader 0L Network community. There is a very good argument that the recent network stoppage was less a technical problem than a problem of misalignment of incentives and expectations. We need to take steps to assure an engaged, professional validator set and we also need to change the competitive dynamics for validators in order to disincentivize passive validators.\xa0\\n\\nTo tackle the first issue, we are implementing a new approach to validator set selection. At the launch of the network, validators were entitled to invite whomever they chose to join the validator set. The system had no checks in place, other than a rate limit on how frequently invitations could be issued. We initially counted on social pressure and common sense to guide our validators to select individuals or organizations who were able to manage their nodes to a professional level, and who would respect system requirements.\\n\\nUnfortunately, we now have experience showing that a more rigorous approach is needed. Indeed, the initial failures that began the cascade that led to the most recent network halt occurred first with the nodes that were under-provisioned and not in line with our published system requirements. Those failures were then complicated by many of those validators failing to be responsive to their machines and take remedial steps to recover from the failure.\\n\\nGoing forward, we are layering in a \u201cvouching\u201d system for validator set selection. At every epoch the system will check that each validator entering the set has endorsement by at least 4 existing validators of different \\"ancestry\\" . We mitigate the sybil issues by checking that the vouches come from\xa0 different \u201cfamily trees\u201d (i.e., who onboarded them). Every epoch, you can only join the validator set if you have at least 4 peers known to be good actors vouching for you. To facilitate this requirement, we have created an onchain permission tree that makes it easy to trace the lineage of individual validators.\xa0\\n\\n### **Funding the Community via Proof of Burn**\\n\\nThe second issue \u2013 the competitive dynamics of the validator class \u2013 is somewhat more complex. The goal is to make the cost to exist as a validator higher, and thereby disincentivize passive validators (free riders). To accomplish this aim, we are making two changes.\\n\\nFirst, we are putting in place a more expensive Proof of Burn mechanism. At launch, Proof of Burn was a fixed and insubstantial amount: Each validator was charged 1 coin per epoch to join the validator set. We also implemented a voluntary autopay function that encouraged validators to redirect a portion of their rewards to community wallets. The mechanism was 0L\u2019s answer to how to capitalize the system\u2019s growth and expansion in the absence of outside capital.\xa0\\n\\nBy increasing the Proof of Burn we can also automate community wallet funding by making it simpler and more seamless for those who opt-in. We\u2019re increasing the burn from 1 coin to 50% of validator rewards. Those funds will be distributed each epoch among the community wallets based on donations to those wallets. Validators also have the option to give more than 50% if they wish, and if they do not want to divert the funds to the community wallets, they can elect to have the coins burned. Note that this change simply streamlines the autopay functionality that has been tested since the Genesis of the network.\\n\\nSecond, we are closing a loophole in the system\u2019s capitalization game by making the Proof of Burn apply to both active and inactive validators. This approach not only helps provide critical network funding, it also incentivizes validators to participate in consensus in order to earn rewards and avoid the clawback of their previously earned coins. We expect this change to be controversial with some people and we have suspended the implementation of the Proof of Burn on inactive validators for 10 epochs. During that time, people can learn more about it and discuss. If there are substantial objections, the issue will be debated and revisited.\xa0\\n\\nThe changes to the validator onboarding and economics may not be guaranteed to reach the desired state, but directionally, they move us closer to the goal: Engaged validators who are stewards of the chain. Implementation of new types of economic incentives and games (for example, delegation) could build on these changes, make the economics more interesting for Carpe miners, and also help disincentivize inattentive validators.\xa0\\n\\n## **Next Steps**\\n\\nAt present, the network is in Recovery Mode and Carpe miners are able to start the app and check balances and have minimal interactions, but not mine their Tower. Recovery Mode suspends all economic activity to allow for testing and network stabilization. (This also disincentivized actors from front-running or otherwise taking advantage of skewed economics from network halts.) To be clear, while the network is in Recovery Mode no rewards are being paid to anyone \u2013 not even validators. One Saturday, 30 April, the network will open again for Carpe miners and we invite everyone to come back in.\\n\\nAlso, as noted above, the Proof of Burn on inactive validators is being held in abeyance until Epoch 185\\\\. During that time, if there are objections to this approach, they need to be discussed in the community to determine whether action should be taken.\xa0\\n\\n## **In Conclusion**\\n\\nBlockchain are infinite games. The game itself evolves and adapts. Passivity and paralysis are not an option.\\n\\n**The 0L network is live and running, as is our global community working towards the mission of a transparent, participatory, liberating, open blockchain network for all. We have dealt with the challenges of the moment to create a stronger foundation for the future, and we will continue to evolve the technology, social contracts, and norms of the project to best accomplish such a mission. Your voice is heard. There are more rewards for Carpe miners, as well as a hard commitment for 50% of the funds to flow to community-building wallets that reward participants that build along with us.**\\n\\n**Carpe diem \u270a\u2600\ufe0f**"},{"id":"/carpe-goes-multilingual","metadata":{"permalink":"/blog/carpe-goes-multilingual","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/carpe-goes-multilingual.md","source":"@site/blog/carpe-goes-multilingual.md","title":"Carpe Goes Multilingual","description":"We\'ve released, today, a new version of the 0L Network\'s Carpe Wallet \\\\& Desktop Miner. This release (v.0\\\\.3\\\\.0\\\\) is our latest release in the Carpe Beta series and includes significant new functionality, including multilingual support and a new tab \\"Events\\", which displays a list of events associated with your account (i.e., when coins move in and out of the wallet). This latest version ships with Chinese, Portuguese, and French language support. It is our plan to add additional languages in the near future.","date":"2022-03-25T00:00:00.000Z","tags":[{"inline":true,"label":"carpe","permalink":"/blog/tags/carpe"},{"inline":true,"label":"wallet","permalink":"/blog/tags/wallet"},{"inline":true,"label":"software","permalink":"/blog/tags/software"}],"readingTime":0.77,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Carpe Goes Multilingual","date":"2022-03-25T00:00:00.000Z","tags":["carpe","wallet","software"]},"unlisted":false,"prevItem":{"title":"Spring Forward","permalink":"/blog/spring-forward\xa0"},"nextItem":{"title":"Research Report: Decentralizing Permissioned Blockchain with Delay Towers","permalink":"/blog/research-report-decentralizing-permissioned-blockchain-with-delay-towers"}},"content":"\x3c!-- truncate --\x3e\\n\\nWe\'ve released, today, a new version of the 0L Network\'s Carpe Wallet \\\\& Desktop Miner. This release (v.0\\\\.3\\\\.0\\\\) is our latest release in the Carpe Beta series and includes significant new functionality, including multilingual support and a new tab \\"Events\\", which displays a list of events associated with your account (i.e., when coins move in and out of the wallet). This latest version ships with Chinese, Portuguese, and French language support. It is our plan to add additional languages in the near future. \\n\\nTo upgrade to the latest version, simply shut down and then restart your Carpe instance. You should be prompted to install the new version. Thanks to all on the Dev Team for making this happen! For those of you who are new to Carpe, [follow this link to grab the installer](https://github.com/0LNetworkCommunity/carpe) for Mac or WIN\\n\\nTo learn more about Carpe, visit the dedicated page on this site: [http://openlibra.blog/technology/carpe\\\\-desktop\\\\-app/](http://openlibra.blog/technology/carpe-desktop-app/)"},{"id":"/research-report-decentralizing-permissioned-blockchain-with-delay-towers","metadata":{"permalink":"/blog/research-report-decentralizing-permissioned-blockchain-with-delay-towers","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/research-report-decentralizing-permissioned-blockchain-with-delay-towers.md","source":"@site/blog/research-report-decentralizing-permissioned-blockchain-with-delay-towers.md","title":"Research Report: Decentralizing Permissioned Blockchain with Delay Towers","description":"This report, published 18 March 2022, looks at the Delay Towers mechanism that was pioneered and deployed in the 0L Network.","date":"2022-03-22T00:00:00.000Z","tags":[{"inline":true,"label":"research report","permalink":"/blog/tags/research-report"}],"readingTime":0.99,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Research Report: Decentralizing Permissioned Blockchain with Delay Towers","date":"2022-03-22T00:00:00.000Z","tags":["research report"]},"unlisted":false,"prevItem":{"title":"Carpe Goes Multilingual","permalink":"/blog/carpe-goes-multilingual"},"nextItem":{"title":"Carpe Beta Launched","permalink":"/blog/carpe-beta-launched"}},"content":"\x3c!-- truncate --\x3e\\n\\nThis report, published 18 March 2022, looks at the Delay Towers mechanism that was pioneered and deployed in the 0L Network.\\n\\nThe article was co-authored by Shashank Motepalli and Hans-Arno Jocobsen of the University of Toronto. We quote the original synopsis below:\\n\\n> Growing excitement around permissionless blockchains is uncovering its latent scalability concerns. Permissioned blockchains offer high transactional throughput and low latencies while compromising decentralization. In the quest for a decentralized, scalable blockchain fabric, i.e., to offer the scalability of permissioned blockchain in a permissionless setting, we present L4L to encourage decentralization over the permissioned Libra network without compromising its sustainability. L4L employs delay towers, -- puzzle towers that leverage verifiable delay functions -- for establishing identity in a permissionless setting. Delay towers cannot be parallelized due to their sequential execution, making them an eco-friendly alternative. We also discuss methodologies to replace validators participating in consensus to promote compliant behavior. Our evaluations found that the cost of enabling decentralization over permissioned networks is almost negligible. Furthermore, delay towers offer an alternative to existing permissionless consensus mechanisms without requiring airdrops or pre-sale of tokens.\\n\\n\\\\>\\\\> [View the original article, with download link to full report](https://arxiv.org/abs/2203.09714)"},{"id":"/carpe-beta-launched","metadata":{"permalink":"/blog/carpe-beta-launched","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/carpe-beta-launched.md","source":"@site/blog/carpe-beta-launched.md","title":"Carpe Beta Launched","description":"With the launch of the beta version of the Carpe Desktop App, the 0L Network has taken the next step towards making it possible for anyone to run a miner and earn crypto rewards.","date":"2022-02-10T00:00:00.000Z","tags":[{"inline":true,"label":"carpe","permalink":"/blog/tags/carpe"},{"inline":true,"label":"wallet","permalink":"/blog/tags/wallet"},{"inline":true,"label":"software","permalink":"/blog/tags/software"}],"readingTime":1.12,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Carpe Beta Launched","date":"2022-02-10T00:00:00.000Z","tags":["carpe","wallet","software"]},"unlisted":false,"prevItem":{"title":"Research Report: Decentralizing Permissioned Blockchain with Delay Towers","permalink":"/blog/research-report-decentralizing-permissioned-blockchain-with-delay-towers"},"nextItem":{"title":"Mysten Labs Partners With 0L Network to Expand Move For Secure Smart Contracts","permalink":"/blog/press-mysten"}},"content":"\x3c!-- truncate --\x3e\\nWith the launch of the beta version of the Carpe Desktop App, the 0L Network has taken the next step towards making it possible for anyone to run a miner and earn crypto rewards.\\n\\nCarpe is a desktop wallet and miner that runs on the new 0L Network blockchain. The app is lightweight and designed to help you establish your digital identity in the 0L Network, while paying you coins to do so. Carpe is a standalone desktop application that will run on any contemporary Windows or Mac machine. The app is gentle on your resources, meaning that you can continue to use your computer normally while the app runs in the background. Simply install it, turn it on, and start earning tokens.\\n\\nToday\'s release is the Beta of Carpe. The new version includes an improved interface and user experience and, under the hood, auto-update and automatic network connections. With this release, the community would also like to thank the over 3,000 (!!) alpha testers who have helped us bring Carpe to where it is today.\\n\\n**To get started, [follow this link](https://github.com/0LNetworkCommunity/carpe)**. We\'ve also created a set of easy to follow instructions, including [a video tutorial](https://youtu.be/FcPiiZNS8sA). Additionally, [you can also find a welcoming community of people that would be happy to help you on our Discord Server. Join us!](https://discord.gg/0LNetwork)\\n\\nCarpe Diem"},{"id":"/press-mysten","metadata":{"permalink":"/blog/press-mysten","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/press-mysten.md","source":"@site/blog/press-mysten.md","title":"Mysten Labs Partners With 0L Network to Expand Move For Secure Smart Contracts","description":"Mysten Labs, a Web 3\\\\.0 infrastructure company, announced a partnership with 0L Network, an open and permissionless version of the Diem blockchain. Together, Mysten Labs and 0L will build tools and resources for the Move smart contract programming language. Move, released as part of the Diem technology stack, is uniquely effective for secure smart contract development. In line with the partnership, the projects plan to roll out joint Move hackathons and mentorship programs starting in March 2022\\\\.","date":"2022-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"press","permalink":"/blog/tags/press"},{"inline":true,"label":"partners","permalink":"/blog/tags/partners"}],"readingTime":0.415,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Mysten Labs Partners With 0L Network to Expand Move For Secure Smart Contracts","date":"2022-02-01T00:00:00.000Z","tags":["press","partners"]},"unlisted":false,"prevItem":{"title":"Carpe Beta Launched","permalink":"/blog/carpe-beta-launched"},"nextItem":{"title":"Future-Proofing the Economics of Blockchains - Appendix: The Rulebook at Genesis","permalink":"/blog/the-rulebook-at-genesis"}},"content":"\x3c!-- truncate --\x3e\\n\\nMysten Labs, a Web 3\\\\.0 infrastructure company, announced a partnership with 0L Network, an open and permissionless version of the Diem blockchain. Together, Mysten Labs and 0L will build tools and resources for the Move smart contract programming language. Move, released as part of the Diem technology stack, is uniquely effective for secure smart contract development. In line with the partnership, the projects plan to roll out joint Move hackathons and mentorship programs starting in March 2022\\\\.\\n\\n[Read Full Article](https://www.globenewswire.com/news-release/2022/02/01/2377039/0/en/Mysten-Labs-Partners-With-0L-Network-to-Expand-Move-For-Secure-Smart-Contracts.html)"},{"id":"/the-rulebook-at-genesis","metadata":{"permalink":"/blog/the-rulebook-at-genesis","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/the-rulebook-at-genesis.md","source":"@site/blog/the-rulebook-at-genesis.md","title":"Future-Proofing the Economics of Blockchains - Appendix: The Rulebook at Genesis","description":"As you can see in our write ups mentioned above, we do things a little differently around here","date":"2021-11-18T00:00:00.000Z","tags":[{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":9.585,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Future-Proofing the Economics of Blockchains - Appendix: The Rulebook at Genesis","date":"2021-11-18T00:00:00.000Z","tags":["canonical"]},"unlisted":false,"prevItem":{"title":"Mysten Labs Partners With 0L Network to Expand Move For Secure Smart Contracts","permalink":"/blog/press-mysten"},"nextItem":{"title":"Future-Proofing the Economics of Blockchains - Part III","permalink":"/blog/future-proofing-the-economics-of-blockchains-pt-3"}},"content":"\x3c!-- truncate --\x3e\\n\\nAs you can see in our write ups mentioned above, we do things a little differently around here: We had no venture investors, there is no premine, no foundation with tokens, and anyone with a laptop can participate and earn coins. Here\'s a quick reference to the policies implemented at genesis:\\n\\n\\n### Rewards:\\n\\n\\n* Rewards are paid at the end of each \\"Epoch\\", daily at 16:00 UTC.\\n* The majority of the rewards will go to Validator Nodes, you\'ll need a cloud host to be successful at this (you can\'t do this with a laptop, and you need to be somewhat technical). Transaction fees are the principal source of rewards, but they can be augmented by Guaranteed Minimum subsidies.\\n* End Users on the other hand, can receive an Identity Subsidy for creating durable identities through Delay Towers. This is a system \\"mining pool\\".\\n\\n\\n![](https://siasky.net/TAAnqdoTyTo8vyr82sWC_bO9CpRUJ7oFU-v4l7PFSng94A/rewards.png)\\n\\n\\n### Requirements:\\n\\n\\n* We do not do Proof of Stake, instead preventing Sybil accounts is done through Delay Towers, a sybil resistance technique we invented.\\n* It uses Proofs of elapsed time which are done by the \\\\`tower\\\\` app on cloud machines, or the \\\\`carpe\\\\` desktop all for end users\\n* Validators are required to build Delay Towers, they must produce 6 delay proofs per day in order to gain admission to the validator set, and also to remain.\\n* End Users can optionally build Delay Towers to establish a persistent identity (and perhaps later join as a validator), and there is a reward for that.\\n\\n\\n### Validator Rewards:\\n\\n\\n* Securing the network is done by a maximum of 100 delegations of \\"Validator Nodes\\". This is very valuable work to the network.\\n* At the start of the network each Validator Node has typically 1 entity or person behind it (a delegation of 1\\\\).\\n* To become a candidate for a Validator Node, all that is required is to run the configuration tool, and to have any existing Validator in a current validator set send an onboarding transaction. (it\'s not a vote by the validator set to include a new validator.)\\n* While it doesn\'t take group permission to onboard a new validator, existing validators are rate-limited from creating endless accounts. They can only onboard a new prospective validator every 14 days/epochs.\\n* The budget for Validator subsidies is \\"thermostatic\\", it goes up or down depending on the total number of Validator Nodes doing work successfully.\\n\\t+ If the network is about to fail, with only 4 nodes on the network, the budget the network has for security, exactly 8,400,000 coins (the maximum). The 4 nodes share the 8,400,000 coins, 2,100,000 each.\\n\\t+ On the other extreme when the network is reaching its technical performance limit, there is no reason to subsidize Validators. At 100 Validator nodes, the total budget is 0, and the 100 validators will share the transaction fees the network produces.\\n* The validator subsidy only exists in the absence of sufficient transaction fees. It is a Guaranteed Minimum, which is net of transaction fees. So hypothetically if the network has 4 nodes, and hence the security budget is 8,400,000, however the total transaction fees are already above this number (e.g. 10,000,000\\\\), there is no need to subsidize the guaranteed minimum, there are no new Coins minted. This prevents unnecessary inflation.\\n\\n\\n### End Users Mining:\\n\\n\\n* Anyone with a laptop and with an ordinary account (End Users) can receive coins for creating a Delay Tower (proofs of elapsed time), as a basis for durable identity. We also call this mining.\\n* At genesis the protocol provides a subsidy for end users building up their identity.\\n* The reward pool for all miners is exactly the equivalent of one Validator Node\'s rewards in a given day. This can be thought of as a single system subsidized \\"mining pool\\".\\n* It is a smaller reward compared to Validator Nodes. So, end users are encouraged to run Validator Nodes or pool together to share rewards of validator nodes. Future mining pools are up to the community to design and create.\\n\\n\\n### Transferability:\\n\\n\\n* There are no restrictions on ordinary 0L accounts (end user accounts). But there are voluntary restrictions people can place on their account: Slow Wallet and Community Wallet tags\\n* Though End users accounts receive relatively smaller amounts of coins for the Identity Subsidy, their accounts have no restrictions on transferability.\\n* Slow Wallets\\n\\t+ Early participants of a network may receive generous subsidies, but they are prevented from dumping on less sophisticated users, these are Slow Wallets. All validator node accounts, where a majority of rewards flow to must be Slow Wallets.\\n\\t+ At genesis Slow Wallets currently cannot transfer Coins between accounts. At epoch 100, they get 10,000 coins unlocked per epoch (day).\\n* Community Wallets\\n\\t+ Community Wallets are optional settings which allow greater transparency, and also allow owners of the account to help prevent fraud. This designation of wallet is useful for anyone wishing to set up a program for the community benefit.\\n\\t+ And it also appoints all addresses in the validator set to be observers of the wallet, and they can slow down transactions by vetoing. With sufficient Vetoes the transaction gets rejected.\\n\\t+ Community Wallets can only make transfers to Slow Wallets.\\n\\n\\n### Sponsoring Programs in the Community:\\n\\n\\n* Autopay aims to make it trivially easy for early coin holders to send to development programs within the community.\\n* At this stage of the network Autopay can only send to wallets tagged Community Wallets, this is a benefit of being a Community Wallet.\\n* At time of writing, there are approximately 12 programs that have elected to use Community Wallets.\\n\\n\\n## Background\\n\\n\\nLike most smart contract platforms, the 0L System requires spending of credits (GAS Coins) for running smart contract computations on the system. These resources are allocated according to specific rules encoded in the core logic of the system.\\n\\n\\n## Earning Credit\\n\\n\\nAnyone can earn credits for themselves by performing computational work on the system. No permission is required. The OL network is a marketplace: of sellers of computation (Validators), and buyers of computation (End Users). The marketplace does not receive a fee. Instead the Validators receive the entirety of the Coins earned for the services performed.\\n\\n\\nSince the transaction fees may not be sufficient inducement for a seller of computation to join as a Validator, the network has Guaranteed Minimum Transaction Fee, which is subsidized in certain network conditions.\\n\\n\\n## Guaranteed Minimum Transaction Fee\\n\\n\\nAt times when the network is insecure (with very few validators), the transaction fees flowing through the marketplace may not be attractive enough for a prospective seller of compute power to join.\\n\\n\\nThe Guaranteed Minimum provides a baseline earnings which the Validator can rely on. A network Subsidy makes up the difference between what actual transactions fees were paid, and what is justifiable as a minimum payment. If the Guaranteed Minimum is 10 Coins given a network condition, but the transaction fees amounted to 3 coins, then the network creates new credits amounting to 7 Coins, and thus pays the total of 10 to the validator. Supposing the minimum guaranteed calculated by the algorithm is instead 1 Coin per validator, and the same 3 coins were due from transaction feed, then the network does not create any new Coins, and pays the 3 coins to the validator (in excess of the 1 Coin the network considered a justifiable minimum).\\n\\n\\nThe network\'s operating software encodes a schedule of the minimal accepted earnings given certain network conditions. The formula is intentionally simple. When there are four validators on the network (near failure) the guaranteed minimum is at its highest. When there are 100 validators on the network, (the transaction throughput is exponentially diminished beyond that amount in BFT networks) the network has excess compute power, and the minimum guaranteed is zero Coins. This means that at 100 validators the validators should expect to earn only the transaction fees flowing through the network. For easy comprehension by prospective validators the schedule is a straight line from 4 to 100 validators.\\n\\n\\nThis Auction aims to ensure the network always pays for security when it needs it, but does not overpay when it is not necessary to do so. It will appear generous at times, and miserly at others, but it should attract the necessary users.\\n\\n\\nNote, these allocation rules make some assumptions about BFT, that there is a super majority of honest actors and that the most committed validators are included in the validator set (proof of weight from Delay Towers)\\n\\n\\n## Identity Subsidy\\n\\n\\n0L\'s identity subsidy mechanism relies on Validators creating Delay Towers ([https://siasky.net/EABaWAXFy3Ztx1vVIpOfScjkRaTb1GrFeGRwqFKd6V-hAg](https://siasky.net/EABaWAXFy3Ztx1vVIpOfScjkRaTb1GrFeGRwqFKd6V-hAg)) which provide a persistent, and non-forgeable identity.\\n\\n\\nIt is important for the network to have as many users as possible creating durable identities, i.e producing Delay Towers. It has a number of benefits: allowing users not yet set up as validators to create identities, allows fullnodes to receive some compensation for providing replication services, and allows the VDF delay mechanism to be tested in a wide variety of hardware configurations so that the difficulty can be periodically adjusted.\\n\\n\\nWhile these activities are useful and deserve a meaningful subsidy, they are also low effort and cannot compete with the earnings to Validators (which are critical). This work is also less useful as the network matures, and has higher security (from Validator participation). Also the identity subsidy is highly gameable, and can lead to exploits by sophisticated users. The economics are designed such that those sophisticated users will be incentivized instead to run Validator nodes.\\n\\n\\nTo balance the needs of validators, and exploits possible, miners thus share the equivalent of 1 Validator\'s Guaranteed Minimum in every epoch. The identity subsidy is an example of a \\"mining pool\\", where the end users share the rewards of one validator node. At genesis the protocol is sponsoring this single mining pool. We expect future mining pools to be an emergent property of the network, as end users seek to receive more rewards, from naturally diminishing rewards to the single system mining pool\\n\\n\\n## Transferring Credits\\n\\n\\nTransfers of credits are unlimited for End User accounts (plain accounts). If an End User is running a \\"miner\\" and creating a tower, those credits are freely transferable.\\n\\n\\nThere two categories of accounts that have opt-in rules for transfers\\n\\n\\n### Community Wallets\\n\\n\\nThese are wallets that have elected to have community oversight. If a person or entity would like to increase the credibility of that wallet (e.g to create a program), they may opt to have the transfers be slowed down or ultimately rejected. More details here:\\n\\n\\n* Community wallets typically will receive funds from AutoPay, if anyone wishes to automatically donate a % of their credits.\\n* Sending automatic payments is easy. It is also encouraged socially. On the current network Validator Nodes are voluntarily opting into donating on average more than 50% of their rewards.\\n\\n\\n### Slow Wallets\\n\\n\\nSince transferring credits by early users can cause undesirable effects (e.g. creating markets and dumping credits on lesser informed users), the earliest members, and the ones most likely to accumulate large amounts of credits are rate-limited in transferring funds. Transferability also interferes with the ability of the auction for security. The exception is transferring credits to Community Wallets. Those transfers are unlimited.\\n\\n\\nThere are accounts that have elected to have restricted transferability. Those are designated Slow Wallets. To join a Validator Set a prospective user must have a Slow Wallet.\\n\\n\\nCarpe diem \u270a\u2600\ufe0f"},{"id":"/future-proofing-the-economics-of-blockchains-pt-3","metadata":{"permalink":"/blog/future-proofing-the-economics-of-blockchains-pt-3","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/future-proofing-the-economics-of-blockchains-pt-3.md","source":"@site/blog/future-proofing-the-economics-of-blockchains-pt-3.md","title":"Future-Proofing the Economics of Blockchains - Part III","description":"TL;DR","date":"2021-11-17T00:00:00.000Z","tags":[{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":15.975,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Future-Proofing the Economics of Blockchains - Part III","date":"2021-11-17T00:00:00.000Z","tags":["canonical"]},"unlisted":false,"prevItem":{"title":"Future-Proofing the Economics of Blockchains - Appendix: The Rulebook at Genesis","permalink":"/blog/the-rulebook-at-genesis"},"nextItem":{"title":"Future-Proofing the Economics of Blockchains - Part I and II","permalink":"/blog/future-proofing-the-economics-of-blockchains-pts-1--2"}},"content":"\x3c!-- truncate --\x3e\\n\\n## TL;DR\\n\\n\\nIncentives are hard. There are many different stakeholders in a healthy economy and the needs of those stakeholders can be a moving target. Advanced mechanisms are employed to address the trade-off between clear rules and adaptive capacity. Polycentric programs with community wallets provide a means of voluntarily contributing to capex, while thermostatic security dynamically rebalances validator rewards based on validator count in order to manage opex. Furthermore, incentive alignment between network operators and end users is enhanced via two mechanisms: i) the introduction of slow wallets for validators which rate limit the availability to spend their rewards and ii) the introduction of an identity subsidy whereby end users may submit proofs of elapsed time to establish persistent identities and earn rewards (which do not have spending rate limits).\\n\\n\\nPart II discussed some principles and constraints of core protocol blockchain economic design. What follows is a discussion on what might reasonably be achieved at bootstrapping given the considerations outlined in the previous part of this article.\\n\\n\\nOne caveat, we don\'t claim that these mechanisms are all necessarily stable or appropriate in steady-state, but that they are useful bootstrapping tools. The working assumption is that a viable network at maturity can articulate a transition to other economic guarantees.\\n\\n\\n### Polycentric Programs\\n\\n\\nA successful network needs builders, not just on day-one but throughout the life of an evolving, growing, improving network. The time and effort of builders has an opportunity cost and so must be rewarded. A network, however, is unowned which makes it challenging to provide to the builders appropriate incentives that are binding and results oriented.\\n\\n\\nNot every holder of the initial token supply is a builder. Similarly, not every builder is in a position to benefit the network indirectly, i.e. with cash. In ordinary startups this isn\u2019t a problem as the liquid investors - the capitalists - pay for the services of the illiquid builders. In the case of a network, a similar process could work if the builders hold tokens that are sold to investors, but there are obvious and notorious regulatory issues with this approach.\\n\\n\\nThere is also a free rider problem. Since the network is unowned, each builder stands to gain from the investments of the other builders and may have an incentive to free ride, i.e. hold their own tokens letting others sell their tokens and make the necessary investments. The problem becomes worse as more people accumulate tokens.\\n\\n\\nA complete solution to both the free rider problem and the funding of public goods in a market setting is unsolved;solving it algorithmically only\xa0[compounds the problem](https://kelsienabben.substack.com/p/algorithms-as-policy). Funding what rides the rails is a human activity. Algorithmically picking the correct moonshot application and the team to execute is an AI-complete problem. As such, there are many attempts to scale up this decision making that ultimately are doomed by the meta-game.\\n\\n\\n\\"The DAO\\" was the early example of a venture fund for \\"pirate equity\\" on the Ethereum chain. The story of the colossal hack is only remarkable, because it brought the designers of The DAO to the attention of regulators, which used it as the case-study for the\xa0[SEC\'s shot across the bow at protocol developers](https://www.sec.gov/litigation/investreport/34-81207.pdf). Variations on this are to be avoided if your protocol is to have a moat against such \\"nation state attacks\\". Regulators haven\'t commented on funding protocol treasuries from pre-mines, founder rewards, and network taxes, but these mechanisms are likely too close for the comfort of many, especially the next generation of protocol builders who have yet to wade into the waters. Given the uncertainty and the potential downsides, most people will want a bigger moat.\\n\\n\\nSo what are the enlightened self interested security guards of the early blockchains to do? Donations to programs run by individuals, businesses, or foundations are straight-forward. Soliciting contributions to do work on open-source projects is the bread-and-butter of many developers. As described previously, expecting early miners to do this post hoc is just a case-study in the prisoner\'s dilemma, and will lead to protocols\'\xa0[capex being perpetually under-funded](https://vitalik.ca/general/2021/08/16/voting3.html). To get to a plausible solution we need to weigh some supply and demand-side effects.\\n\\n\\nOn the demand side (early contributors wanting to contribute to programs which benefit the community), how do you get people to act in favor of their most virtuous preferences? Donations are prisoner\u2019s dilemmas that are vulnerable to free riding and to simple greed. Even if I value a project to produce a public good, I may try to free ride on the contributions of others -- a problem that gets worse if I don\u2019t value the public good at all.\\n\\n\\nOn the supply side (the programs on offer), the question becomes how to prevent the things that blockchain as a movement is antithetical to: Graft, nepotism, exploits, and incompetence? Centralization of pools and discretion, such as premines to a foundation or network taxes to a group account, just seem to attract a type of Lord of the Flies standard of governance. Is it possible to have a market of programs, and do away with centralization and whitelists?\\n\\n\\n#### Optimizing Demand Side\\n\\n\\nYou can encourage people to elect at a rate closer to the community optimum by making opt-in donations obvious, effortless,\xa0[automated, and highly visible](https://medium.com/commonsstack/automating-ostrom-for-effective-dao-management-cfe7a7aea138). Elinor Ostrom, the Nobel prize winning economist and political scientist, showed that\xa0[tolerable solutions](https://www.onthecommons.org/magazine/elinor-ostroms-8-principles-managing-commmons)\xa0exist for these kinds of problems especially in small, long-lasting groups where people can be monitored and initially gently chastised for norm-breaking with subsequent graduated sanctions.\\n\\n\\n#### Optimizing Supply Side\\n\\n\\nThe supply of programs need not be fixed. Anyone should be able to create a program, and solicit donations - no matter the size. Like big-brand global non-profits who compete with each other for donor dollars, protocol programs are in a market. The most credible programs will attract the most funding. The programs with the most safeguards will also receive the most funding. A market for projects allows real world outcomes to form a feedback loop for which some projects continue to get funding and some die out.\\n\\n\\nPrograms opting into participatory decision-making increase their chances of serving the market, i.e. the donors\u2019 preferences. While it doesn\'t need to be included in the protocol, the protocol may offer smart-contract capabilities by which people can prove that they are a donor, such that the program can more easily poll the market for upcoming decisions, big or small. This is complex to do in the offline world, but in a smart contracts environment it\'s as simple as providing an on-chain \\"receipt\\" of donation to the account. Again, the protocol need not bind a program to do this, but making it readily available and there being simply one program adopting this could very well make it the standard by which other programs need to compete against in the market for donations.\\n\\n\\nA second boost to credibility of programs is giving them the ability to delegate the catching of fraud. Again, this is not possible with traditional offline foundations, but the transparency of a public ledger provides opportunities. A smart contract could be provided to programs such as a \\"secure wallet\\", where the program can elect a group which has supervisory authority in some very narrow cases. Typically on blockchain this is done with \\"multi-sig\\" wallets that require multiple signatories to allow a disbursement. However, electing signatories is an opaque process, and the technology to implement this is cumbersome In practice, most multi-sigs (some with billions of US dollars worth of assets) have fewer than ten authorities.\\n\\n\\nThere\'s another more practical issue, that is, getting authorities to proactively sign every invoice is impractical. The process can be onerous when the goal is to prevent self-dealing and fraud. As an alternative, the program administrator should recruit the stakeholders to identify fraudulent transactions, i.e., slow them down to be scrutinized, and ultimately blocked. This could allow a larger group of stakeholders to observe, and they need not be fixed but may freely join or leave that role. More practically, the program may just elect the validator set operators (consensus nodes) to be in that role since they are ultimately the most trusted authorities on the network.\\n\\n\\nWe think providing these tools to both consumers and providers of public good generation processes can create market micro-structures that fend off the prisoner\'s dilemma for a time. But this game relies on Ostrom\'s assumptions that social consensus can be enforced, and this does not scale. Scaling social coordination, however, is part of the magic of blockchain. In subsequent rounds of play, and with new players, stronger consensus can be encoded into the blockchain\'s policy. Modifying these games to create greater benefits for donors, ultimately incorporating guild-like tithes, or even a subscription of services, may be acceptable by subsequent cohorts.\\n\\n\\nSaid differently: While regulators may not allow you to create binding games to solve prisoner\'s dilemma at genesis, with the right social norms this can be punted into a future round of the game.\\n\\n\\nNative token balances don\'t automatically solve your funding issues. Valuation of your dry powder is a vanity metric, given that actually using the funds can cause extreme turbulence in the market and therefore\xa0[needs to be considered carefully](https://uncommoncore.co/a-new-mental-model-for-defi-treasuries/). In this situation, proportions matter. Assuming that there is a healthy market for programs that are working to produce public goods, the next step is preventing the program ecosystem from becoming ransacked, not by fraud, but by a more stealthy actor: Dilution.\\n\\n\\n### Thermostatic Security\\n\\n\\nIn designing a blockchain system, attention should be given to where the value flows.\\nHow economic value is allocated depends on the rules of a system. In a competitive market with free entry, for example, suppliers compete prices down to costs and most of the surplus value flows to consumers. In a system with monopoly, the total value generated is smaller but a larger share flows to suppliers.\\n\\n\\nThe biggest impact on the distribution of credits are the subsidies to node operators, after all, that is how the credits materialize in the first place and continue to be issued. In many protocols, especially early ones, much of the value flows to the miners in the form of block rewards (subsidies in the absence of transaction fees). The miners in turn compete to obtain that value and in so doing dissipate it in the form of server and electricity costs. Since much of the value per transaction (in the form of mining fees and subsidies) flows to suppliers, those blockchains aren\'t providing much consumer surplus in terms of transactions, although they can be very useful as a store of value.\\n\\n\\nValidators and full node operators verify that the transactions submitted to a blockchain follow the formal rules of the blockchain. Validation is critical to the successful operation of a blockchain, but it is an essentially mechanical or algorithmic procedure, much like verifying that a letter is appropriately addressed and stamped or that a contract has been signed. Validators should be paid enough to cover their costs and a normal profit, but there are few reasons to offer validators the prospects of extraordinary returns. Validation is like road maintenance, garbage pickup or web services--a critical service that should be prioritized, paid regularly, securely, and well. But, if you want value to flow to users of the service, validators should be paid based on the costs of supplying the service, not on the value of the service itself.\\n\\n\\n##### *The auction*\\n\\n\\nTo avoid both over and underpayment of validators, and to distinguish validator payment from the fundamental properties of the system, the blockchain uses a simple and clear algorithmic process to converge on a fixed number of validators. The equilibrium number of validors is set so that it is at an optimal level for the validation of the network: large enough for competitive pricing and robust security, yet small enough to prevent value dissipation.\\n\\n\\nThe key variable is the count of validators that have signed blocks within the last Y blocks. This moving average is data which is available to the core system\'s state machine. When the count of validators is below the optimal level, total validator compensation increases. When the count is above the optimal level, total validator compensation decreases.\\n\\n\\n![](https://siasky.net/TACPw_L307kSOzbii_ZrbZYQQJJzPzdbkn6ttjCXz96z8Q/graph.png)\\n\\n\\nValidators in this model are well paid but not overpaid. They are also paid equally, assuming the work is above a threshold. Based on the chart above, we propose that having, for example, over 100 nodes performing validation (in classical pBFT based consensus) has diminishing marginal returns to security, and therefore should not be overcompensated.\\n\\n\\nFor this auction to work, it\'s important that it should be easy for validators to enter the market and also to exit. Ease of entry and exit and an adjustment process that changes validator compensation to keep the number of validators roughly constant around the optimal level together ensure that validators are always paid a price that reflects the true cost of providing validator services.\\n\\n\\n### Slow Wallets\\n\\n\\nBootstrapping the network requires a careful balancing of two considerations. First, early contributors and adopters should be rewarded for their investments and efforts. Second, early contributors and adopters should not be rewarded such that later contributors are second-class citizens and thus should not be incentivized to \u201cpump and dump.\u201d A chain can balance these two considerations by rewarding early contributors and adopters, but locking them in until after everyone has had an opportunity to join, test and use the network. Thus, early contributors and adopters who may have outsized gains are not rewarded until the network matures.\\n\\n\\nThere is no obvious reason the entirety of the credits for computation should be transferable between accounts. It is not like this for airline miles. It is also not like this for commodities, or real estate. If you are designing the credit to be durable and useful for computation in the future, or more, it is wise to keep in mind how the flows of those other assets work. Not all gold in the world can be transferred between accounts at a moment\'s notice. And how much of Manhattan\'s real estate by \\"market-cap\\" changes hands on a given day? The answer: A fraction of one percent.\\n\\n\\nAt the start of a network, when an ecosystem is not yet developed, there are limited places to use your compute credits. There are limited smart contracts to execute, limited places to bond your credit for access to other benefits. So, while you can earn credits, and they are yours free and clear to use an unlimited amount in smart contract execution, there\'s not a great operating case for transferring them to other parties at the start of the network.\\n\\n\\nSpeculation is one case, and there\'s nothing inherently wrong with that. What is a problem, however, is speculation by people with information advantages, people that have no\xa0[\\"duty of care\\" to the platform](https://medium.com/token-engineering-commons/engineering-ethics-in-web3-18d981278018?source=linkShare-bdd1335dfbd-1636835251)\xa0(i.e. the risk of rug-pulls, and dumping); those actors make it a less trusted environment.\\n\\n\\nThe network may choose to enforce limits on balance transfers in the code, for the simple reason of preventing a prisoner\'s dilemma, that is, while some parties may be happy to opt-in to slowly transferring their account balances, as soon as someone breaks the rule it causes a run on the bank.\\n\\n\\nSlow wallets should be opt-in, and not seen as a tax. The outcome an enlightened self-interested miner is seeking is: \\"I\'ll place my funds in a slow wallet, as long as others do so\\". To increase the incentive the collective can say certain activities on the network, ones that require greater trust for instance, need to be done by people with slow wallets, e.g. running validator nodes, can only be done by accounts with slow wallets. Additionally, this can be coupled with other ecosystem activities that create stronger consensus: The development programs (e.g., an engineering fund) can have a policy that will state that it will only pay out to individuals who have opted into having a \\"slow wallet\\". Thus, it becomes possible for the network to persuade the actors which have the most power to disrupt the economics of the chain to voluntarily opt into a lockup.\\n\\n\\nIn many protocols we observe that locking schemes do, however, still tend to privilege early members (or investors with different term sheets) and those with information asymmetries. Two proposals can mitigate this: (1\\\\) there should not be any lower \\"castes\\" of the unlocking regime; everyone has the same rule, and (2\\\\) people get the same flat amount unlocked everyday (not on a percentage basis).\\n\\n\\nA reasonable lockup policy might look like this: Slow wallets are enforced by the state machine. If you want to be a validator, or otherwise access early features, those features will check if you have a slow wallet. You can, of course, keep an end-user wallet which has no limitations, but also does not access certain features. Transfer limits on slow wallets start at 0 and increase daily at a fixed amount (not a percentage, so whales do not have extra advantage). Every slow wallet has the same transfer limit schedule.\\n\\n\\nA possible variation on the above can be considered: The transfer limit schedule can be adjusted over time as transaction fees increase Thus, transferability matches the maturity of the network as measured by usage. This mechanism, however, suffers from a kind of problem: It will be very unpredictable, and have a low user experience. The user will not know what to do differently to effect the change.\\n\\n\\nPrincipally, and this should by now be obvious, the main benefit of locking is that it incentivizes early contributors to play the long game. All players over time should effectively be hearing the same instruction: Creating trains to ride the rails increases the long-term value of the network. Producing the public goods of the network is what makes your number go up. In other words, by limiting the opportunity to dump, locking incentivizes socially valuable greed. Extrinsic incentives are good when they incentivize actions in the social interest, that is, when they encourage investments that will increase the value of the network. Said differently, people who have bound themselves together for an extended period of time are incentivized to discover ways to cooperate (in and out-of-band) to produce and fund the application layer.\\n\\n\\n## Conclusion\\n\\n\\nWe intend our principles to be a Schelling point to attract certain personalities. Not all of our designs are necessarily stable under all scenarios. In fact, we\'ve made it clear that the donation game will eventually break down. We\'re confident though that these mechanisms will attract the people necessary to iterate in subsequent rounds of the game. People like you, since you\'ve read this far!\\n\\n\\nThe warning signs of the past mistakes are loud and clear for public infrastructure. To return to our prior narrative, railway profits were eroded by competition with the interstate highway system and air travel. This brought the Pennsylvania Railroad company to its knees. The lesson is: Don\u2019t fall in love with instances of public goods, but do build on them, and plan for the next century.\\n\\n\\nWe are playing an infinite game, not a finite game and the only way to win an infinite game is to keep playing. Carpe diem \u270a\u2600\ufe0f"},{"id":"/future-proofing-the-economics-of-blockchains-pts-1--2","metadata":{"permalink":"/blog/future-proofing-the-economics-of-blockchains-pts-1--2","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/future-proofing-the-economics-of-blockchains-pts-1--2.md","source":"@site/blog/future-proofing-the-economics-of-blockchains-pts-1--2.md","title":"Future-Proofing the Economics of Blockchains - Part I and II","description":"TL;DR","date":"2021-11-17T00:00:00.000Z","tags":[{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":17.635,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Future-Proofing the Economics of Blockchains - Part I and II","date":"2021-11-17T00:00:00.000Z","tags":["canonical"]},"unlisted":false,"prevItem":{"title":"Future-Proofing the Economics of Blockchains - Part III","permalink":"/blog/future-proofing-the-economics-of-blockchains-pt-3"},"nextItem":{"title":"0L Aims To Revive Facebook\u2019s Libra Cryptocurrency With Fair Launch","permalink":"/blog/thedefiant"}},"content":"\x3c!-- truncate --\x3e\\n\\n## TL;DR\\n\\n\\nA transformation in society is taking place and layer-1 computational blockchains are the substrate. While the economic fortunes of layer-1 computational blockchains may wax and wane, the goal of the collective behind them should be to transition their economic stake from the infrastructure layer into the application layer. This leap will take time, and most blockchains will not make the leap. Coordinating the labor and care that goes into the work of producing a blockchain that can make the leap is not trivial. We propose some principles so that blockchains can successfully cross over to that shore when the day comes.\\n\\n\\n## PART I - The Opportunity\\n\\n\\nCrypto is an experiment in digital scarcity. New digital resources have emerged, such as coins, tokens, NFTs and more. We\'re here to talk about layer-1 blockchain network \\"gas\\" coins. Through one lens, the liquid and instant settlement of these resources makes them look like cash. From another perspective, they look like deeds, rights, memberships, or even a cooperative business that defies our legal definitions of companies and partnerships. More generally, gas coins mediate access to one of most exciting social technologies in recent memory: Smart contracts.\\n\\n\\nThe computation needed for smart contracts is not orthodox computing power. Credibly neutral replicated state machines are the technical artifacts that are required and currently the quantity demand exceeds the quantity supplied. Current crypto economics are not necessarily well configured.\\n\\n\\nWe\'re not here to wax hyperbolic about the power of smart contract platforms but, for new entrants, suffice it to say that the blockchain as a ledger is only one facet of the innovation. At the baseline, smart contracts allow for the composing of many interactions of value, both native and non native to the digital realm. The collective ingenuity of workers in this space is engaged by the possibilities of programmable monies, firmly binding agreements, durable memberships, and all manner of automation of value. Beyond the horizon are even more experimental use-cases: Prediction markets, new forms of voting, new forms of identity and pseudo-identity, the integration of the real world and virtual reality in the metaverse. More generally, it\u2019s obvious that the world is moving online and will continue to do so. The power of blockchains is that they let people create secure property rights and identity systems that amplify the power and utility of the online world.\\n\\n\\nThe early experiments in this space (e.g., payments, decentralized finance, asset tokenization) are each\xa0*trillion*\xa0dollar markets; this certainly explains in part why the crypto space has boomed. However, the financial exuberance around blockchains contains the seeds of its own destruction. The promise of the blockchain will be fulfilled precisely when and if blockchains are cheap, abundant and commoditized. The froth we see in the market for blockchains is based on the assumption that these infrastructures can capture the value the ecosystem provides; but the ecosystem will produce tremendous value only when the infrastructure becomes a global public good accessible to everyone at low cost. The cheaper the rails the more value will ride the rails. This may appear paradoxical, but the implication here is that the rails don\'t reflect the value of what is riding upon them.\\n\\n\\nLayer-1 platforms of the next decade will begin to see more acceptance, but they will also see challenges to the unit economics of providing the compute resource. This article highlights what some of those challenges may be, and how the community which holds native gas coins - the \\"digital asset collective\\" - can future-proof the economics of the blockchain.\\n\\n\\n### Cautionary Tales From Infrastructure Businesses\\n\\n\\nNot all blockchains will be successful. While transformative, a number may end up being more staid than they appear at the moment. There\'s a risk that the colorful and exciting vision of the metaverse escapes the actual economics of operating the blockchain infrastructure. Indeed, the most successful blockchains will likely become utilities.\\n\\n\\nInfrastructure businesses often boom early but over time tend towards steady but normal profit levels. In the United States, the opening of the Baltimore and Ohio railroad in 1827 began a boom in railroad construction that would last for over 60 years. The railroads were tremendous investments, but their real value was in opening up hundreds of millions of acres of farmland, thus lowering the cost of food and creating national sales markets which let every good enjoy economies of scale. As railroad construction boomed, however, competition eroded railroad profits and value was transferred to consumers and bystanders. As the railroads became infrastructure, the growth in value shifted towards those who were able to leverage the structure for growing businesses. In other words, as the railroads became infrastructure, you didn\u2019t want to be a rail operator, you wanted to be Sears, Roebuck and Co.\\n\\n\\nYou may think financial \\"rails\\" are different. They aren\u2019t. You may think you have time, after all, the railroad bonanza lasted for a century. You don\u2019t. The rate of change is speeding up.\\n\\n\\nThere is lots of money to be made in the heyday of an infrastructure play, but the opportunity can vanish fast, especially in the age of digital abundance. By way of comparison, the window of opportunity for Internet Service Providers in the early 90s shrunk by a factor of 10\\\\. What took 60 years for railroads took 6 years for ISPs. When the government\'s Arpanet opened up access to the general public, a new land rush took place. Everyone who was operating bulletin board services began jockeying to provide dialup access to the Internet. The hottest skills on the market were not only software programmers, but also electrical engineers for wiring up banks of telephone switches. Real estate near points of access to phone exchanges went for premium.\\n\\n\\nWhere are the names of the early ISPs today? Your equity in Compuserve, The World, Prodigy, or Earthlink did not earn you any stake in Google, Amazon, or Facebook. Over the next decade, the telecom engineers did not receive the same life-changing stock options their web developer peers did. The one notable exception was AOL, which avoided obscurity by buying Time Warner, and eventually being gobbled up and then spat out by Verizon, an infrastructure company. The AOL story is noteworthy because they tried in many ways to make the leap from the infrastructure layer and capture the application layer (with the ultimately misguided tactic of creating a walled garden) .\\n\\n\\nFor digital asset cooperatives to make the leap from billing for ledger access to providing consumer surplus, the economics of the blockchain of today need to be anchored on solid economic principles. The blockchains that succeed will be the ones that transfer the most value to the structures that build on top of them. Blockchains as infrastructure means creating user experiences where the blockchain technologies become transparent to the user. The boom may not last, but it can be the foundation for continued growth and utility. The railroads, after all, never went away and continue to be critical to the world economy.\\n\\n\\nIn the coming decade blockchains will see a number of changes and they will cement their place in society as infrastructure. The value of access to the ledgers, and the flows to capital, will increasingly resemble traditional economic assets. Like dialup networks, transaction fees on blockchains will fall to negligible amounts given advances in high-throughput blockchains (which will become commodities because of open source software).\\n\\n\\nYour digital asset collective may want to be more than a reliable infrastructure business. Yet capturing value on the application layer of blockchain is less than obvious. The (regulatory compliant) mechanisms don\'t yet exist, but the collective can future-proof its layer-1 economics to create optionality to escape a lackluster infrastructure fate in a world where the\xa0[fat protocol thesis (an idea that enterprise value accrues into a vertically integrated settlement layer) proves hollow](https://www.usv.com/writing/2016/08/fat-protocols/). The value is likely to be modular and decentralized, not monolithic and bundled.\\n\\n\\n## Part II - Principles for Future-Proofing Your Blockchain\\n\\n\\nFor a time, exuberance will mask the realities, but eventually, the community of holders of a chain\u2019s native asset will need to make a leap. When transaction fees fall off the cliff, the collective will need alternative business revenues; simply selling access to the ledger will no longer produce attractive returns. We think the blockchains that survive the coming crisis will be built on the following principles.\\n\\n\\n### Don\'t Eat Your Seed Corn\\n\\n\\nIn most protocols we observe a confusion between capex (capital expenditures), and opex (operational expenditures). Payment for security in the moment, an operating expense, is not equivalent to investment in future security, a capital expenditure.\\n\\n\\nTo illustrate, imagine the blockchain as a physical notary business. As is the case in many countries in South America and Europe, private companies can acquire a concession to store and provide access to contracts, land records, birth certificates, etc. The business has a finite budget. It can invest in security guards to stand outside the entry, or invest in physical vaults and computer systems. As with any business, there are strategic considerations and ultimately it will have to employ a mix of both outflows.\\n\\n\\nPaying security guards is a certain kind of recurring outflow - an operating expense. The costs appear in the same part of the income statement as expenses like phone systems, administrative staff, executive travel, etc., that is, activities (expenses) deemed necessary for the business. Opex should not be confused with outflows of capital made for investment purposes; that is capital expenditures. Capex is different (for example it doesn\'t even appear on an income statement); it\'s part of the value of the company (balance sheet) which is transferred between assets. You are trading the cash assets of today for future productive resources, e.g., by investing in new factory machinery, delivery vans, document vaults, etc.\\n\\n\\nThe capex/opex distinction is not an accounting gimmick---confusing them is the downfall of many a business tycoon. No amount of paying for security guards would obviate the need for an investment in a new vault. The owner of the notary needs to set aside cash, equity, debt - whatever instrument - to pay for the capex. Startups a la Silicon Valley, pay for initial capex (acquisition of talent, software, R\\\\&D) with equity. However unfair, the labor market does not often make errors, and the people who accrue the most equity from the market are leaders and engineers, not security guards.\\n\\n\\nIn blockchain, paying for moment-to-moment security is done with transaction fees to miners/validators. In the absence of these transaction fees, there are subsidies to cover for the market cost of providing network security, lest the network risk losing its perceived integrity.\\n\\n\\nFor much of the first decade of blockchain, the future investment in the protocol was done on the basis of the \\"enlightened self-interest\\" of the early security guards of a chain. The logic goes as follows: The security guards amassed such a large equity in the notary business, that they now were the primary stakeholders, and as such had the incentive to reach into their pockets to recapitalize the notary, who had gone delinquent in its capital investments. Paying security guards in the hope of them later contributing to paying for your vault is circuitous and risk-prone. If the coins are readily and easily tradable, the dominant strategy is to dump and move on to the next chain when you notice capex being under-capitalized.\\n\\n\\nA protocol needs to be careful that the opex does not eat up the capex. The more cash you spend on opex the less you have for capex. The equity you issue to security guards dilutes the engineers and that\'s before we consider intergenerational fairness. Time compounds these losses: When dilute your brother with a drop, you dilute his grandchildren in buckets.\\n\\n\\nWe are not trying to be obtuse or sanctimonious, but rather point out a structural problem that could prove fatal to protocols that mis-invest their cash flow in a philosophical concept, rather than in building useful applications. A new protocol seeking to be lasting and fruitful needs to have a sustainable long term investment model. While solutions are difficult to come by, meaningful experiments are taking place.\\n\\n\\nA number of protocols approached this problem by dedicating funds (or \\"founder rewards\\") to \\"foundations\\", but this then started attracting regulatory scrutiny. A later variation saw some chains implementing \\"decentralized treasuries\\" to make decisions on work that needs to be done (e.g.,as in Tezos, Cosmos, et al). While there are still regulatory overhangs here, and a trend toward bureaucracy, this is directionally the right move.\\n\\n\\nDigital asset cooperatives need to stand firm and preserve the capex games they create. Issuing new coins -- like issuing new equity -- is an invisible diluent, and it mostly hurts those who are not minding it. There will always be relenting and incessant requests to spend more today on opex. Don\'t confuse your opex for capex. Don\'t eat your seed corn.\\n\\n\\n### Produce consumer surplus\\n\\n\\nGenerally speaking, blockchains should aim to maximize consumer surplus; that is, the difference between the value a consumer places on a good and its price. Maximizing consumer surplus means increasing the value of a blockchain to consumers and keeping prices low so that the bulk of the tremendous potential from blockchains flows to consumers. Ensuring that gains flow to consumers requires competition and a blockchain design that doesn\u2019t create artificial rents or bottlenecks that can be exploited by rapacious actors.\\n\\n\\nIt\u2019s widely acknowledged that the current payment infrastructure is slow and expensive, especially for international transactions. In contrast, a million dollar transaction can clear across a blockchain in minutes at a price of pennies. The claim is true, but it rings false when transaction fees on popular blockchains are high and variable, with spikes of $10, $100, or more, not uncommon for a single transaction.\\n\\n\\nA usable blockchain integrated with the real world must produce fees that are low. Low and consistent is ideal. Low and variable is ok. High and variable, however, is a problem. This is both a user experience and a negative network effect problem.\\n\\n\\nConsumer surplus is maximized when every consumer who values a good at more than its cost is able to purchase. In a competitive, well-functioning market, price (P) approaches the marginal cost (MC) of production. Consumers who value the good more than its price purchase the good and when P\\\\=MC. It follows that every consumer who values the good more than its cost purchases the good. If the price were above MC, too few consumers would purchase and if the price were below MC (say because of subsidies or non-price allocation) too many consumers would purchase. P\\\\=MC is the ideal. (There are, of course, well known exceptions to deal with cases of externalities and large fixed costs. We focus on the base case for clarity.)\\n\\n\\nSuppliers would prefer P\\\\>MC, which happens when markets are monopolized or otherwise broken. The US medical system, for example, is dominated by rents and bottlenecks that push P\\\\>MC and which have been exploited by\xa0[the Shkrelis of the world](https://www.nytimes.com/2015/09/21/business/a-huge-overnight-increase-in-a-drugs-price-raises-protests.html). US housing markets are similarly broken by zoning and regulations that prevent building even in places where prices are well above the costs of production.\\n\\n\\nTo fulfill their promise, blockchains must onboard billions of people into a new, lower cost financial system (as a first step!). Onboarding billions of people will happen only when P\\\\=MC, that is, when the price of using a blockchain falls to its true cost of production. To get there, blockchains have to be designed to operate at their maximal technical limits and not be throttled back in order to create rents. Blockchains must also surface information and not incentivize the creation and exploitation of information asymmetries. Everyone must have access to a blockchain on an equal footing.\\n\\n\\nIn addition to keeping prices close to marginal cost, blockchains should be designed to increase value to consumers. Blockchains, as with other platforms, can be designed to maximize eyeballs, or information collection, or surveillance--techniques which can increase producer profits. In the short run, profits can attract investment and customers, but in the long run, a blockchain built for producers leaves a dissatisfied public only slightly better off than before.\\n\\n\\n### Maximize the correct resource\\n\\n\\nBlockchains have attracted attention because the sector has produced outsized financial gains. These gains, however, are merely the promise of future value. As the technology matures, financial gains will diminish and gains to consumers will grow. We want to build the future in which consumers devote an ever-larger share of their time and contribution to the globally connected online world.\\n\\n\\nSecurity and decentralization are important for the bootstrapping and running of the network. As we put it earlier, the utilities must work reliably and we want a six-sigma blockchain. Most of today\u2019s crypto industry revenues, however, flow to trading and mining as built-in economics, which leaves little room for rewarding the builders who make the things people love. We want to create organic incentives that benefit the builders and the users -- the economic actors rather than the security and rule enforcers.\\n\\n\\nA blockchain collective should aim to allocate funding to the building of an open and expressive space where people have the capacity to organize themselves around their shared interests, activities, outcomes, etc, and instantiate that as software, games, and economies. To make things, people have to choose to invest their labor in a protocol, and we want the protocol to be able to reward them for that labor and investment (rather than a venture fund which owns their equity, whereas the protocol is a community that generates public goods).\\n\\n\\nWhether one calls it the global village, cyberspace, or the metaverse is immaterial. Moving forward, the key idea is to assemble and reward the people who generate value in the new world.\\n\\n\\nFinancial incentives are one method of attracting time and attention but are not the only nor always the best method. Paying fruit pickers per fruit will increase the number of fruits picked per hour but the fruit may be picked too early or too small. Thus, even in a simple task such as fruit picking, financial incentives must be combined with other methods of encouraging productivity such as monitoring or profit-sharing.\\n\\n\\nThe key problem with financial incentives is that you get what you pay for but what you can pay for is not necessarily what you want. As a result,\xa0[financial incentives must be used with care](https://vitalik.ca/general/2021/09/26/limits.html)\xa0especially for complex, multi-dimensional tasks where monitoring and measuring are difficult. Said differently: algorithmic and programmatic distributions are very unlikely to be maximizing the correct resource.\\n\\n\\n### Integrate with the world\\n\\n\\nIt was natural for early innovations in the digital space to position themselves against the world. Most famously, John Perry Barlow offered\xa0[A Declaration of the Independence of Cyberspace](https://www.eff.org/cyberspace-independence)\xa0in which he declared:\\n\\n\\n\\n> Governments of the Industrial World, you weary giants of flesh and steel, I come from Cyberspace, the new home of Mind. On behalf of the future, I ask you of the past to leave us alone. You are not welcome among us. You have no sovereignty where we gather.\\n\\n\\nFor better or worse, Barlow was wrong. Governments have power even in Cyberspace because people want to integrate their real lives and online lives. Similarly, if a blockchain is to remain relevant, it must integrate with the real world. The metaverse, so to speak, is not only a digital simulacrum, but also an online world synthesized with the quotidian. Integrating with the real world means considering the existing rules of the road.\\n\\n\\nDesigning for the environments people live in is a question of user-experience. With everything UX, there are tradeoffs. While securities laws need to change to keep pace with new technologies, like it or not, the regulators are an agent in your game. While it is possible to design games that flaunt regulators, this exposes less adventurous users -- the next billion -- to unnecessary duress. Following existing law, especially US law, restricts some of the economic mechanisms which would be effective. The absence of ambiguity however should not be seen as a limitation; on the contrary, it should allow the protocol to be practicable and useful to future denizens of the metaverse. This is not an admission of defeat, it is actually an aggressive stance, positioning for exponential growth.\\n\\n\\nFor the same reasons, economic mechanisms must be understandable. Mechanisms (i.e., the rules for which rewards are given) are what guide users, validators, and investors across language and other barriers. Good mechanism design incentivizes the crowd to \\"do the right thing\\". People need to know what activity they are to do, and what they should expect as a result. As is well documented in cognitive science research, humans are limited in their ability to\xa0[navigate optionality](https://thedecisionlab.com/reference-guide/economics/the-paradox-of-choice/), they place a\xa0[lot of value on labels instead of mechanics](https://journals.sagepub.com/doi/abs/10.1177/0146167204264004), have\xa0[non-obvious responses to price information](https://en.wikipedia.org/wiki/Forced_compliance_theory#Festinger_and_Carlsmith), are\xa0[notoriously bad at planning for the future](https://www.nber.org/bah/2016no1/how-biases-affect-retirement-savings),\xa0[etc. etc.](https://en.wikipedia.org/wiki/Cognitive_bias#List_of_biases)\xa0Given that context, if your incentive model doesn\'t match peoples\u2019 intuitions, you should expect erratic, random behavior from the majority of your players and exploitation by the minority of informed insiders.\\n\\n\\nSometimes the best incentive is to make doing the right thing easy and obvious."},{"id":"/thedefiant","metadata":{"permalink":"/blog/thedefiant","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/thedefiant.md","source":"@site/blog/thedefiant.md","title":"0L Aims To Revive Facebook\u2019s Libra Cryptocurrency With Fair Launch","description":"Every now and then folks adjacent to crypto Twitter like to tweet out some version of \u201cRemember Libra?\u201d. Libra was Facebook\u2019s first effort to get in on the decentralized web, with a bold promise to \u201cbank the unbanked\u201d via blockchain that was revealed in mid-2019\\\\. The world\u2019s largest social network caved into regulatory pressure and gave up on its higher-end ambitions less than a year later.","date":"2021-11-16T00:00:00.000Z","tags":[{"inline":true,"label":"news","permalink":"/blog/tags/news"}],"readingTime":0.36,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"0L Aims To Revive Facebook\u2019s Libra Cryptocurrency With Fair Launch","date":"2021-11-16T00:00:00.000Z","tags":["news"]},"unlisted":false,"prevItem":{"title":"Future-Proofing the Economics of Blockchains - Part I and II","permalink":"/blog/future-proofing-the-economics-of-blockchains-pts-1--2"},"nextItem":{"title":"Libra Liberated","permalink":"/blog/libra-liberated"}},"content":"\x3c!-- truncate --\x3e\\n\\nEvery now and then folks adjacent to crypto Twitter like to tweet out some version of \u201cRemember Libra?\u201d. Libra was Facebook\u2019s first effort to get in on the decentralized web, with a bold promise to \u201cbank the unbanked\u201d via blockchain that was revealed in mid-2019\\\\. The world\u2019s largest social network caved into regulatory pressure and gave up on its higher-end ambitions less than a year later.\\n\\n[Read Full Article](https://thedefiant.io/0l-libra-fork-fair-launch/)"},{"id":"/libra-liberated","metadata":{"permalink":"/blog/libra-liberated","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/libra-liberated.md","source":"@site/blog/libra-liberated.md","title":"Libra Liberated","description":"There once was a community that wanted a blockchain.","date":"2021-11-15T00:00:00.000Z","tags":[{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":9.28,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Libra Liberated","date":"2021-11-15T00:00:00.000Z","tags":["canonical"]},"unlisted":false,"prevItem":{"title":"0L Aims To Revive Facebook\u2019s Libra Cryptocurrency With Fair Launch","permalink":"/blog/thedefiant"},"nextItem":{"title":"Part 3 - A Delay Towers Implementation on BFT","permalink":"/blog/delay-towers-pt-3-implementation-on-bft"}},"content":"\x3c!-- truncate --\x3e\\n\\nThere once was a community that wanted a blockchain.\\n\\n\\nIts members wanted to be a part of the coming transformation of society.\\n\\n\\nThis is the story of how they got their chain, and why you might want to join them.\\n\\n\\n## The Opportunity\\n\\n\\nDecentralized architecture, coupled with the power of smart contracts, is a once-in-a-century opportunity for society: It is far more than programmable money, it is a canvas for valuable human interactions.\\n\\n\\nThe opportunity is materializing now. While the common narrative is that it is still \u201cearly days,\u201d the reality is that the value of individual crypto networks reach toward, and even surpass, one trillion US dollars. As such, the budgets to enter this space and stay relevant are astronomical and ever-increasing. It is possible that the leading platforms of today, and their stakeholders, will permanently dominate the space. And that\'s even before the roll-out of corporate and national blockchains.\\n\\n\\nIt can certainly seem like there is not much low-hanging fruit for anyone that has been left out of this story so far. The window to build a new meaningful network is closing.\\n\\n\\nBut there is one unusual (perhaps unique) opportunity left.\\n\\n\\n## The Game\\n\\n\\nIf you\'re new to the blockchain space, you will soon learn that the technology is not \\\\*the product\\\\*. The product is the game the technology enables.\\n\\n\\nThe players, the interactions, and their outcomes, are the design elements of blockchain. And there are many ways to craft gameplay.\\n\\n\\nBlockchain networks inherit an ethos from their creators. Communities -- and their norms and goals -- precede the technological artifacts of a chain. Perhaps then it is not surprising that many groups design their game to reflect existing patterns and myths. You can, for example, design a blockchain where the economic game resembles a corporation, maximizing profit for winners with exit strategies. Or you can design what is called an \\\\*infinite game\\\\*; a framework that perpetually sustains new players, new rules, new settings, and new possibilities. We think infinite games depend on people opting-in out of excitement, and not out of lack of alternatives, or fear of missing out.\\n\\n\\n**We wanted to create a game that anyone could play; a game everyone would want to keep playing.**\\n\\n\\nBefore Silicon Valley built Robinhood the company, there was Robin Hood the legend. The story is set in a kingdom whose king is absent, off fighting distant crusades. The young prince, a usurper of power, has occupied the void and turns ordinary life into a hopeless maze. In the depths of this unfortunate situation, a group of individuals arise who take exception to the status quo and attempt to rebalance power and equity.\\n\\n\\nThis story is timeless. It has a villain who we all recognize. The usurper is familiar across centuries; it changes in name only: sovereigns, incumbents, bureaucracy, big-tech.\\n\\n\\nThe legend lives on not because a single player wins, but because the circumstance of inertia, subjugation and injustice recur. The winner is the Robin Hood game itself. Humanity perpetually plays it; an infinite game.\xa0**The rules of play are simple. You can take from authority, if you give back to your people. You should aim to do well for yourself, whilst remaining a fun-loving rascal.**\\n\\n\\n## Snatch the jewels\\n\\n\\nIn June 2019, something curious happened: A consortium of the most powerful financial and technology houses on the planet banded together to build a new, global cryptocurrency, prompted in their efforts by Facebook. They preached equality and financial inclusion, with assurances that decentralization of this network was just a matter of time.\\n\\n\\nAs the project progressed, things began to change and a grimmer reality set in. What began as a blockchain-powered digital currency aimed to improve financial inclusion became a payment network governed exclusively by incumbent corporate actors and enterprise compliance requirements.\\n\\n\\nBehind the scenes, away from the growing controversy about money and regulation, a talented group of engineers was creating breakthrough technologies. To make this planned digital currency work, for the scale of billions of users, they built a bejeweled blockchain. It was a blockchain as fast and secure as anything in the market. Most importantly to this story, they released that code under an open source license for others to modify and remix. It was called Libra (later renamed, Diem).\\n\\n\\nThe situation created an inherent contradiction. While the code was open sourced, the network that ran the code was fundamentally closed and controlled exclusively by a private consortium of big brand actors who were required to provide large pools of capital for membership.\\n\\n\\n**We didn\'t think that was right, so we jailbroke Diem.**\xa0We forked the open-sourced Libra code back in 2019, and kept up with the changes under its new name, Diem. Since then thousands of developer hours have gone into making that code ready for release. We are now ready to share it with you. We call it 0L, not only the 0th Libra-consensus blockchain, but also an open Libra network.\\n\\n\\n**0L\u2019s vision is to turn that jewel of a blockchain, and the network which it instantiates, into something that is open, permissionless, participatory, and egalitarian.**\\n\\n\\nThis was hard work, and took two years to complete. The job was far more complex than simply making a copy of source code. The original project was designed to be run on a private network with a tightly controlled set of economic incentives that vested power and economic return solely in the network operators. A new economic model had to be designed, a new Sybil resistance algorithm invented (Delay Towers), and a number of related mechanisms had to be adjusted to optimize performance under these new conditions. The result is thousands upon thousands of lines of new code designed to make that blockchain fit for use in a public network.\\n\\n\\n## Genesis\\n\\n\\nJust a couple weeks ago, on October 27th 2021, a new network genesis took place. It is a blank canvas. This blockchain network is maximally compatible with Diem, but capable of permissionless innovation and decentralized economies.\\n\\n\\nThere are millions of people working in crypto today. We need billions. To get there, the protocol must be safe for use, and avoid a variety of attack vectors. Stated differently: We need to protect the game.\\n\\n\\nPaying homage to Bitcoin, 0L went back to the basics: There is no pre-mine, no corporations, no investors, and no permission.\\n\\n\\n* We chose to stay close to Bitcoin\'s model.\\n* There\'s a foundation which pays for Github hosting, and does nothing else.\\n* Early miners didn\'t take any VC money.\\n* 0L doesn\'t use proof-of-stake.\\n* We skipped the DAOs controlling a treasury.\\n* Coins don\'t buy shareholder votes.\\n* There was no ICO, nor an airdrop.\\n* There were no side-deals with exchanges.\\n* No market-making.\\n\\n\\nIf your instinct was to say a network without those activities is not viable, you are squarely wrong.\xa0**It is 0L\'s superpower. No one should be looking over their shoulder at governments because they participate in a protocol.**\\n\\n\\n## Do well\\n\\n\\nIf you ever wonder what opportunities are left for entrepreneurs in the world, we urge you: Look for the \\\\*negative space\\\\*.\\n\\n\\nCompanies and governments will not do - or cannot do - all the things we want from life. In this void lie an endless amount of problems at the intersection of information, economics, and social coordination. This is all of humanity\'s unfinished work; a vast negative space which the markets and sovereigns have weak dominion over.\\n\\n\\nWhat are the things you expect from the government but can\'t get? What then do you need to acquire from companies but are inadequate? Depending on where you live, making progress in healthcare, education, justice, news, or voting, can feel hopeless.\\n\\n\\nHope comes to us in the form of new economic games we can play because of blockchains. Blockchain offers truthful notaries, durable memberships, transparent markets, and binding agreements. Modern economics provides new mechanism design gadgets: Prediction markets, Quadratic Voting, Dominant Assurance Contracts, Crowdsourcing, Curved Bonding, and things yet to come. The true potential is yet to be unlocked, to be imagined and instantiated by you and this growing community. Today, we merely lay a foundation upon which you can build.\\n\\n\\nThis is the entrepreneurial blue ocean of our time, however solving these issues may not lead to viable startups. That\'s perfect! This is the domain of \\\\*the thing that comes after companies\\\\*. We are all so early that there is not yet a good name for it. Web3 and the multiverse are still mere shadows flickering on the wall.\\n\\n\\nDon\'t try to replace companies, they are good at what they do. Don\u2019t pick fights with nation states that provide for their citizens, however inefficiently. Instead, go do the things they cannot.\xa0**Mechanism designers are the new entrepreneurs. Design the negative space, and become the social architects in the era of blockchains.**\\n\\n\\n## Do good\\n\\n\\nWe live in a society, and we must be wise towards each other.\\n\\n\\nSince 0L is based on an existing open source license, and it arrived to us freely, all members must think critically about the value inherent in the technology, and the potential which it can produce. How should we distribute that potential? On 0L there\'s wide latitude to craft a better distribution game \\\\*because\\\\* the network is unencumbered by the pressures of generating a return to corporate and venture investors.\\n\\n\\n0L makes it easy for you to decide if and how to share your mining rewards. Using auto-pay, all node operators have the option to donate a meaningful portion of their node\u2019s earnings to support a variety of programs, so that donating activities in the community (and beyond) is frictionless. You can auto-pay to your team, to your tribe, or to a cause. In our experimental network, we observed node operators donating on average over 50% of their mining rewards. This was not just toward the sustainability of the blockchain (engineering programs), but also humanitarian programs and baskets of high-impact nonprofits.\\n\\n\\n## Underdogs have more fun\\n\\n\\nAmong other things, Bitcoin is a weird and wonderful prank on sovereign power. There are many other powers-that-be which deserve the same treatment by a merry band of rascals.\\n\\n\\nJailbreaking Libra/Diem was not a quick win. The fun started almost three years ago by many volunteers coding and puzzling over the technology. We successfully ran a real-world experimental network for nearly a year. We could have launched with that network, and we could have done a pre-mine, but we didn\'t because it\'s just less fun for everyone. We sunsetted the test network, and started a blank gameboard with you in mind.\\n\\n\\nWith that done, the real fun can begin. Your first mission? Take the prince\'s jewels.\\n\\n\\nDownload an early beta release of \\\\*Carpe\\\\*, a light miner that you can run on your laptop and make coins. There\'s nobody you need to pay to get coins, no company to ask permission from, and most importantly: No one that can take this back from you.\\n\\n\\n[https://github.com/0LNetworkCommunity/libra\\\\#readme](https://github.com/0LNetworkCommunity/libra#readme)\\n\\n\\nThe future missions are entirely up to you. Crypto are the in-game points for the real world.\\n\\n\\n**Game it, play it, carpe diem \u270a\u2600\ufe0f ,**\\n\\n\\n\\n> - Otto"},{"id":"/delay-towers-pt-3-implementation-on-bft","metadata":{"permalink":"/blog/delay-towers-pt-3-implementation-on-bft","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/delay-towers-pt-3-implementation-on-bft.md","source":"@site/blog/delay-towers-pt-3-implementation-on-bft.md","title":"Part 3 - A Delay Towers Implementation on BFT","description":"TL;DR","date":"2021-11-12T00:00:00.000Z","tags":[{"inline":true,"label":"Delay Towers","permalink":"/blog/tags/delay-towers"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":13.145,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Part 3 - A Delay Towers Implementation on BFT","date":"2021-11-12T00:00:00.000Z","tags":["Delay Towers","canonical"]},"unlisted":false,"prevItem":{"title":"Libra Liberated","permalink":"/blog/libra-liberated"},"nextItem":{"title":"Part 2 - From Puzzle Towers and VDFs to Delay Towers","permalink":"/blog/delay-towers-pt-2"}},"content":"\x3c!-- truncate --\x3e\\n\\n## TL;DR\\n\\n\\nDelay towers provide many benefits to BFT networks, including diverse distribution of participants, Sybil resistance, eco-friendliness, determinism, and others. This post delves into one specific implementation of delay towers and its integration with a high-throughput BFT network for bootstrapping purposes, and offers it as a strategy to achieve the goals of a free and fair chain launch.\\n\\n\\n## Context\\n\\n\\nIf you followed the previous parts, you\'ll recall that we are using delay towers to bootstrap a new blockchain with the following properties:\\n\\n\\n* High-throughput\\n* Fast finality time\\n* Fair launch\\n* Permissionless access\\n* Engender decentralization with equitable distribution\\n\\n\\nA blockchain protocol can use delay towers to establish persistent identity for the nodes as a Sybil resistance mechanism. Delay towers serve as a proof of elapsed time (PoET) to complement BFT consensus, providing a mix of security and performance benefits that PoS ordinarily provides while preserving regulatory benefits of PoW and lowering barriers to distribution. This post delves into one specific implementation of delay towers to envision how all the pieces of delay tower and BFT fit in.\\n\\n\\n## Delay Towers Implementation\\n\\n\\n### VDF Implementation\\n\\n\\nThe growing demand for VDFs for applications, such as randomness beacons, has led to various implementations of VDFs. The current protocol uses Chia\'s VDF implementation. Chia sponsored some of the early work around VDFs and has an actively deployed open-source implementation with benchmarking. Another notable implementation is Stark VDFs that use computational integrity proofs such as Starks, pioneered by Starkware with VeeDoo service on Ethereum. Other VDFs include RSA moduli and trusted setups which are yet to be deployed in the wild.\\n\\n\\n### Anatomy of a Delay Tower\\n\\n\\nNodes run the delay function locally, offline, using the \\"tower-builder\\" application to produce a\xa0*proof\\\\_0*\xa0file. The proof file consists of:\\n\\n\\n* A Preimage with account authorization key (public key), the chain ID with an arbitrary state of the ledger\\n* The hex encoded bytes of the proof of the delay.\\n* The metadata, such as the delay time.\\n\\n\\nThe preimage serves as the base identity for which the remainder of the delay tower will be referencing. Ultimately the preimage is committed to a chain, and the state machine will verify that the preimage belongs to an account on the chain.\\n\\n\\nAll the subsequent proofs will use the preceding proof\'s SHA256 hash as an input for evaluating their delay functions; the \\"tower-builder\\" application builds new proofs on top of existing proof to grow the delay tower. Each new block is then submitted to the chain (\\"committed\\"), and thus verified as (A) being a valid proof of elapsed time and (B) being contiguous with the previous proof committed to the chain - thus giving a linear path back to the original preimage. The proofs do not need to be stored on chain after they have passed those two approvals. Only the current proof\'s hash needs to be persisted on the chain, in anticipation of the next proof which will be verified.\\n\\n\\nAs for the state of the tower, the delay tower is stored locally on the node as a repository of JSON proof files. Each proof takes approximately 4kB. The tower state lives off-chain, which the user stores on their node and is responsible for backing up. This would allow for the user to replay the entire tower history if there was a need to do so (e.g. using as identity proof on another chain, or in the event of the principal chain\'s catastrophic failure).\\n\\n\\nThat said, additional governance is necessary to prevent outliers from exploiting validator set admission and consensus voting power (as discussed further below). As we\'ve seen, above, the state machine encodes certain rules for the submission of the tower. Upper and lower-bound threshold of proof counts can be employed.\\n\\n\\nFor upper bounds, for all accounts on chain (whether a validator or not) the state-machine will outright reject proofs after an excess amount of proofs have been submitted in a given epoch (one day in our case). This is an important check to remove outliers which can happen due to either: Exploits in the cryptography (which as yet undiscovered) or advances in hardware that would allow for order-of magnitude improvement. The upper-bound disincentivizes such investments.\\n\\n\\nSimilarly, additional rules exist for a lower-bound. The chain may disconsider \\"sufficient\\" proofs as having been submitted for certain cases. For example a minimum number of proofs per epoch would be necessary to join a validator set for the first time, be removed from \\"jail\\" for non-compliance, or simply in order to remain in the validator set, etc. This is discussed further, below. While in the experimental network these thresholds are hard-coded and can be changed by protocol upgrades, future implementations can make such VDF thresholds dynamic, varying according to current system state.\\n\\n\\nThe description above sketches out the lifecycle of an individual delay tower. Let us examine how it integrates with a BFT blockchain chain.\\n\\n\\n## Network Genesis\\n\\n\\nAt the genesis of a network, the BFT chain needs a defined set of validators in the system state. Different genesis \\"ceremonies\\" are possible in creating BFT networks. In Proof of Authority, a centralized entity simply provides a genesis \\"layout\\" with the nodes that are to participate.\\n\\n\\nCoordinating a network genesis such that it is permissionless requires some infrastructure in order for nodes to make themselves candidates for genesis (registration). Usually a Github repo is used for this purpose. Once all the registrations are present, individual node operators will use a layout file with the registrations that they would like to see included in the first block of the network. In the case of using a delay tower, their proof\\\\_0 can be included in the registration information.\\n\\n\\nDuring the registration period, the validators candidates will generate offline and submit proof\\\\_0 along with their node configurations (such as network and public keys) to the ceremony repository. After the registration period closes, each node participating in genesis will use a genesis building tool to produce the first block of the network. Note that the genesis block does not need to be produced by one entity, each node in the new network can create the genesis.blob independently for a fully decentralized ceremony. One of the steps of the tool in our case, is to run a VDF \\"verifier\\" that confirms that proofs of each registrant indeed correspond to an expected delay and that the preimage of proof\\\\_0 belongs in fact to the registrant. At the end of the process the genesis block for the network is produced. In this proposed implementation, a successful bootstrapping requires neither pre-mining, a coin drop, nor any other means of distributing the necessary starting stake(s).\\n\\n\\n## Steady State\\n\\n\\n### Onboarding Nodes\\n\\n\\nAs in the genesis ceremony, each new prospective validator node (a node that wishes to enter a validator set) needs to submit configuration information to the network. After genesis, the only way of doing this (in any account-based blockchain) is to have an existing account create the new prospective account and optionally, send the configuration information on behalf of the prospective validator. For this to take place, the prospective validator must generate\xa0*proof\\\\_0*\xa0locally and transmit it (out of band) to an existing account to initialize its configurations. As discussed below, further governance can be added to the account creation, such as requiring these accounts to be created by existing compliant validators, and rate-limiting the account creation by the onboarder account.\\n\\n\\nIn a single step, one transaction, the onboarder can submit the validator\'s configuration information and the\xa0*proof\\\\_0*\xa0(whose delay can be verified on chain via the transaction). Assuming all configuration information is valid (such as network settings) and the\xa0*proof\\\\_0*\xa0is verified the prospective validator can become a candidate to enter the validator set.\\n\\n\\n### Mining\\n\\n\\nThe governance can decide at what point the validator can join the validator set. In this proposal, the validator candidate needs to continue to produce proofs for a full day (one epoch) before they are admitted to the validator set.\\n\\n\\nTo grow their delay tower, nodes run a \\"tower-builder\\" app. Running the \\"tower-builder\\" application is called mining. The tower-builder operates in parallel to other node operations, e.g. the consensus node executable runs in a completely separate process. The tower-builder could in fact be run in a separate environment as the consensus process.\\n\\n\\nFrom this point on, the miner is building the delay tower. The miner submits the VDF proofs and the chain state machine verifies the correctness of submitted VDF proofs. However, for the node operator the quantity of proofs must be created within certain thresholds. These thresholds may adapt over time. But on bootstrapping the network, a generous threshold will make allowance for operator\'s adapting to this system. In this implementation, a minimum of 7 proofs need to be produced per epoch (approx 4 hours of proofs per day as measured on typical cloud hardware), but an upper bound of 72 proofs per epoch (e.g. 20mins per proof continuously running). This range will narrow as more system information is collected from real-world usage. Furthermore these thresholds can be dynamically adjusted, but further research is needed.\\n\\n\\nAs noted in the previous post, mining delay towers is not the same as PoW puzzles; it is sequential, cannot be parallelized, and has no advantage with heavy computational power. As a result, mining delay towers are indeed very eco-friendly.\\n\\n\\n### Consensus Voting Power\\n\\n\\nThe BFT protocol needs a supermajority to reach consensus on block production, and every validator has some \\"votes\\" in the consensus, called voting power. In this implementation, the tower height equals the voting power in the consensus. This is a deterministic and straightforward rule that is easy to verify.\\n\\n\\nOver time, the relative linear advantage of an early node decreases, and the marginal difference between a tower starting later, will decrease and voting power becomes more evenly distributed. This could be a benefit over PoS networks where reputation and rewards are directly dependent on the stake.\\n\\n\\nWhile a longer discussion is necessary on economics, it should be noted that tower height need not confer any economic advantages besides admission to the validator set. In this design, all the validators in BFT contribute relatively equally, and any major differences are often due to operator error. Hence, there\'s no need for consensus power to affect rewards for participating in the validator set (as is often the case for PoS).The rewards are shared equally among all the compliant validators.\\n\\n\\n### Cardinality\\n\\n\\nBFT network performance worsens if the cardinality of the validator set is too high; accordingly an upper limit on the validator set is needed. There are upper bounds to BFT network performance; there is a steep dropoff in network latency observed after 128 network nodes in most BFT consensus implementations. Thus the participation in the quorum set needs to be restricted.\\n\\n\\nDifferent BFT networks use different strategies to select the validator set, these are typically Proof of Stake (as pioneered by Cosmos). Variations incorporating some measure of randomness exist. The simple algorithm is picking the top N validators by Proof of Stake from the list of validator candidates.\\n\\n\\nDelay towers could provide an alternative. The consensus power, as defined by the delay tower height, can determine the validator set in a direct, observable, and deterministic manner Similar to the rule described above. The Top N validators by tower height gain admission to the validator set.\\n\\n\\nAgain while this is a separate discussion on economics, the design above is not entirely sufficient for game theoretical equilibrium since it would penalize new entrants who may be doing more delay proofs, instead of incumbents who may abandon running the tower-builder.\\n\\n\\nAs mentioned above thresholds can be enforced by the chain. A miner that intends to be part of the validator set needs to mine at least K proofs to state to gain admission in the following epoch. This is true for new prospective validators, as well as the existing validators.\\n\\n\\n### Jailing\\n\\n\\nBased on whether the validators are validating blocks (proposing and signing blocks) and/or mining, the validators could fall in one of these categories.\\n\\n\\n\\n\\n| Case | Validating blocks | Mining delay tower | Gets reward | Jailed |\\n| --- | --- | --- | --- | --- |\\n| 1 | Yes | Yes | Yes | No |\\n| 2 | Yes | No | No | No |\\n| 3 | No | Yes | No | Yes |\\n| 4 | No | No | No | Yes |\\n\\n\\nThe validators who are not validating blocks are not contributing to the consensus. This will increase latency. For instance, if a failed validator is chosen to propose the next block, the network has a timeout in that round instead of a new block. Even worse, if more than one-third of voting power is not reached, finality is affected. Therefore, this behavior must be disincentivized, and the validators who do not meet a threshold within an epoch are jailed. Note that the nodes that are not mining are not punished because they are not affecting the network.\\n\\n\\n### Rate Limiting Validator Entry\\n\\n\\nThe validator\u2019s entry into the network is an attack surface, including possible Sybil attacks. One potential approach, without PoS and an active centralized membership service provider, is to ask all existing validators to vote on the new validator. However, this approach could lead to encouraging validator-wide agreement (politics) for expanding the validator set. As an alternative, every validator could be rate-limited, and only those who are actively contributing (i.e., mining, and voting for 14 epochs) obtain an invite. This invite can be used to onboard a potential validator by initializing their validator configurations and these invites cannot be transferred or accumulated. At any point, there can be no more than one referral for a validator.\\n\\n\\nAssuming no more than one-third of validators are malicious, as the network grows from a seed root of trust (as all blockchains do), the damage a Sybil can conduct to consensus is limited; the sybil cannot amplify their consensus votes faster than the good actors amplify theirs. Rate limiting also prevents one actor (e.g., a \\"foundation\\") from assigning seats in the consensus since they are rate-limited as other actors.\\n\\n\\n## Benefits\\n\\n\\nThe implementations above are an experiment; a proposal on how to integrate Delay Towers into networks which typically are PoS or PoA Sybil resistant.\\n\\n\\nTo recap: bootstrapping a BFT network with delay towers has multi-fold benefits:\\n\\n\\n* Delay towers provide an equal playing field by making it hard to repurpose existing hardware, e.g., PoW ASICs.\\n* Bootstrapping a network without external capital or ICOs.\\n* Delay towers offer better distribution by lowering the barriers to entry. Can run on any commodity hardware.\\n* Similar security as PoS network during bootstrapping. With withdrawal limits in place, delay tower height correlates to the stake in native tokens in PoS systems.\\n* Delay towers provide a persistent identity that is hard to forge.\\n* Eco-friendly consensus with minimal energy usage.\\n\\t+ Determinism and hence, no wasted cycles\\n\\t+ Delay towers are sequential and are not parallelizable by nature.\\n\\t+ Upper limits on number of accepted proofs per epoch caps the arms race.\\n* Economics that are familiar to users of PoS networks. The rewards are distributed similarly to PoS networks, wherein everyone contributing to BFT consensus is rewarded.\\n\\n\\n## Conclusion\\n\\n\\nDelay towers envision a permissionless, durable, and non-forgeable identity which is fast to verify. This post delves into specifics of productionizing delay towers by integrating them into a BFT network. Delay towers serve as a persistent identity that can be used for consensus power while bootstrapping the network.\\n\\n\\n\\n\\n---\\n\\n\\n## Full Series\\n\\n\\n1. [A high-throughput chain with a fair launch](http://openlibra.blog/2021/11/01/delay-towers-part-0/)\\n2. [Puzzle Towers for BFT](http://openlibra.blog/2021/11/05/delay-towers-part-1/)\\n3. [From Puzzle Towers and VDFs to Delay Towers](http://openlibra.blog/2021/11/08/delay-towers-part-2/)\\n4. [Implementation on BFT](http://openlibra.blog/2021/11/12/part-3-a-delay-towers-implementation-on-bft/)"},{"id":"/delay-towers-pt-2","metadata":{"permalink":"/blog/delay-towers-pt-2","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/delay-towers-pt-2.md","source":"@site/blog/delay-towers-pt-2.md","title":"Part 2 - From Puzzle Towers and VDFs to Delay Towers","description":"From Puzzle Towers and VDFs to Delay Towers","date":"2021-11-08T00:00:00.000Z","tags":[{"inline":true,"label":"Delay Towers","permalink":"/blog/tags/delay-towers"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":6.47,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Part 2 - From Puzzle Towers and VDFs to Delay Towers","date":"2021-11-08T00:00:00.000Z","tags":["Delay Towers","canonical"]},"unlisted":false,"prevItem":{"title":"Part 3 - A Delay Towers Implementation on BFT","permalink":"/blog/delay-towers-pt-3-implementation-on-bft"},"nextItem":{"title":"Part 1 - Puzzle Towers for BFT","permalink":"/blog/delay-towers-pt-1"}},"content":"\x3c!-- truncate --\x3e\\n\\n## From Puzzle Towers and VDFs to Delay Towers\\n\\n\\n## TL;DR\\n\\n\\nBy extending puzzle towers with VDF, a delay tower becomes a permissionless and non-forgeable identity which is fast to verify. This is a form of sybil resistance, we don\'t observe in any other system. A delay tower becomes a permissionless and non-forgeable identity which is fast to verify. These properties make a delay tower unique, scarce, and perhaps valuable in its own right.\\n\\n\\n## Context\\n\\n\\nThe\xa0[first part](https://siasky.net/EABaWAXFy3Ztx1vVIpOfScjkRaTb1GrFeGRwqFKd6V-hAg)\xa0introduced puzzle towers for establishing a persistent identity in BFT blockchains. It concluded that using hash puzzles, practiced in PoW, would lead to an arms race in computing power leading to ASICs and mining pools. The goals are to avoid the arms race, to increase distribution, and additionally, the ideal puzzle should have the following properties:\\n\\n\\n1. Prevent creating significant advantage for high computing power\\n2. Instantaneous verification of the correctness of solved puzzle proofs\\n3. Work on a commodity machine without additional hardware\\n\\n\\nTo address these issues, in Part 2 we investigate verifiable delay functions as a means of enhancing puzzle towers.\\n\\n\\n## VDF 101\\n\\n\\n[Verifiable Delay Function](https://eprint.iacr.org/2018/601.pdf)(VDF) is one of the latest discoveries in cryptography, popularized by Dan Boneh, Joseph Bonneau, Benedikt Bunz, and Ben Fisch. It is a cryptographic primitive for providing a guarantee that a lower bound of time has elapsed.\\n\\n\\nVDFs are used to prove a delay in a verifiable manner. In other words, VDF slows things down by taking a specified number of steps to compute. VDFs satisfy two properties:\\n\\n\\n* **Sequentiality:**\xa0One cannot parallelize their computation.\\n* **Uniqueness:**\xa0Given an input, the output is unique and deterministic even though the proofs might vary.\\n\\n\\nVDFs are composed of three functions:\\n\\n\\n1. *setup()*\xa0- takes in system configurations and credentials to initialize.\\n2. *evaluate()*\xa0- the delay function which takes\xa0*t*\xa0sequential steps to compute.\\n3. *verify()*\xa0- a Boolean function to verify the correctness of the output and proof.\\n\\n\\nThe\xa0*evaluate()*\xa0function is the delay function which takes\xa0*t*\xa0sequential steps to compute and generates an output and a proof. In 2019, a\xa0[paper](https://eprint.iacr.org/2018/601.pdf)\xa0proposed a generalization of time-lock puzzles as a candidate for the\xa0*evaluate()*\xa0function. The function is given as follows:\xa0*f(x) \\\\= \\\\[x^(2^t)]*\\n\\n\\nThe final step in the VDF construction is the\xa0*verify()*\xa0function, responsible for verifying the correctness of output and proofs. The candidates for\xa0*verify()*\xa0were independently presented by\xa0[Wesolowski](https://eprint.iacr.org/2018/623.pdf)\xa0and\xa0[Pietrzak](https://eprint.iacr.org/2018/627.pdf)\xa0in 2020\\\\. The\xa0[implementation study](https://eprint.iacr.org/2020/332)\xa0states that the Pietrzak scheme is more efficient than Wesolowski as it takes less time to verify the correctness of the output and proofs.\\n\\n\\nThis section isn\'t an in-depth guide to VDF; instead, it evaluates VDF for its use with puzzle towers by creating a cumulative proof of elapsed time. To conclude, VDFs can take an arbitrary amount of time to be computed, serving as proof of elapsed time, and one can verify the proofs almost instantaneously.\\n\\n\\n## Extending the Puzzle Towers with VDFs\\n\\n\\nPuzzle towers prove the sequential work done. However, using PoW style puzzles gives undue advantage to better computational power. The design goal is to solve puzzles that prove work done or time elapsed. Several protocols have a variation on this, including\xa0[Solana\u2019s Proof of History](https://solana.com/solana-whitepaper.pdf)\xa0(PoH).\xa0Solana\u2019s white paper states that this approach needs all the steps in the sequence to be replayed for verifying correctness, which could be an expensive operation. VDFs help us establish an alternative to hash-based PoW that is both sequential and easy to verify. Currently, Chia uses VDFs in its core protocol, Proof of Time (PoT), to ensure consistency in block times.\\n\\n\\nSimply put, delay towers are created by replacing the puzzle in the puzzle tower with VDFs. The delay towers are a sequential series of sequential work. Every miner in the network initializes their delay tower by running a\xa0*setup()*\xa0function with their mnemonics and configurations. After setting up, the miner runs the\xa0*evaluate()*\xa0function locally, and this is the delay component to produce output and a proof. Every miner sends proof as a transaction to the network. The validators verify the correctness of proofs submitted by miners using\xa0*verify()*\xa0function. If valid, the validators update the miner state, i.e., increase the height of the delay tower for that miner and the hash of last verified proof on the blockchain. The miners need to use the hash of the previously verified proof as an input for evaluating the following proof, building a delay tower for that miner. As more and more proofs are submitted, the height of the delay tower for the miner rises. The height of the delay tower signals how long a miner has been mining proofs in the network, thus used for ranking the candidates for the validator set.\\n\\n\\nFrom the original design of puzzle towers, delay towers improves on:\\n\\n\\n* **Wasted cycles:**\xa0Eliminating randomness leads to determinism in increasing the tower height. VDFs cannot be parallelized, and they do not benefit significantly from alternative hardware such as GPUs. With reduced computational requirements, there are minimal compute cycles and hence, lesser carbon emissions.\\n* **Distribution:**\xa0Determinism leads to predictability for users not using specialized hardware, making it more inclusive.\\n* **Faster verification time:**\xa0Given a proof, VDFs are quick to verify. The validators verify the correctness on-chain as part of the protocol with minimal resources.\\n\\n\\nThis allows for a new Sybil resistance mechanism while overcoming the limitations of PoS based networks while bootstrapping a new permissionless blockchain ecosystem, with a fair shot at an equitable outcome for the participants over the course of history.\\n\\n\\n## Integration\\n\\n\\nThe delay tower in itself does not provide all the guarantees in isolation. The tower needs to be confirmed against a main blockchain regularly. With that in mind, many additional constraints can be added in smart contract logic, and even updated dynamically.\\n\\n\\nOne could set many parameters, perhaps even dynamically, such as the lower bound of time to compute a proof. The VDF\xa0*evaluate()*\xa0is configured to take 30 minutes to compute, and then\xa0*verify()*\xa0takes around 260 milliseconds to validate correctness.\\n\\n\\n* **Time:**\xa0Lower bound of of time to evaluate the VDF\\n\\t+ Increasing the threshold of time to an hour means that massive CPU harvesting attacks through zombie networks become infeasible since host systems are needed to be used for extended periods without the ability to parallelize the work.\\n* **Threshold of quantity:**\xa0Too many or too few proofs.\\n\\t+ To prevent very few proofs being created a minimum threshold per period can be included.\\n\\t+ Likewise an arms race scenario can be disincentivized by having an upper bound on proofs submitted in a period for a given benefit (e.g. this could gate subsidies, or even prevent entry into the validator set if it goes beyond the ceiling).\\n* **External information into the preimage:**\\n\\t+ Similar to Chia Timelords, a block header can be included in each VDF such that the user needs to wait for a block header before submitting a proof. The sequential nature of puzzle towers means that any excess proof done while waiting for the block header will not be valid.\\n\\n\\n## Conclusion\\n\\n\\nThere are some differences between a VDF (delay tower) and a proof-of-work puzzle (puzzle tower):\\n\\n\\n* Determinism - no randomness\\n* Lower bound on time\\n* No wasted cycles\\n* Sequential - cannot be parallelized\\n\\n\\nDelay towers based on VDF make it impossible to forge a tower in meaningfully less time than it took the original user, even for anyone with infinite capital and computational resources.\xa0**This is a form of sybil resistance, we don\'t observe in any other system. A delay tower becomes a permissionless and non-forgeable identity which is fast to verify. These properties make a tower unique, scarce, and perhaps valuable in its own right.**\\n\\n\\nThe following and final part of the article will discuss one implementation of delay towers.\\n\\n\\n\\n\\n---\\n\\n\\n## Full Series\\n\\n\\n1. [A high-throughput chain with a fair launch](http://openlibra.blog/2021/11/01/delay-towers-part-0/)\\n2. [Puzzle Towers for BFT](http://openlibra.blog/2021/11/05/delay-towers-part-1/)\\n3. [From Puzzle Towers and VDFs to Delay Towers](http://openlibra.blog/2021/11/08/delay-towers-part-2/)\\n4. [Implementation on BFT](http://openlibra.blog/2021/11/12/part-3-a-delay-towers-implementation-on-bft/)"},{"id":"/delay-towers-pt-1","metadata":{"permalink":"/blog/delay-towers-pt-1","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/delay-towers-pt-1.md","source":"@site/blog/delay-towers-pt-1.md","title":"Part 1 - Puzzle Towers for BFT","description":"Puzzle Towers for BFT","date":"2021-11-05T00:00:00.000Z","tags":[{"inline":true,"label":"Delay Towers","permalink":"/blog/tags/delay-towers"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":8.505,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Part 1 - Puzzle Towers for BFT","date":"2021-11-05T00:00:00.000Z","tags":["Delay Towers","canonical"]},"unlisted":false,"prevItem":{"title":"Part 2 - From Puzzle Towers and VDFs to Delay Towers","permalink":"/blog/delay-towers-pt-2"},"nextItem":{"title":"Part 0 - A high-throughput chain with a fair launch","permalink":"/blog/delay-towers-pt-0"}},"content":"\x3c!-- truncate --\x3e\\n\\n## Puzzle Towers for BFT\\n\\n\\n## TL;DR\\n\\n\\nPuzzle towers may offer a new Sybil resistance technique worth exploring for permissionless environments, especially during network bootstrapping. They offer a glimpse into what a different game for starting a diverse BFT network might look like. However, without modifying the type of work done in a puzzle tower, the advantages given to current PoW miners would make the proposal a non-starter. Alternatives to traditional PoW will be discussed in the following article.\\n\\n\\n## Context\\n\\n\\nBlockchain systems can leverage Byzantine Fault Tolerant (BFT) protocols to provide high throughput (transactions per second) and faster finalities. Currently, proof of authority (PoA) and proof of stake (PoS) are widely used Sybil resistance mechanisms for BFT networks. While PoA systems lack credible neutrality (due to permissioned access to the validator set being managed by centralized membership providers), PoS systems are permissionless with open access to the network. PoS systems have a well-defined parameter space and protocol designers are tasked with tuning parameters to match a community\'s requirements and culture.\\n\\n\\nWithout going into depth, it\'s worthwhile to summarize a few challenges of PoS networks.\\n\\n\\n### Distribution of tokens\\n\\n\\nHow does a PoS blockchain genesis happen? If you strictly apply the logic of PoS, a stake must pre-exist before the network. Without getting into the notorious regulatory issues associated with token issuance, the manner in which the initial distribution occurs has the potential to threaten the credibility of a neutral smart contract execution environment.\\n\\n\\nAllocation of stake always has bias (which could contribute positively or negatively to the community\'s goals). BFT networks also have biases: High validator node requirements and upper bounds on quorum sizes often tend towards monopoly. And that\'s before considering the compounding of interest on stake, which likely only exacerbates the bias.\\n\\n\\n### Diversity of stakeholders\\n\\n\\nA public good smart contract system must aim to be neutral. It\'s difficult to imagine neutrality without diversity. This raises the question: How can one ensure diversity among stakeholders in the network?\\n\\n\\nThe predominant issue with achieving a plural and diverse set of stakeholders is the technical overhead necessary to participate in a new blockchain. Most platforms\' stakes are typically reserved for technologists and venture capitalists.The general public and many institutions are left out at worst, or merely second thoughts at best. Networks requiring high capital commitments, i.e., you must buy a stake, make those networks inaccessible to many. In some limited situations we\xe2\u20ac\u2122ve seen institutions \\"loaned\\" the necessary stake, or developers granted stake (by a centralized promoter) as part of a testnet program, but such mitigations tend to be marginal in impact and fall short of open, equitable access.\\n\\n\\nWith this context on PoS and industry practices, let us revisit BFT networks and see if we can address these challenges.\\n\\n\\n## Byzantine Fault Tolerance (BFT)\\n\\n\\nWe need the briefest background on what we mean by BFT. Leslie Lamport published the Byzantine Generals Problem in 1982, laying the foundation for multiple breakthroughs in distributed computing over the past four decades. The goal of BFT protocols is to solve the Byzantine Generals problem, i.e., reach consensus among a set of nodes where some of the nodes might be dishonest. The Practical Byzantine Fault Tolerant (PBFT) protocol established a standard for BFT protocols running in production. We\'ve seen multiple variants of PBFT developed by optimizing parameters, such as rounds, to reach finality and messages broadcast. For instance, the improvements on the aggregation of signatures with the BLS scheme allowed us to reduce the number of broadcasted messages. Protocols such as HotStuff progressed BFT to consensus linearity wherein an agreement on a message is reached in a single round. Pipelining of blocks in HotStuff guarantees the finality of the proposed block by the third block following the proposed block. These advances in consensus are highly desirable and future blockchains will likely continue to use variations on these protocols.\\n\\n\\n## Blockchains and BFT\\n\\n\\nAny blockchain open to the world essentially has to solve the Byzantine Generals problem of reaching consensus among (un)trusted parties. The earliest blockchains addressed BFT by stating that higher computational power will increase the probability of proposing the next block (Proof of Work), i.e., using computational power as a substitute for identity. Over time, this led to an arms race of investing in computational resources, i.e., making higher capital investments to increase the likelihood of proposing a new block and thereby earning the associated rewards. Furthermore, this introduced the game-theoretic assumption that one would not harm the system they are highly invested in. Though this addresses Byzantine Generals\' problem in a trustless setting, experience has shown that out-of-band coordination can lead to centralization (e.g. with the emergence of mining pools). Furthermore, PoW struggles to scale to the transactional demands of contemporary use-cases, creating along the way increased waste and exacerbating concerns about energy usage.\\n\\n\\nBy decoupling the establishment of identity and reaching consensus, we could better solve the problems inherent in current approaches. Using alternative ways to establish identity, one could leverage BFT consensus protocols for scaling the blockchain system to meet the demands of high transactional throughput and faster finality times.\\n\\n\\nIn most variants of BFT protocols a set of validators are committed to proposing and attesting new blocks. This set has to be stable and can only be altered at fixed intervals called epochs. Permissioned blockchains rely on Proof of Authority (PoA), wherein a centralized membership service provider authenticates and authorizes validators in the network. Eliminating the centralized membership service provider could lead to Sybil attacks as a malicious party can subvert the consensus protocol by creating many (pseudo)anonymous identities.\\n\\n\\nTo achieve the benefits of BFT consensus, networks have two hard requirements: persistent identities and that the identities are not cheap. Said differently, the reasonable economic value which can be held on-chain safely will be as low as the cost of creating new node identities.\\n\\n\\nThe only known Sybil resistance mechanism to achieve this in a permissionless setting is Proof of Stake (PoS). We have already seen the challenges of PoA and PoS systems in the previous section.\\n\\n\\nPuzzle towers may offer a new Sybil resistance technique worth exploring for permissionless environments, especially during network bootstrapping. In addition, puzzle towers might solve distribution and diversity challenges, at least to a certain extent.\\n\\n\\n## Puzzle Towers to bootstrap BFT networks\\n\\n\\nPuzzle towers were introduced by Dominic Williams in Sybil-resistant Network Identities From Dedicated Hardware. The key idea is to use chained work (such as a Bitcoin puzzle) to prove work done by an agent, wherein the cumulative count of proofs can also be used for providing certain guarantees. One such guarantee would be the cumulative time (or clock cycles) by an agent on the network.\\n\\n\\nPuzzle towers are sequential proofs of work. They consist of chains of proofs obtained from solving puzzles in sequence. The zeroth proof consists of a unique identifier of the owner, such as their public key, and all the proofs following it would have a hash of its previously verified proof. Each agent\xe2\u20ac\u2122s puzzle tower height and last computed hash is stored on a chain, and this data can subsequently be used in consensus games while ranking the candidates in the validator set.\\n\\n\\nPuzzle towers act as a reputation by building persistent identity for the agent which is built with time and cannot be bought or transferred.\\n\\n\\nThere\'s an additional benefit to creating a possibly wider distribution of initial consensus weights. In BFT, puzzle towers provide a way for consensus weight to get distributed to consensus agents (validators), without needing any permission, and without needing to purchase stake from a centralized actor. Even the genesis transaction of a network can include several puzzle towers from different actors, and a group of people can elect from those candidates a genesis validator set.\\n\\n\\nPuzzle towers signal a kind of reputation in the system; one that is acquired by actively participating in the network over time. The mechanism bears similarity to PoS systems where nodes that successfully engage in consensus have their rewards increase over time, and the ones that fail do not receive rewards.\\n\\n\\nAssuming native tokens earned as rewards for securing the network are not transferable between nodes, the consensus weight resulting from puzzle towers would be the same as in a PoS system. Said differently, at the start of networks a puzzle-tower-based vote distribution would correlate with the voting power in a purely PoS voting scheme.\\n\\n\\nThe major differentiator is that no stake had to be acquired to participate. The players all start from the same position: A tower of zero height, and with zero coins. From then on, any node which computes delay towers is treated equally irrespective of stake they own, or when they joined.\\n\\n\\nThough we are not yet making claims about the steady-state Sybil-resistance of these implementations, puzzle towers may be a plausible genesis and bootstrapping ritual.\\n\\n\\n## Limitations of Puzzle Towers\\n\\n\\nThe original puzzle towers design solves one distribution issue, namely that it doesn\'t require capital or permission to join a network. But unmodified, they do tend to benefit an existing community. Hash-based puzzles will suffer from the same race on hardware that plagues Bitcoin and will require highly technical people to set up and maintain nodes to receive \\\\*any\\\\* reward. This design sets a high barrier to entry for contributors.\\n\\n\\nAdditionally, it is expensive, but not impossible, to forge a hash-based puzzle tower quickly. For instance, an agent with an ASIC miner could compute an impostor tower which someone started mining with a desktop computer.\\n\\n\\nLastly, building a puzzle tower based on typical Proof-of-Work puzzles is expensive to verify. The puzzle towers -- if designed as sequential functions, as described -- are computationally expensive to verify their correctness because the verifier has to run all the steps again to obtain the result. When scaled-up this might consume most of the cycles a blockchain should use for its consensus and application layer.\\n\\n\\nNext we\'ll look at Verifiable Delay Functions as alternative work which can be done in a puzzle tower.\\n\\n\\n\\n\\n---\\n\\n\\n## Full Series\\n\\n\\n1. [A high-throughput chain with a fair launch](http://openlibra.blog/2021/11/01/delay-towers-part-0/)\\n2. [Puzzle Towers for BFT](http://openlibra.blog/2021/11/05/delay-towers-part-1/)\\n3. [From Puzzle Towers and VDFs to Delay Towers](http://openlibra.blog/2021/11/08/delay-towers-part-2/)\\n4. [Implementation on BFT](http://openlibra.blog/2021/11/12/part-3-a-delay-towers-implementation-on-bft/)"},{"id":"/delay-towers-pt-0","metadata":{"permalink":"/blog/delay-towers-pt-0","editUrl":"https://github.com/0LNetworkCommunity/documentation/edit/main/blog/blog/delay-towers-pt-0.md","source":"@site/blog/delay-towers-pt-0.md","title":"Part 0 - A high-throughput chain with a fair launch","description":"A high\\\\-throughput chain with a fair launch","date":"2021-11-01T00:00:00.000Z","tags":[{"inline":true,"label":"Delay Towers","permalink":"/blog/tags/delay-towers"},{"inline":true,"label":"canonical","permalink":"/blog/tags/canonical"}],"readingTime":3.925,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Part 0 - A high-throughput chain with a fair launch","date":"2021-11-01T00:00:00.000Z","tags":["Delay Towers","canonical"]},"unlisted":false,"prevItem":{"title":"Part 1 - Puzzle Towers for BFT","permalink":"/blog/delay-towers-pt-1"}},"content":"\x3c!-- truncate --\x3e\\n\\n## A high\\\\-throughput chain with a fair launch\\n\\n\\n## TL;DR\\n\\n\\nA fair launch of a high\\\\-throughput layer\\\\-1 blockchain is happening.\\n\\n\\nYou won\'t need to buy anything or otherwise pay a centralized organization for access. The goal is to create a new standard in blockchain bootstrapping through Delay Towers.\\n\\n\\nThere\'s a new layer\\\\-1 chain that wants to exist. It wants to have these characteristics:\\n\\n\\n* High\\\\-throughput\\n* Faster finality time\\n* Fair launch\\n* Establishing a persistent identity\\n* Permissionless access\\n* Engender decentralization\\n* Regulatory certainty\\n\\n\\nCentralized launches of Proof of Stake networks are an unsatisfactory strategy for bootstrapping a community\\\\-led public good. No disrespect meant to projects that have launched in such a way, there was just no credible technical alternative, possibly until now.\\n\\n\\n## The Tradeoff\\n\\n\\nIf you are looking for a blockchain with fast finality, you are likely evaluating a derivative of the Byzantine Fault Tolerance (BFT) consensus system. Research on BFT consensus has progressed from designs requiring multiple rounds of communication to finalize a block, up to the latest breakthroughs of \\"consensus linearity\\" and \\"pipelining\\", which produce systems where the throughput is limited only by the network connection latency.\\n\\n\\nTo achieve the benefits of BFT, the networks require establishing identities for validators to participate in the consensus protocol. Currently, most blockchains rely on either of these: Proof of Authority (PoA) for private consortia and Proof of Stake (PoS) for permissionless environments. PoA lacks credible neutrality due to centralized validator membership control, and PoS suffers from a lack of diversity of participants and high inequality while raising numerous significant regulatory concerns. The novel Delay Towers are an alternative mechanism to establish persistent identity in permissionless environments.\\n\\n\\n## Delay Towers\\n\\n\\nDelay Towers are a Proof of Elapsed Time to build persistent identities. Drawing inspiration from the paper\xa0[\\"Sybil\\\\-resistant network identities from dedicated hardware\\"](https://docs.google.com/document/d/1eRTAe3szuIoZEloHvRMtZlrU7t2un4UVQ8LarpU3LNk/edit?usp=sharing)by Dominic Williams, the proposed design extends the idea of \\"puzzle towers\\" with\xa0[Verifiable Delay Functions (VDFs)](https://eprint.iacr.org/2018/601.pdf)VDFs are cryptographic primitives for providing a guarantee that a lower bound of time has elapsed.\\n\\n\\nIn this protocol every node in a network has a Delay Tower, which is composed of linearly chained proofs. A chain of Delay Tower blocks produces a guarantee of cumulative work done by a node in the network. Each proof extends from the previous one (using one proof as the preimage to the next block), building the tower \\"higher\\"; creating a series of sequential proofs of work. Unlike traditional Proof of Work puzzle algorithms that are parallelizable and probabilistic, \\"mining\\" a Delay Tower is sequential and deterministic. Since VDFs cannot be parallelized, they do not benefit significantly from alternative hardware such as GPUs. The delay towers enable persistent identities by providing a permissionless and non\\\\-forgeable identity for miners.\\n\\n\\nDelay Towers establish an identity for miners, and can be used as a metric to quantify a node\'s commitment to a network, and subsequently rank it for the purpose of choosing inclusion in the validator quorum at every epoch. This is achievable, in part due to a significant cost to participate in the network. One has to dedicate resources to build their towers and a high exit penalty to recreate their identity due to lost work. And the cost goes up over time as all nodes continue to extend their towers.\\n\\n\\nIt is not feasible to apply infinite money or resources to forge a tower, the time taken cannot meaningfully be reduced. A forgery will take approximately the same amount of time as the original. As such, a Delay Tower becomes a permissionless and non\\\\-forgeable identity that is fast to verify; valuable in its own right.\\n\\n\\n## The Experiment\\n\\n\\nAn experimental network ran successfully for nearly 1 year without interruption. It used a Delay Tower protocol for assigning consensus power for a modern BFT blockchain architecture. This is the first publication in a series of articles which will summarize the protocol, and discuss the attractive features that were observed in the experiment, such as:\\n\\n\\n* Providing persistent identity which aids in Sybil resistance in BFT consensus.\\n* Offer a more diverse distribution than usual, to anyone with minimal computational resources.\\n* Levelling the playing field, with a linear function the advantage of the miners at genesis goes down over time.\\n* With minimal computations and no wasted cycles, delay towers offer an eco\\\\-friendly alternative to PoW approaches.\\n* Offering a mechanism to bootstrap a BFT network without selling tokens (ICOs), venture\\\\-backed foundations, or airdrops.\\n\\n\\n## To be continued\\n\\n\\nInstructions for mining the new chain will materialize in the coming weeks.\xa0\\n\\n\\n\\n\\n---\\n\\n\\n## Full Series\\n\\n\\n1. [A high\\\\-throughput chain with a fair launch](http://openlibra.blog/2021/11/01/delay-towers-part-0/)\\n2. [Puzzle Towers for BFT](http://openlibra.blog/2021/11/05/delay-towers-part-1/)\\n3. [From Puzzle Towers and VDFs to Delay Towers](http://openlibra.blog/2021/11/08/delay-towers-part-2/)\\n4. [Implementation on BFT](http://openlibra.blog/2021/11/12/part-3-a-delay-towers-implementation-on-bft/)"}]}}')}}]);